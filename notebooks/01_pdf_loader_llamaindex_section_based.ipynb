{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "767d3ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# point this to your project root (where `src/` folder lives)\n",
    "project_root = Path(\"/Users/ywxiu/jasp-multimodal-rag\").resolve()\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# now you can import\n",
    "from src.ingestion.pdf_text_loader import (\n",
    "    clean_page_header,\n",
    "    convert_text_to_sections,\n",
    "    reconstruct_equations,\n",
    "    normalize_tables,\n",
    "    split_markdown_by_sections,\n",
    "    count_tokens\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4b1ab278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from src.ingestion import pdf_text_loader\n",
    "\n",
    "importlib.reload(pdf_text_loader)\n",
    "\n",
    "from src.ingestion.pdf_text_loader import normalize_tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "76f9985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_dir = Path(\"/Users/ywxiu/jasp-multimodal-rag/data/raw\")\n",
    "pdf_name = \"Statistical-Analysis-in-JASP-A-guide-for-students-2025.pdf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "03176261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹Raw text (first 500 chars):\n",
      "   \n",
      "95 | P a g e  \n",
      "JASP 0.19.3 - Professor Mark Goss-Sampson \n",
      "Tukey â€“ is one of the most commonly used tests and provides controlled Type I error for groups with \n",
      "the same sample size and equal group variance. \n",
      "Scheffe â€“ controls for the overall confidence level when the group sample sizes are different. \n",
      "Sidak â€“ is similar to Bonferroni but assumes that each comparison is independent of the others . \n",
      "Slightly more powerful than Bonferroni. \n",
      " \n",
      "EFFECT SIZE \n",
      "JASP provides 3 alternative effect size calculations for use with the independent group ANOVA tests: \n",
      "Eta squared (Î· 2) - accurate for the sample variance explained but overestimates the population \n",
      "variance. This can make it difficult to compare the effect of a single variable in different studies. \n",
      "Partial Eta squared (Î· p2) â€“ this solves the problem relating to population variance overestimation , \n",
      "allowing for comparison of the effect of the same variable in different studies. \n",
      "Omega squared (Ï‰2) â€“ Normally, statistical bias gets very small as sample size increases, but for small \n",
      "samples (n<30), Ï‰2 provides an unbiased effect size measure. \n",
      "Test Measure Trivial Small Medium Large \n",
      "ANOVA Eta \n",
      "Partial Eta \n",
      "Omega squared \n",
      "<0.1 \n",
      "<0.01 \n",
      "<0.01 \n",
      "0.1 \n",
      "0.01 \n",
      "0.01 \n",
      "0.25 \n",
      "0.06 \n",
      "0.06 \n",
      "0.37 \n",
      "0.14 \n",
      "0.14 \n",
      " \n",
      "RUNNING THE INDEPENDENT ANOVA \n",
      "Load Independent ANOVA diets.csv. This contains A column containing the 3 diets used (A, B and C) \n",
      "and another column containing the absolute amount of weight loss after 8 weeks on one of 3 different \n",
      "diets.  For good practice, check the descriptive statistics and the boxplots for any extreme outliers. \n",
      "Go to ANOVA > ANOVA, put weight loss into the Dependent Variable and the Diet groupings into the \n",
      "Fixed Factors box.  In the first instance, tick Descriptive statistics and Ï‰2 as the effect size.  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs = SimpleDirectoryReader(data_dir).load_data()\n",
    "page99 = [d for d in docs if d.metadata.get(\"page_label\") == \"99\"][0]\n",
    "print(\"ðŸ”¹Raw text (first 500 chars):\")\n",
    "print(page99.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3a793e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹After clean_page_header:\n",
      "Tukey â€“ is one of the most commonly used tests and provides controlled Type I error for groups with \n",
      "the same sample size and equal group variance. \n",
      "Scheffe â€“ controls for the overall confidence level when the group sample sizes are different. \n",
      "Sidak â€“ is similar to Bonferroni but assumes that each comparison is independent of the others . \n",
      "Slightly more powerful than Bonferroni. \n",
      " \n",
      "EFFECT SIZE \n",
      "JASP provides 3 alternative effect size calculations for use with the independent group ANOVA tests: \n"
     ]
    }
   ],
   "source": [
    "cleaned = clean_page_header(page99.text)\n",
    "print(\"ðŸ”¹After clean_page_header:\")\n",
    "print(cleaned[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9bb94e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹Found 3 sections on page 99\n",
      "----\n",
      "Title: None\n",
      "Tukey â€“ is one of the most commonly used tests and provides controlled Type I error for groups with\n",
      "the same sample size and equal group variance.\n",
      "Scheffe â€“ controls for the overall confidence level when the group sample sizes are different.\n",
      "Sidak â€“ is similar to Bonferroni but assumes that each comparison is independent of the others .\n",
      "Slightly more powerful than Bonferroni.\n",
      "----\n",
      "Title: EFFECT SIZE (page 99)\n",
      "JASP provides 3 alternative effect size calculations for use with the independent group ANOVA tests:\n",
      "Eta squared (Î· 2) - accurate for the sample variance explained but overestimates the population\n",
      "variance. This can make it difficult to compare the effect of a single variable in different studies.\n",
      "Partial Eta squared (Î· p2) â€“ this solves the problem relating to population variance overestimation ,\n",
      "----\n",
      "Title: RUNNING THE INDEPENDENT ANOVA (page 99)\n",
      "Load Independent ANOVA diets.csv. This contains A column containing the 3 diets used (A, B and C)\n",
      "and another column containing the absolute amount of weight loss after 8 weeks on one of 3 different\n",
      "diets.  For good practice, check the descriptive statistics and the boxplots for any extreme outliers.\n",
      "Go to ANOVA > ANOVA, put weight loss into the Dependent Variable and the Diet groupings into the\n",
      "F\n"
     ]
    }
   ],
   "source": [
    "sections = convert_text_to_sections(cleaned, \"99\")\n",
    "print(f\"ðŸ”¹Found {len(sections)} sections on page 99\")\n",
    "for s in sections:\n",
    "    print(\"----\")\n",
    "    print(f\"Title: {s['title']}\")\n",
    "    print(s[\"content\"][:400])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "43619f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹After reconstruct_equations + normalize_tables:\n",
      "JASP provides 3 alternative effect size calculations for use with the independent group ANOVA tests:\n",
      "Eta squared ( 2) - accurate for the sample variance explained but overestimates the population\n",
      "variance. This can make it difficult to compare the effect of a single variable in different studies.\n",
      "Partial Eta squared ( p2)  this solves the problem relating to population variance overestimation ,\n",
      "allowing for comparison of the effect of the same variable in different studies.\n",
      "Omega squared (2)  No\n"
     ]
    }
   ],
   "source": [
    "for s in sections:\n",
    "    s[\"content\"] = reconstruct_equations(s[\"content\"])\n",
    "    s[\"content\"] = normalize_tables(s[\"content\"])\n",
    "\n",
    "print(\"ðŸ”¹After reconstruct_equations + normalize_tables:\")\n",
    "print(sections[1][\"content\"][:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "950c8161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'file_path': '/Users/ywxiu/jasp-multimodal-rag/data/processed/markdown/Statistical-Analysis-in-JASP-A-guide-for-students-2025.md', 'file_name': 'Statistical-Analysis-in-JASP-A-guide-for-students-2025.md', 'file_type': 'text/markdown', 'file_size': 187828, 'creation_date': '2025-11-06', 'last_modified_date': '2025-11-06'}\n",
      "# USING THE JASP ENVIRONMENT (page 6)\n",
      "\n",
      "\n",
      "Open JASP.\n",
      "The main menu can be accessed by clicking on the top-left icon.\n",
      "Open:\n",
      "JASP has its own . jasp format but can open a variety of\n",
      "different dataset formats, such as:\n",
      ".xls/xlsx (Excel files)\n",
      ".csv (comma-separated values) can be saved in Excel\n",
      ".txt (plain text) can also be saved in Excel\n",
      ".tsv (tab-separated values) can also be saved in Excel\n",
      ".sav (IBM SPSS data file)\n",
      ".ods (Open Document spreadsheet)\n",
      ".dta (Stata data file)\n",
      ".por (SPSS ASCII file)\n",
      ".Sas7\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "docs = SimpleDirectoryReader(\n",
    "    input_dir=\"/Users/ywxiu/jasp-multimodal-rag/data/processed/markdown\",\n",
    "    recursive=False\n",
    ").load_data()\n",
    "\n",
    "print(len(docs), docs[0].metadata)\n",
    "print(docs[0].text[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "39d60e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "import re\n",
    "\n",
    "def split_markdown_by_sections(document_text):\n",
    "    pattern = r\"^# (.+?) \\(page (\\d+)\\)\"\n",
    "    matches = list(re.finditer(pattern, document_text, flags=re.MULTILINE))\n",
    "    sections = []\n",
    "\n",
    "    for i, match in enumerate(matches):\n",
    "        title, page = match.group(1), match.group(2)\n",
    "        start = match.end()\n",
    "        end = matches[i + 1].start() if i + 1 < len(matches) else len(document_text)\n",
    "        section_text = document_text[start:end].strip()\n",
    "\n",
    "        sections.append({\n",
    "            \"text\": section_text,\n",
    "            \"metadata\": {\n",
    "                \"section_title\": title,\n",
    "                \"page_start\": page,\n",
    "                \"page_end\": page,\n",
    "            },\n",
    "        })\n",
    "    return sections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0b8d4fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Created 270 section-level documents\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "documents = []\n",
    "for doc in docs:\n",
    "    for sec in split_markdown_by_sections(doc.text):\n",
    "        documents.append(\n",
    "            Document(\n",
    "                text=sec[\"text\"],\n",
    "                metadata={\n",
    "                    \"pdf_name\": doc.metadata.get(\"file_name\"),\n",
    "                    **sec[\"metadata\"],\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "print(f\"âœ… Created {len(documents)} section-level documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8acf00d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Token lengths added to metadata!\n",
      "{'pdf_name': 'Statistical-Analysis-in-JASP-A-guide-for-students-2025.md', 'section_title': 'USING THE JASP ENVIRONMENT', 'page_start': '6', 'page_end': '6', 'token_length': 810}\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "# Choose the tokenizer for your target model\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")  # for GPT-4-turbo / GPT-3.5-turbo\n",
    "\n",
    "def count_tokens(text):\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "# Add token length as metadata\n",
    "for doc in documents:\n",
    "    n_tokens = count_tokens(doc.text)\n",
    "    doc.metadata[\"token_length\"] = n_tokens\n",
    "\n",
    "print(\"âœ… Token lengths added to metadata!\")\n",
    "print(documents[0].metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c9ffaca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re, uuid, tiktoken\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from llama_index.core import Document\n",
    "\n",
    "def save_test_only_json(\n",
    "    documents: List[Document],\n",
    "    output_path: str,\n",
    "    pdf_name: str,\n",
    "    source_path: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    Save section-level LlamaIndex Documents to a JSON file\n",
    "    with minimal, ChromaDB-safe metadata.\n",
    "    Handles case-insensitive placeholder extraction.\n",
    "    \n",
    "    Args:\n",
    "        documents (List[Document]): List of LlamaIndex Document objects.\n",
    "        output_path (str): Path to save the JSON file.\n",
    "        pdf_name (str): Name of the original PDF source.\n",
    "        source_path (str): Absolute path to the markdown file used.\n",
    "    \"\"\"\n",
    "\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "    def count_tokens(text: str) -> int:\n",
    "        return len(encoding.encode(text))\n",
    "\n",
    "    def clean_none_values(d: dict) -> dict:\n",
    "        \"\"\"Remove keys with None or empty strings (Chroma-safe).\"\"\"\n",
    "        return {k: v for k, v in d.items() if v not in [None, \"\"]}\n",
    "\n",
    "    # --- Pattern: match image placeholders, case-insensitive ---\n",
    "    placeholder_pattern = re.compile(r\"\\[image_placeholder_[a-z0-9_]+\\]\", re.IGNORECASE)\n",
    "\n",
    "    records = []\n",
    "    for doc in documents:\n",
    "        text = doc.text\n",
    "        meta = doc.metadata.copy()\n",
    "\n",
    "        # --- Parse section title and page number ---\n",
    "        section_title = meta.get(\"section_title\", \"\")\n",
    "        page_start = str(meta.get(\"page_start\", \"\"))\n",
    "        section_id = (\n",
    "            re.sub(r\"[^A-Za-z0-9]+\", \"_\", section_title)\n",
    "            .strip(\"_\")\n",
    "            .upper()\n",
    "            + f\"_PAGE_{page_start}\"\n",
    "        )\n",
    "\n",
    "        # --- Extract image placeholders (case-insensitive) ---\n",
    "        placeholders = placeholder_pattern.findall(text)\n",
    "        # Normalize placeholders to uppercase for consistency\n",
    "        placeholders = [p.upper() for p in placeholders]\n",
    "\n",
    "        # --- Build metadata dict ---\n",
    "        record_meta = {\n",
    "            \"doc_id\": str(uuid.uuid4())[:8],\n",
    "            \"pdf_name\": pdf_name,\n",
    "            \"source_path\": source_path,\n",
    "            \"markdown_file\": Path(source_path).name,\n",
    "            \"section_id\": section_id,\n",
    "            \"section_title\": section_title,\n",
    "            \"page_start\": page_start,\n",
    "            \"image_placeholders\": placeholders,\n",
    "            \"token_length\": count_tokens(text),\n",
    "            \"processing_date\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "        }\n",
    "\n",
    "        # --- Remove null/empty keys ---\n",
    "        record_meta = clean_none_values(record_meta)\n",
    "\n",
    "        # --- Append record ---\n",
    "        records.append({\"text\": text, \"metadata\": record_meta})\n",
    "\n",
    "    # --- Save to JSON ---\n",
    "    output_path = Path(output_path)\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(records, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"âœ… Saved {len(records)} section-level documents â†’ {output_path}\")\n",
    "    print(f\"ðŸ“¸ Example placeholders from second doc: {records[1]['metadata'].get('image_placeholders', [])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "eca216cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved 270 section-level documents â†’ /Users/ywxiu/jasp-multimodal-rag/data/processed/test_only.json\n",
      "ðŸ“¸ Example placeholders from second doc: ['[IMAGE_PLACEHOLDER_USING_THE_JASP_ENVIRONMENT_PAGE_6_1]', '[IMAGE_PLACEHOLDER_USING_THE_JASP_ENVIRONMENT_PAGE_6_2]', '[IMAGE_PLACEHOLDER_USING_THE_JASP_ENVIRONMENT_PAGE_6_3]', '[IMAGE_PLACEHOLDER_USING_THE_JASP_ENVIRONMENT_PAGE_6_4]']\n"
     ]
    }
   ],
   "source": [
    "# Example call in your pipeline\n",
    "save_test_only_json(\n",
    "    documents=documents,\n",
    "    output_path=\"/Users/ywxiu/jasp-multimodal-rag/data/processed/test_only.json\",\n",
    "    pdf_name=\"Statistical-Analysis-in-JASP-A-guide-for-students-2025.pdf\",\n",
    "    source_path=\"/Users/ywxiu/jasp-multimodal-rag/data/processed/markdown/Statistical-Analysis-in-JASP-A-guide-for-students-2025.md\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9faca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bf0e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e08bce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b486fef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bb080da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved 270 section-level documents with token metadata â†’ /Users/ywxiu/jasp-multimodal-rag/data/processed/text_only.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Path for your output JSON file\n",
    "output_path = Path(\"/Users/ywxiu/jasp-multimodal-rag/data/processed/text_only.json\")\n",
    "\n",
    "# Convert each Document to a plain dict\n",
    "# `Document` objects have a .text and .metadata attribute\n",
    "data_to_save = [\n",
    "    {\n",
    "        \"text\": doc.text,\n",
    "        \"metadata\": doc.metadata\n",
    "    }\n",
    "    for doc in documents\n",
    "]\n",
    "\n",
    "# Write to disk\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data_to_save, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"âœ… Saved {len(documents)} section-level documents with token metadata â†’ {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d882092b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "99e8d81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 18:13:49,076 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 1226e0d5-f6b2-46c6-ac66-0837b6cc67b6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 18:13:50,295 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1226e0d5-f6b2-46c6-ac66-0837b6cc67b6 \"HTTP/1.1 200 OK\"\n",
      "2025-11-05 18:13:52,738 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1226e0d5-f6b2-46c6-ac66-0837b6cc67b6 \"HTTP/1.1 200 OK\"\n",
      "2025-11-05 18:13:56,043 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1226e0d5-f6b2-46c6-ac66-0837b6cc67b6 \"HTTP/1.1 200 OK\"\n",
      "2025-11-05 18:13:56,728 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1226e0d5-f6b2-46c6-ac66-0837b6cc67b6/result/markdown \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# SPLITTING DATA FILES\n",
      "\n",
      "If there is a grouping variable (categorical or ordinal), descriptive statistics and plots can be produced for each group. Using Descriptive data.csv with the variable data in the Variables box, now add Group to the Split box.\n",
      "\n",
      "| Variables          | Descriptive Statistics |                         |       |         |\n",
      "| ------------------ | ---------------------- | ----------------------- | ----- | ------- |\n",
      "| Variable           |                        | Group 1                 |       | Group 2 |\n",
      "|                    | Mean                   | 16.021                  |       | 18.787  |\n",
      "| Std. Error of Mean |                        |                         | 0.362 | 0.316   |\n",
      "|                    | Std. Deviation         |                         | 6.424 | 7.040   |\n",
      "|                    | Skewness               |                         | 0.200 | -0.176  |\n",
      "|                    | Std. Error of Skewness |                         | 0.137 | 0.110   |\n",
      "|                    | Kurtosis               | -0.101                  |       | -0.397  |\n",
      "|                    | Std. Error of Kurtosis |                         | 0.274 | 0.219   |\n",
      "|                    | Shapiro-Wilk           |                         | 0.993 | 0.993   |\n",
      "| Group              |                        | P-value of Shapiro-Wilk | 0.119 | 0.029   |\n",
      "\n",
      "# DESCRIPTIVE DATA VISUALISATION\n",
      "\n",
      "JASP produces a comprehensive range of descriptive and analysis-specific plots. These plots will be explained in their relevant chapters.\n",
      "\n",
      "# BASIC PLOTS\n",
      "\n",
      "Firstly, to look at examples of the basic plots, open Descriptive data.csv with the variable data in the Variables box, go to Plots and tick Distribution plots, Display density, Interval plots, Q-Q plots, and dot plots.\n",
      "\n",
      "| Basic plots       | Distribution plots | Correlation plots | Interval plots |\n",
      "| ----------------- | ------------------ | ----------------- | -------------- |\n",
      "| Display density   |                    |                   |                |\n",
      "| Display rug marks |                    |                   |                |\n",
      "| Bin width type    | Sturges            |                   |                |\n",
      "| Number of bins    | 30                 |                   |                |\n",
      "\n",
      "# Categorical plots\n",
      "\n",
      "| Pareto plots                           |                                            |\n",
      "| -------------------------------------- | ------------------------------------------ |\n",
      "| Pareto rule                            | 95.0 %                                     |\n",
      "| Likert plots                           | Assume all variables share the same levels |\n",
      "| Adjustable font size for vertical axis | Normal                                     |\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_parse import LlamaParse\n",
    "\n",
    "parser = LlamaParse(result_type=\"markdown\")\n",
    "docs = parser.load_data(\"/Users/ywxiu/jasp-multimodal-rag/data/test/test_pages25-28.pdf\")\n",
    "\n",
    "print(docs[0].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f303e48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '1', 'file_name': 'test_pages25-28.pdf', 'file_path': '/Users/ywxiu/jasp-multimodal-rag/data/test/test_pages25-28.pdf', 'file_type': 'application/pdf', 'file_size': 1716874, 'creation_date': '2025-10-24', 'last_modified_date': '2025-10-24', 'chapter': 'Unknown', 'section': 'Unknown'}\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, Document\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = \"/Users/ywxiu/jasp-multimodal-rag/data/test\"\n",
    "raw_docs = SimpleDirectoryReader(DATA_DIR).load_data()\n",
    "\n",
    "enriched_docs = []\n",
    "for doc in raw_docs:\n",
    "    pdf_name = Path(doc.metadata[\"file_name\"]).stem\n",
    "\n",
    "    # Infer chapter and section from filename, if present\n",
    "    parts = pdf_name.split(\"_\")\n",
    "    chapter = next((p for p in parts if p.lower().startswith(\"chapter\")), None)\n",
    "    section = next((p for p in parts if p.lower().startswith(\"section\")), None)\n",
    "\n",
    "    doc.metadata[\"chapter\"] = chapter or \"Unknown\"\n",
    "    doc.metadata[\"section\"] = section or \"Unknown\"\n",
    "    enriched_docs.append(doc)\n",
    "\n",
    "print(enriched_docs[0].metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e929d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f84852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports and configuration\n",
    "import base64\n",
    "import json\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from pdf2image import convert_from_path\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# ---- CONFIG ----\n",
    "PDF_PATH = Path(\"../data/test/test_pages25-28.pdf\")      # path to your local PDF\n",
    "\n",
    "OUTPUT_DIR = Path(\"data/test/image\")     # directory to save page images\n",
    "MODEL_NAME = \"llava-phi3:latest\"  # Ollama model name\n",
    "\n",
    "OLLAMA_URL = \"http://localhost:11434/api/generate\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81c0f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE =\"\"\"\n",
    "\n",
    "Summarize this image in a concise, academic tone relevant to a statistical software(JASP),such as interface screenshots or outputs.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f9ae0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f82c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bd0a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543df8b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcec194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e1eba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcd75c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import Document\n",
    "from itertools import groupby\n",
    "import fitz, base64, requests\n",
    "\n",
    "def load_structured_manual(pdf_path):\n",
    "    parser = LlamaParse(result_type=\"json\")\n",
    "    parsed = parser.load_data(pdf_path)   # returns pages with structured elements\n",
    "    sections = []\n",
    "    cur_section = None\n",
    "    text_buffer = []\n",
    "\n",
    "    for page in parsed:\n",
    "        for el in page[\"elements\"]:\n",
    "            if el[\"type\"] == \"heading\" and el[\"level\"] in [1, 2]:\n",
    "                if text_buffer:\n",
    "                    sections.append((cur_section, \"\\n\".join(text_buffer)))\n",
    "                    text_buffer = []\n",
    "                cur_section = el[\"text\"]\n",
    "            elif el[\"type\"] == \"paragraph\":\n",
    "                text_buffer.append(el[\"text\"])\n",
    "    if text_buffer:\n",
    "        sections.append((cur_section, \"\\n\".join(text_buffer)))\n",
    "\n",
    "    docs = [\n",
    "        Document(\n",
    "            text=txt.strip(),\n",
    "            metadata={\n",
    "                \"section\": sec,\n",
    "                \"chapter\": sec.split(\":\")[0] if \":\" in sec else None,\n",
    "                \"source\": pdf_path\n",
    "            }\n",
    "        )\n",
    "        for sec, txt in sections if txt.strip()\n",
    "    ]\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457fef9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca628d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LlamaParse is async-first, so we need to run this line of code if you are working on a notebook\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "71c9a1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LLAMA_CLOUD_API_KEY\"] = \"llx-Hs5ASBbsMgrqi91UgmKJOIR0JdCMilbWWpaWMSTX7n7qcb7x\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d42a26f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.getenv(\"LLAMA_CLOUD_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2abf7456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ywxiu/jasp-multimodal-rag\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "203e124e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ywxiu/jasp-multimodal-rag\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/ywxiu/jasp-multimodal-rag\")\n",
    "print(os.getcwd())  # should now show /Users/ywxiu/jasp-multimodal-rag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb080b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 18:18:02,708 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id cb7f9819-715f-4346-8408-620c826a8c67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 18:18:03,930 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:18:06,156 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:18:09,438 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:18:13,647 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:18:19,076 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:18:24,468 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:18:29,874 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:18:35,345 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:18:40,777 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:18:46,212 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 18:18:51,656 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:18:57,094 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:19:02,507 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:19:07,944 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:19:13,388 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:19:18,833 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:19:24,267 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:19:29,663 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:19:35,091 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:19:40,564 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 18:19:46,230 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:19:51,661 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:19:57,049 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:20:02,454 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:20:08,554 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:20:13,989 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:20:19,427 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:20:24,854 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:20:30,260 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:20:35,700 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 18:20:41,137 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:20:46,589 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:20:52,000 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:20:57,423 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:21:02,855 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:21:08,342 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:21:13,834 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:21:19,311 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:21:24,745 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 18:21:25,158 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cb7f9819-715f-4346-8408-620c826a8c67/result/text \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_parse import LlamaParse\n",
    "documents = LlamaParse(result_type=\"text\").load_data(\"./data/raw/Statistical-Analysis-in-JASP-A-guide-for-students-2025.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea2ad670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1aba5f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "9  JASP\n",
      "\n",
      "LOGISTIC REGRESSION\n",
      "In simple and multiple linear regression outcome and predictor variable(s) were continuous data.\n",
      "What if the outcome was a binary/categorical measure? Can, for example, a yes or no outcome be\n",
      "predicted by other categorical or continuous variables? The answer is yes if binary logistic regression\n",
      "is used. This method is used to predict the probability of a binary yes or no outcome.\n",
      "\n",
      "The null hypothesis tested is that there is no relationship between the outcome and the predictor\n",
      "variable(s).\n",
      "\n",
      "As can be seen in the graph below, a linear regression line between the yes and no responses would\n",
      "be meaningless as a prediction model. Instead, a sigmoidal logistic regression curve is fitted with a\n",
      "minimum of 0 and a maximum of 1. Some predictor values overlap between yes and no. For example,\n",
      "a prediction value of 5 would give an equal 50% probability of being a yes or no outcome. Thresholds\n",
      "are therefore calculated to determine if a predictor data value will be classified as a yes or no outcome.\n",
      "\n",
      "       1.0               Outcome = Yes\n",
      "\n",
      "       0.8\n",
      "\n",
      "       0.6\n",
      "\n",
      "       0.4\n",
      "\n",
      "       0.2\n",
      "                                          Outcome = No\n",
      "       0.0\n",
      "\n",
      "            0               2         4   6  8        10\n",
      "\n",
      "ASSUMPTIONS FOR BINARY LOGISTIC REGRESSION\n",
      "\n",
      "â€¢     The dependent variable must be binary, i.e. yes or no, male or female, good or bad.\n",
      "â€¢     One or more independent (predictor variables) can be continuous or categorical variables.\n",
      "â€¢     A linear relationship exists between any continuous independent variables and the logit\n",
      "      transformation (natural log of the odds that the outcome equals one of the categories) of the\n",
      "      dependent variable.\n",
      "\n",
      "LOGISTIC REGRESSION METRICS\n",
      "\n",
      "AIC (Akaike Information Criteria) and BIC (Bayesian Information Criteria) are measures of fit for the\n",
      "model; the best model will have the lowest AIC and BIC values.\n",
      "\n",
      "88 | P a g e\n",
      "JASP 0.19.3 - Professor Mark Goss-Sampson\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(documents[91].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d9ba1910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ywxiu/Library/Caches/pypoetry/virtualenvs/jasp-multimodal-rag-F1fOabRm-py3.12/lib/python3.12/site-packages/llama_cloud_services/parse/base.py:551: UserWarning: The following parameters are unused: config.\n",
      "\n",
      " - 'config' is not a valid parameter. Please check the documentation or update the package.\n",
      "  warnings.warn(\n",
      "2025-10-23 19:19:18,368 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 97c78384-e7b2-40b3-8225-6ac393bdd949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 19:19:19,591 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/97c78384-e7b2-40b3-8225-6ac393bdd949 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:19:21,764 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/97c78384-e7b2-40b3-8225-6ac393bdd949 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:19:24,971 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/97c78384-e7b2-40b3-8225-6ac393bdd949 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:19:29,164 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/97c78384-e7b2-40b3-8225-6ac393bdd949 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:19:34,599 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/97c78384-e7b2-40b3-8225-6ac393bdd949 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:19:40,006 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/97c78384-e7b2-40b3-8225-6ac393bdd949 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:19:45,464 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/97c78384-e7b2-40b3-8225-6ac393bdd949 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:19:50,943 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/97c78384-e7b2-40b3-8225-6ac393bdd949 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:19:56,366 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/97c78384-e7b2-40b3-8225-6ac393bdd949 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:20:01,799 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/97c78384-e7b2-40b3-8225-6ac393bdd949 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 19:20:07,170 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/97c78384-e7b2-40b3-8225-6ac393bdd949 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:20:12,601 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/97c78384-e7b2-40b3-8225-6ac393bdd949 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:20:18,097 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/97c78384-e7b2-40b3-8225-6ac393bdd949 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:20:23,670 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/97c78384-e7b2-40b3-8225-6ac393bdd949 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:20:29,101 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/97c78384-e7b2-40b3-8225-6ac393bdd949 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:20:35,858 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/97c78384-e7b2-40b3-8225-6ac393bdd949 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:20:41,370 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/97c78384-e7b2-40b3-8225-6ac393bdd949 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:20:46,800 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/97c78384-e7b2-40b3-8225-6ac393bdd949 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:20:54,124 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/97c78384-e7b2-40b3-8225-6ac393bdd949 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:20:59,576 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/97c78384-e7b2-40b3-8225-6ac393bdd949 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 19:21:05,016 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/97c78384-e7b2-40b3-8225-6ac393bdd949 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:21:10,713 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/97c78384-e7b2-40b3-8225-6ac393bdd949 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:21:16,447 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/97c78384-e7b2-40b3-8225-6ac393bdd949 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:21:16,858 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/97c78384-e7b2-40b3-8225-6ac393bdd949/result/text \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from llama_parse import LlamaParse\n",
    "\n",
    "parser = LlamaParse(\n",
    "    api_key=\"llx-Hs5ASBbsMgrqi91UgmKJOIR0JdCMilbWWpaWMSTX7n7qcb7x\",\n",
    "    result_type=\"text\",\n",
    "    config={\n",
    "        \"parsing_instruction\": (\n",
    "            \"When you encounter plots in the document, \"\n",
    "            \"insert a clear placeholder in the text like \"\n",
    "            \"[FIGURE_PLACEHOLDER: page{page_number}_fig{index}]. \"\n",
    "            \"Do not describe the image; just insert the marker in the correct position.\"\n",
    "        )\n",
    "    }\n",
    ")\n",
    "\n",
    "documents_new = parser.load_data(\"./data/raw/Statistical-Analysis-in-JASP-A-guide-for-students-2025.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a569c885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "9  JASP\n",
      "\n",
      "LOGISTIC REGRESSION\n",
      "In simple and multiple linear regression outcome and predictor variable(s) were continuous data.\n",
      "What if the outcome was a binary/categorical measure? Can, for example, a yes or no outcome be\n",
      "predicted by other categorical or continuous variables? The answer is yes if binary logistic regression\n",
      "is used. This method is used to predict the probability of a binary yes or no outcome.\n",
      "\n",
      "The null hypothesis tested is that there is no relationship between the outcome and the predictor\n",
      "variable(s).\n",
      "\n",
      "As can be seen in the graph below, a linear regression line between the yes and no responses would\n",
      "be meaningless as a prediction model. Instead, a sigmoidal logistic regression curve is fitted with a\n",
      "minimum of 0 and a maximum of 1. Some predictor values overlap between yes and no. For example,\n",
      "a prediction value of 5 would give an equal 50% probability of being a yes or no outcome. Thresholds\n",
      "are therefore calculated to determine if a predictor data value will be classified as a yes or no outcome.\n",
      "\n",
      "       1.0               Outcome = Yes\n",
      "\n",
      "       0.8\n",
      "\n",
      "       0.6\n",
      "\n",
      "       0.4\n",
      "\n",
      "       0.2\n",
      "                                          Outcome = No\n",
      "       0.0\n",
      "\n",
      "            0               2         4   6  8        10\n",
      "\n",
      "ASSUMPTIONS FOR BINARY LOGISTIC REGRESSION\n",
      "\n",
      "â€¢     The dependent variable must be binary, i.e. yes or no, male or female, good or bad.\n",
      "â€¢     One or more independent (predictor variables) can be continuous or categorical variables.\n",
      "â€¢     A linear relationship exists between any continuous independent variables and the logit\n",
      "      transformation (natural log of the odds that the outcome equals one of the categories) of the\n",
      "      dependent variable.\n",
      "\n",
      "LOGISTIC REGRESSION METRICS\n",
      "\n",
      "AIC (Akaike Information Criteria) and BIC (Bayesian Information Criteria) are measures of fit for the\n",
      "model; the best model will have the lowest AIC and BIC values.\n",
      "\n",
      "88 | P a g e\n",
      "JASP 0.19.3 - Professor Mark Goss-Sampson\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(documents[91].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bb92c9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: llama-parse\n",
      "Version: 0.6.54\n",
      "Summary: Parse files into RAG-Optimized formats.\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: Logan Markewich <logan@llamaindex.ai>\n",
      "License-Expression: MIT\n",
      "Location: /Users/ywxiu/Library/Caches/pypoetry/virtualenvs/jasp-multimodal-rag-F1fOabRm-py3.12/lib/python3.12/site-packages\n",
      "Requires: llama-cloud-services\n",
      "Required-by: llama-index-readers-llama-parse\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show llama-parse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2a4a7820",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 19:37:56,058 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id fe1b5ba6-fad2-4a26-9496-2c91cc1bdb04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 19:37:57,359 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fe1b5ba6-fad2-4a26-9496-2c91cc1bdb04 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:37:59,548 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fe1b5ba6-fad2-4a26-9496-2c91cc1bdb04 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:38:02,780 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fe1b5ba6-fad2-4a26-9496-2c91cc1bdb04 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:38:07,119 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fe1b5ba6-fad2-4a26-9496-2c91cc1bdb04 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:38:14,932 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fe1b5ba6-fad2-4a26-9496-2c91cc1bdb04 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:38:20,480 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fe1b5ba6-fad2-4a26-9496-2c91cc1bdb04 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:38:25,871 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fe1b5ba6-fad2-4a26-9496-2c91cc1bdb04 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:38:31,379 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fe1b5ba6-fad2-4a26-9496-2c91cc1bdb04 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:38:36,901 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fe1b5ba6-fad2-4a26-9496-2c91cc1bdb04 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:38:42,340 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fe1b5ba6-fad2-4a26-9496-2c91cc1bdb04 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 19:38:47,854 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fe1b5ba6-fad2-4a26-9496-2c91cc1bdb04 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:38:53,264 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fe1b5ba6-fad2-4a26-9496-2c91cc1bdb04 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:38:58,715 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fe1b5ba6-fad2-4a26-9496-2c91cc1bdb04 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:39:07,410 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fe1b5ba6-fad2-4a26-9496-2c91cc1bdb04 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:39:12,853 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fe1b5ba6-fad2-4a26-9496-2c91cc1bdb04 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:39:18,272 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fe1b5ba6-fad2-4a26-9496-2c91cc1bdb04 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:39:23,713 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fe1b5ba6-fad2-4a26-9496-2c91cc1bdb04 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:39:29,134 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fe1b5ba6-fad2-4a26-9496-2c91cc1bdb04 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:39:34,597 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fe1b5ba6-fad2-4a26-9496-2c91cc1bdb04 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:39:40,025 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fe1b5ba6-fad2-4a26-9496-2c91cc1bdb04 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 19:39:45,426 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fe1b5ba6-fad2-4a26-9496-2c91cc1bdb04 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:39:50,908 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fe1b5ba6-fad2-4a26-9496-2c91cc1bdb04 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:40:01,556 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fe1b5ba6-fad2-4a26-9496-2c91cc1bdb04 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:40:07,539 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fe1b5ba6-fad2-4a26-9496-2c91cc1bdb04 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:40:13,104 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fe1b5ba6-fad2-4a26-9496-2c91cc1bdb04 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:40:18,633 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fe1b5ba6-fad2-4a26-9496-2c91cc1bdb04 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:40:24,033 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fe1b5ba6-fad2-4a26-9496-2c91cc1bdb04 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:40:29,502 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fe1b5ba6-fad2-4a26-9496-2c91cc1bdb04 \"HTTP/1.1 200 OK\"\n",
      "2025-10-23 19:40:29,851 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fe1b5ba6-fad2-4a26-9496-2c91cc1bdb04/result/text \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from llama_parse import LlamaParse\n",
    "\n",
    "parser = LlamaParse(\n",
    "    api_key=\"llx-Hs5ASBbsMgrqi91UgmKJOIR0JdCMilbWWpaWMSTX7n7qcb7x\",\n",
    "    result_type=\"text\",\n",
    "    parse_mode=\"parse_document_with_llm\"\n",
    ")\n",
    "\n",
    "documents_new = parser.load_data(\n",
    "    \"./data/raw/Statistical-Analysis-in-JASP-A-guide-for-students-2025.pdf\",\n",
    "    extra_info={\n",
    "        \"parsing_instruction\": (\n",
    "            \"When you encounter plots in the document, \"\n",
    "            \"insert a clear placeholder in the text like \"\n",
    "            \"[FIGURE_PLACEHOLDER: page{page_number}_fig{index}]. \"\n",
    "            \"Do not describe the image; just insert the marker in the correct position.\"\n",
    "        )\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f0860c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "007d8ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    STATISTICAL ANALYSIS IN JASP\n",
      "\n",
      "    A GUIDE FOR STUDENTS\n",
      "\n",
      "                                JASP 2025\n",
      "\n",
      "    Professor Mark A Goss-Sampson\n",
      "    Professor Mark A Goss-Sampson\n",
      "\n",
      "\n",
      "    7th Edition JASP v0.19.3 2025\n",
      "\n",
      "    Copyright Â© 2025 by Mark A Goss-Sampson.\n",
      "\n",
      "    Licenced as CC BY 4.0\n",
      "\n",
      "    All rights reserved. This book or any portion thereof may not be reproduced or used in any manner\n",
      "    whatsoever without the express written permission of the author except for research, education or\n",
      "    private study.\n",
      "\n",
      "                                                   9  JASP\n",
      "\n",
      "    CONTENTS\n",
      "\n",
      "    PREFACE                                             1\n",
      "    USING THE JASP ENVIRONMENT                          2\n",
      "    DATA HANDLING IN JASP                               8\n",
      "    DATA EDITING IN JASP                               11\n",
      "    JASP ANALYSIS MENU                                 12\n",
      "    DESCRIPTIVE STATISTICS                             15\n",
      "     SPLITTING DATA FILES                              21\n",
      "    DESCRIPTIVE DATA VISUALISATION                     21\n",
      "     BASIC PLOTS                                       21\n",
      "     CUSTOMISABLE PLOTS                                24\n",
      "     EDITING PLOTS                                     28\n",
      "    EXPLORING DATA INTEGRITY                           30\n",
      "    DATA TRANSFORMATION                                38\n",
      "    EFFECT SIZE                                        42\n",
      "    ONE-SAMPLE T-TEST                                  44\n",
      "    BINOMIAL TEST                                      48\n",
      "    MULTINOMIAL TEST                                   51\n",
      "     CHI-SQUARE â€˜GOODNESS-OF-FITâ€™ TEST                 53\n",
      "     MULTINOMIAL AND Î§Â² â€˜GOODNESS-OF-FITâ€™ TEST.        54.\n",
      "    COMPARING TWO INDEPENDENT GROUPS                   56\n",
      "     INDEPENDENT T-TEST                                56\n",
      "     MANN-WITNEY U TEST                                61\n",
      "    COMPARING TWO RELATED GROUPS                       63\n",
      "     PAIRED SAMPLES T-TEST                             63\n",
      "     WILCOXONâ€™S SIGNED RANK TEST                       67\n",
      "    CORRELATION ANALYSIS                               69\n",
      "    REGRESSION                                         75\n",
      "     SIMPLE REGRESSION                                 78\n",
      "     MULTIPLE REGRESSION                               81\n",
      "    LOGISTIC REGRESSION                                88\n",
      "    COMPARING MORE THAN TWO INDEPENDENT GROUPS         93\n",
      "     ANOVA                                             93\n",
      "     KRUSKAL-WALLIS â€“ NON-PARAMETRIC ANOVA            100\n",
      "    COMPARING MORE THAN TWO RELATED GROUPS            103\n",
      "\n",
      "                                                               9         JASP\n",
      "\n",
      "     RMANOVA                                                              103\n",
      "     FRIEDMANâ€™S REPEATED MEASURES ANOVA                                   109\n",
      "    COMPARING INDEPENDENT GROUPS AND THE EFFECTS OF COVARIATES            112\n",
      "     ANCOVA                                                               112\n",
      "    TWO-WAY INDEPENDENT ANOVA                                             120\n",
      "    TWO-WAY REPEATED MEASURES ANOVA                                       128\n",
      "    MIXED FACTOR ANOVA                                                    137\n",
      "    CHI-SQUARE TEST FOR ASSOCIATION                                       145\n",
      "    META-ANALYSIS IN JASP                                                 153\n",
      "     EFFECT SIZE COMPUTATION IN JASP                                      158\n",
      "     RUNNING THE META-ANALYSIS IN JASP                                    159\n",
      "    EXPERIMENTAL DESIGN AND DATA LAYOUT IN EXCEL FOR JASP IMPORT.         164\n",
      "\n",
      "\n",
      "     Independent t-test                                                   164\n",
      "     Paired samples t-test                                                165\n",
      "     Correlation                                                          166\n",
      "     Logistic Regression                                                  168\n",
      "     One-way Independent ANOVA                                            169\n",
      "     One-way repeated measures ANOVA                                      170\n",
      "     Two-way Independent ANOVA                                            171\n",
      "     Two-way Repeated measures ANOVA                                      172\n",
      "     Two-way Mixed Factor ANOVA                                           173\n",
      "     Chi-squared - Contingency tables                                     174\n",
      "    SOME CONCEPTS IN FREQUENTIST STATISTICS                               175\n",
      "    WHICH TEST SHOULD I USE?                                              179\n",
      "     Comparing one sample to a known or hypothesized population mean.     179\n",
      "     Testing relationships between two or more variables                  179\n",
      "     Predicting outcomes                                                  180\n",
      "     Testing for differences between two independent groups               180\n",
      "     Testing for differences between two related groups                   181\n",
      "     Testing for differences between three or more independent groups     181\n",
      "     Testing for differences between three or more related groups         182\n",
      "     Test for interactions between 2 or more independent variables        182\n",
      "\n",
      "\n",
      "    PREFACE\n",
      "\n",
      "    JASP stands for Jeffreyâ€™s Amazing Statistics Program in recognition of the pioneer of Bayesian\n",
      "    inference Sir Harold Jeffreys. This is a free multi-platform open-source statistics package, developed\n",
      "    and continually updated by a group of researchers at the University of Amsterdam. They aimed to\n",
      "    develop a free, open-source programme that includes both standard and more advanced statistical\n",
      "    techniques with a major emphasis on providing a simple intuitive user interface.\n",
      "\n",
      "    In contrast to many statistical packages, JASP provides a simple drag-and-drop interface, easy access\n",
      "    menus, intuitive analysis with real-time computation and display of all results. All tables and graphs\n",
      "    are presented in APA format and can be copied directly and/or saved independently. Tables can also\n",
      "    be exported from JASP in LaTeX format\n",
      "\n",
      "    JASP can be downloaded free from the website https://jasp-stats.org/ and is available for Windows,\n",
      "    Mac OS X and Linux. You can also download a pre-installed Windows version that will run directly from\n",
      "    a USB or external hard drive without the need to install it locally. The WIX installer for Windows\n",
      "    enables you to choose a path for the installation of JASP â€“ however, this may be blocked in some\n",
      "    institutions by local Administrative rights.\n",
      "\n",
      "    The programme also includes a data library with an initial collection of over 50 datasets from Andy\n",
      "    Fields' book, Discovering Statistics using IBM SPSS statisticsÂ¹ and The Introduction to the Practice of\n",
      "    StatisticsÂ² by Moore, McCabe and Craig.\n",
      "\n",
      "    Keep an eye on the JASP site since there are regular updates as well as helpful videos and blog posts!!\n",
      "\n",
      "    This book is a collection of standalone handouts covering the most common standard (frequentist)\n",
      "    statistical analyses used by students studying Human Sciences. Datasets used in this document are\n",
      "    available for download from https://osf.io/bx6uv/\n",
      "\n",
      "    I would also like to thank Per Palmgren from the Karolinska Institutet in Sweden for his helpful\n",
      "    comments, suggestions and proofreading of the original guide.\n",
      "\n",
      "    Professor Mark Goss-Sampson\n",
      "    Centre for Exercise Activity and Rehabilitation\n",
      "    University of Greenwich\n",
      "    2025\n",
      "\n",
      "    1 A Field. (2017) Discovering Statistics Using IBM SPSS Statistics (5th Ed.) SAGE Publications.\n",
      "    2 D Moore, G McCabe, B Craig. (2011) Introduction to the Practice of Statistics (7th Ed.) W H Freeman.\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "                                                                                                   1 | P a g e\n",
      "\n",
      "\n",
      "    USING THE JASP ENVIRONMENT\n",
      "    Open JASP.\n",
      "\n",
      "    JASP                                                                     Ã—\n",
      "\n",
      "            New Data  Descriptives  T-Tests  ANOVA  Mixed Models Regression  Frequencies  Factor\n",
      "            IJASP        Welcome to JASP                                                        JASP 0.19.3\n",
      "\n",
      "    A Fresh Way to Do Statistics: Free, Friendly, and Flexible\n",
      "\n",
      "                        Free:      JASP is an open-source project with structural support from the University of\n",
      "                                   Amsterdam & others.\n",
      "                        Friendly:  JAsP has an intuitive interface that was designed with the user in mind.\n",
      "                        Flexible:  JAsP offers standard analysis procedures in both their classical and\n",
      "                                   Bayesian manifestations.\n",
      "                                              So open a data file and take JASP for a spin!\n",
      "\n",
      "                                             JASP is supported by the following institutions:\n",
      "                                   The College of Arts and Sciences and the Department of Statistics at\n",
      "                                                           Texas A&M University\n",
      "    Report bugs                             Suggest your institution joins the JASP Community     Ask a question\n",
      "    Request features                                                                           Visit the website\n",
      "\n",
      "    The main menu can be accessed by clicking on the top-left icon.\n",
      "\n",
      "     Open               >     Recent Files          Open:\n",
      "                                                    JASP has its own .jasp format but can open a variety of\n",
      "     Save                    Computer         >     different dataset formats, such as:\n",
      "                                                    .xls/xlsx (Excel files)\n",
      "     Save As            >                           .csv (comma-separated values) can be saved in Excel\n",
      "                              OSF             >     .txt (plain text) can also be saved in Excel\n",
      "     Export Results     >                           .tsv (tab-separated values) can also be saved in Excel\n",
      "                              Data Library    -     .sav (IBM SPSS data file)\n",
      "     Export Data        >                           .ods (Open Document spreadsheet)\n",
      "                                                    .dta (Stata data file)\n",
      "\n",
      "     Sync Data          >                           .por (SPSS ASCII file)\n",
      "                                                    .Sas7bdat /cat (SAS data files)\n",
      "                                                    .xpt (SAS transport file)\n",
      "     Close\n",
      "\n",
      "     Preferences        >                                Data Sets (*.jasp *.csv *.txt *.sav\n",
      "\n",
      "     About                                               Open                          Cancel\n",
      "\n",
      "    You can open recent files, browse your computer files, access the Open Science Framework (OSF) or\n",
      "    open the wide range of examples that are packaged with the Data Library in JASP.\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "                                                                                                2 | P a g e\n",
      "\n",
      "\n",
      "     Save/Save as:\n",
      "\n",
      "    Open               >                        Using these options for the data file, any annotations and the analysis\n",
      "                            Computer     >      can be saved in the .jasp format\n",
      "\n",
      "    Save                    OSF          >      Export:\n",
      "\n",
      "    Save As            >                        Results can be exported to either an HTML file or a PDF file\n",
      "                                                Data can be exported to either a .csv, .tsv or .txt file\n",
      "    Export Results     >\n",
      "                                                Sync data:\n",
      "    Export Data                                 Used to synchronise with any updates in the current data file (also\n",
      "\n",
      "    Sync Data          >                        can use Ctrl-Y)\n",
      "                                                Close:\n",
      "    Close                                       As it states, it closes the current file but not JASP.\n",
      "\n",
      "    Preferences        >\n",
      "\n",
      "    About\n",
      "\n",
      "     Preferences:\n",
      "\n",
      "     There are four sections that users can use to tweak JASP to suit their needs\n",
      "\n",
      "     In the Data Preferences section, users can:\n",
      "\n",
      "               â€¢      Set the default spreadsheet editor (i.e. Excel, SPSS, etc.)\n",
      "               â€¢      Change the threshold so that JASP more readily distinguishes between nominal and scale data.\n",
      "               â€¢      Add a custom missing value code.\n",
      "\n",
      "                                         Data Preferences\n",
      "\n",
      "                                         External spreadsheet editor (for data synchronization)\n",
      "                                              Use default spreadsheet editor\n",
      "                                                 Select custom editor\n",
      "\n",
      "                                         Import settings\n",
      "                                              Order labels by value by default\n",
      "                                              Threshold for Scale -  10       + Reset types of loaded variables\n",
      "                                              Maximum allowed levels for scale when used as nominal/ordinal - 100 +\n",
      "\n",
      "                                         Missing values setting\n",
      "                                              Show missing values as:\n",
      "                                              Missing Value List\n",
      "\n",
      "                                               NA\n",
      "                                               NaN\n",
      "                                               nan\n",
      "\n",
      "                                                Set current workspace with these values\n",
      "                                                         Reset with standard values\n",
      "                                                        Show workspace missing values\n",
      "\n",
      "                                         Windows workaround\n",
      "                                              Assume CSV is the selected codepage, when no BOM is specified.\n",
      "                                              Choose codepage here\n",
      "\n",
      "                                                                                                                   3 | P a g e\n",
      "\n",
      "\n",
      "    In the Results Preferences section, users can:\n",
      "\n",
      "     â€¢     Set JASP to return exact p values, i.e. P=0.00087 rather than P<.001\n",
      "     â€¢     Fix the number of decimals for data in tables â€“ makes tables easier to read/publish\n",
      "     â€¢     Change the pixel resolution of the graph plots\n",
      "     â€¢     Select when copying graphs whether they have a white or transparent background.\n",
      "     â€¢     PDF output settings\n",
      "\n",
      "           Results Preferences\n",
      "\n",
      "            Table options\n",
      "                              Display exact p-values\n",
      "                              Use exponent notation\n",
      "                              Fix the number of decimals    3 +\n",
      "\n",
      "            Plot options\n",
      "            Use PPI of screen in plots: (96)\n",
      "                              Custom PPI:  -        300     +\n",
      "            Image background color\n",
      "                              White\n",
      "            Transparent\n",
      "\n",
      "            PDF Settings\n",
      "            Orientation\n",
      "                              Portrait\n",
      "                              )Landscape\n",
      "            Page size A4\n",
      "\n",
      "            Miscellaneous options\n",
      "                              Show R syntax\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    In the Interface Preferences section, users can now define a user font and pick between two different\n",
      "    themes: a light theme (default) and a dark theme.\n",
      "\n",
      "    The preferred language currently supports 13 languages: English, Spanish, German, Dutch, French,\n",
      "    Indonesian, Japanese, Portuguese, Chinese and Galician.\n",
      "\n",
      "    In this section, there is also the ability to change the system size (zoom) for accessibility and scroll\n",
      "    speeds.\n",
      "\n",
      "    4 | P a g e\n",
      "\n",
      "\n",
      "User Interface Options\n",
      "\n",
      "Fonts\n",
      " Interface:                   default: Segoe UI\n",
      " R, JAGS, or lavaan code: default: Segoe UI\n",
      " Result & help:               default: Segoe UI\n",
      " Use Qt's text rendering\n",
      "Display\n",
      " Descriptive statistics\n",
      " Estimates of effect size\n",
      "       nÂ²  partial nÂ²       âœ“ Ï‰\n",
      " Vovk-Sellke maximum p-ratio\n",
      "\n",
      "Model\n",
      "\n",
      "    Themes                                                       Assumption Checks\n",
      "               Light theme                                       Homogeneity tests\n",
      "                Dark theme                                       Homogeneity corrections\n",
      "\n",
      "    Preferred language                                           None       Brown-Forsythe             Welch\n",
      "     Choose language en - English                                Q-Q plot of residuals\n",
      "     Help us translate or improve JASP in your language\n",
      "\n",
      "    Accessibility options\n",
      "             ALT-Navigation mode                                 Display\n",
      "\n",
      "    Check for updates                                              Descriptive statistics\n",
      "             Daily automatic check for updates & known issues      Estimates of effect size\n",
      "\n",
      "    Miscellaneous options                                               $nÂ²             partial nÂ²2         Ï‰2\n",
      "     Zoom (%):                 - 100     +                         Vovk-Sellke maximum p-ratio\n",
      "     Ribbon scale (%):         - 100     +                       Model\n",
      "\n",
      "     Scroll speed (pix/s):     - 800     +                               Assumption Checks\n",
      "              Safe graphics mode\n",
      "              Disable animations                                 Homogeneity tests\n",
      "              Use native file dialogs                              Homogeneity corrections\n",
      "\n",
      "                                                                  None         Brown-Forsythe               Welch\n",
      "                                                                 Q-Q plot of residuals\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                 Comparison of the dark and light themes in JASP\n",
      "\n",
      "    In the Advanced Preferences section, most users will probably never have to change any of the default\n",
      "    settings.\n",
      "\n",
      "    5 | P a g e\n",
      "\n",
      "\n",
      "    JASP has a streamlined interface to switch between the spreadsheet, analysis and results views.\n",
      "\n",
      "  Descriptive Statistics  Results\n",
      "  Variables  Descriptive Statistics\n",
      "  Injuries\n",
      "  Descriptive Statistics\n",
      "  :  Wales   TongaInjuries  Japan\n",
      "  New Zealand\n",
      "  Valid  11  11  11  11\n",
      "  Missing  0  0  0  0\n",
      "  Mean  4.00  6.91  3.91  2.91\n",
      "  Std. Deviation  1.18  1.14  1.81  1.76\n",
      "  Minimum  2.00  5.00  2.00  0.00\n",
      "  Maximum  6.00  9.00  7.00  6.00\n",
      "\n",
      "  Boxplots\n",
      "  Split  Injuries\n",
      "  Opponent  10\n",
      "  Frequency tables (nominal and ordinal variables)  8\n",
      "  Plots\n",
      "  Distribution plots  20â¶\n",
      "  Display density  4\n",
      "  Correlation plots\n",
      "  Boxplots  2\n",
      "  Label Outliers\n",
      "  :  Color  :  0\n",
      "  Boxplot element  Wales  Tonga  New Zealand  Japan\n",
      "  Violin element  Opponent\n",
      "  Jitter element\n",
      "  Statistics\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    The vertical bars highlighted above allow for the windows to be dragged right or left by clicking and\n",
      "    dragging the three vertical dots.\n",
      "\n",
      "    The individual windows can also be completely collapsed using the right or left arrow icons.\n",
      "\n",
      "    If you click the Results  icon, a range of options is provided, including:\n",
      "\n",
      "     â€¢     Edit title\n",
      "     â€¢     Copy\n",
      "     â€¢     Export results\n",
      "     â€¢     Add notes\n",
      "     â€¢     Remove all\n",
      "     â€¢     Refresh all\n",
      "\n",
      "    The â€˜add notesâ€™ option allows the results output to be easily annotated and then exported to an HTML\n",
      "    or PDF file by going to File > Export Results.\n",
      "\n",
      "    6 | P a g e\n",
      "\n",
      "\n",
      "    ANOVA - Number of England Injuries\n",
      "     Cases           Sum of Squares   df      Mean Square  F  p\n",
      "     Country code     97.09              3    32.364       13.23  <.001\n",
      "     Residual         97.82             40    2.445\n",
      "    Note. Type III Sum of Squares\n",
      "\n",
      "    One way ANOVA of injuries received by Enqland rugby players against Tonga, New Zealand, France and Wales\n",
      "\n",
      "    B I U 8 Normal  â€¢ E = A A $x 2 x^}$  \", E E Normal  Ã· Ix\n",
      "\n",
      "    The Add notes menu provides many options to change text font, colour, size, etc.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    You can change the size of all the tables and graphs using Ctrl+ (increase), Ctrl- (decrease), Ctrl=\n",
      "    (back to default size). Graphs can also be resized by dragging the bottom right corner of the graph.\n",
      "\n",
      "    As previously mentioned, all tables and figures are APA standard and can just be copied into any other\n",
      "    document. Since all images can be copied/saved with either a white or transparent background. This\n",
      "    can be selected in Preferences > Advanced as described earlier.\n",
      "\n",
      "    There are many further resources on using JASP on the website https://jasp-stats.org/\n",
      "\n",
      "    7 | P a g e\n",
      "\n",
      "\n",
      "    DATA HANDLING IN JASP\n",
      "    For this section, open England injuries.csv\n",
      "\n",
      "    All files must have a header label in the first row. Once loaded, the dataset appears in the window:\n",
      "\n",
      "           Opponent          Injuries          +\n",
      "    1      Japan                              4\n",
      "    2      Japan                              1\n",
      "    3      Japan                              3\n",
      "    4      Japan                              6\n",
      "    5      Japan                              2\n",
      "    6      Japan                              3\n",
      "    7      Japan                              4\n",
      "    8      Japan                              0\n",
      "    9      Japan                              5\n",
      "    10     Japan                              2\n",
      "    11     Japan                              2\n",
      "    12        New Zealand                     2\n",
      "    13        New Zealand                     4\n",
      "\n",
      "    For large datasets, there is a hand icon that allows easy scrolling through the data.\n",
      "\n",
      "    On import, JASP makes a best guess at assigning data to the different variable types:\n",
      "\n",
      "    Nominal    Ordinal    Continuous\n",
      "\n",
      "    If JASP has incorrectly identified the data type, just click on the appropriate variable data icon in the\n",
      "    column title to change it to the correct format.\n",
      "\n",
      "                                         Opponent  2 Injuries\n",
      "\n",
      "    2                                    Japan     Scale\n",
      "                                                   Ordinal\n",
      "    3                                    Japan     3 Nominal\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    If you have coded the data, you can click on the variable name to open the following window in which\n",
      "    you can label each code. These labels now replace the codes in the spreadsheet view. If you save this\n",
      "    as a .jasp file, these codes, as well as all analyses and notes, will be saved automatically. This makes\n",
      "    the data analysis fully reproducible.\n",
      "\n",
      "    8 | P a g e\n",
      "\n",
      "\n",
      "    Filter Value     Label\n",
      "   1                 Tonga\n",
      "   2                 New Zealand\n",
      "   3                 France     â†‘â†“\n",
      "           4        Wales\n",
      "\n",
      "                                x\n",
      "\n",
      "    In this window, you can also carry out simple filtering of data, for example, if you untick the Wales\n",
      "    label, it will not be used in subsequent analyses.\n",
      "\n",
      "    Clicking this icon in the spreadsheet window opens up a much more comprehensive set of data\n",
      "    filtering options:\n",
      "\n",
      "  +-*Ã·/^âˆš% = â‰  < â‰¤ > â‰¥  V | -\n",
      "  G...e  lyl\n",
      "  Cou...ode  Ïƒy\n",
      "  Number of... Injuries  $Ïƒ^\n",
      "  âˆ‘y\n",
      "  â…¡y\n",
      "  min(y)\n",
      "  max(y)\n",
      "  mean(y)\n",
      "  round(y)\n",
      "  Welcome to the drag and drop filter!  length(y)\n",
      "  median(y)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Using this option will not be covered in this document. For detailed information on using more\n",
      "    complex filters, refer to the following link: https://jasp-stats.org/2018/06/27/how-to-filter-your-data-\n",
      "    in-jasp/\n",
      "\n",
      "    9 | P a g e\n",
      "\n",
      "\n",
      "    By default, JASP plots data in the Value order (i.e. 1-4). The order can be changed by highlighting the\n",
      "    label and moving it up or down using the appropriate arrows:\n",
      "\n",
      "    Filter  Value    Label         Move up\n",
      "            1        Tonga         Move down\n",
      "            2        New Zealand\n",
      "            3        France    â†‘â†“  Reverse order\n",
      "            4        Wales\n",
      "\n",
      "                               x   Close\n",
      "\n",
      "    Injuries                                        Injuries\n",
      "    10                                                    10\n",
      "\n",
      "    8                                                      8\n",
      "\n",
      "    0 6                                                  20â¶\n",
      "    4                                                      4\n",
      "\n",
      "    2                                                      2\n",
      "\n",
      "    0           Japan  New Zealand  Tonga     Wales        0    Wales   Tonga  New Zealand    Japan\n",
      "\n",
      "                       Opponent                                                  Opponent\n",
      "\n",
      "Filter  Value        Label\n",
      "        Japan        Japan\n",
      "        New Zealand  New Zealand\n",
      "        Tonga       Tonga\n",
      "        Wales        Wales\n",
      "Filter  Value        Label\n",
      "        Wales        Wales\n",
      "        Tonga        Tonga\n",
      "        New Zealand  New Zealand\n",
      "        Japan        Japan\n",
      "\n",
      "    If you need to edit the data in the spreadsheet, just double-click on a cell and the data should open\n",
      "    up in the original spreadsheet, i.e. Excel. Once you have edited your data and saved the original\n",
      "    spreadsheet, JASP will automatically update to reflect the changes that were made, provided that you\n",
      "    have not changed the file name.\n",
      "\n",
      "    10 | P a g e\n",
      "\n",
      "\n",
      "    DATA EDITING IN JASP\n",
      "\n",
      "    JASP has its internal data editor, which allows users to either enter new data directly,\n",
      "\n",
      "    I New Data  Descriptives  T-Tests  ANOVA  Mixed Models  Regression  Frequencies         Factor\n",
      "\n",
      "    or to edit existing (external) data.\n",
      "\n",
      "    .\n",
      "    I Edit Data  Descriptives  T-Tests  ANOVA  Mixed Models  Regression Frequencies  Factor\n",
      "\n",
      "    Clicking on this opens a new ribbon allowing the user to add new data directly or edit an\n",
      "    open dataset. If an external dataset has been modified, the Synchronisation option will save\n",
      "    those changes to the dataset directly.\n",
      "\n",
      "    I    R  2 â†’\n",
      "         Analyses  Synchronisation  Resize Data  Insert  Remove  Undo  Redo\n",
      "\n",
      "    Once the editing has been completed, you can return directly to the data analysis interface.\n",
      "\n",
      "    11 | P a g e\n",
      "\n",
      "\n",
      "    JASP ANALYSIS MENU\n",
      "\n",
      "    .\n",
      "    I Edit Data  Descriptives  T-Tests  ANOVA  Mixed Models  Regression  Frequencies  Factor\n",
      "\n",
      "    The main analysis options can be accessed from the main toolbar. Currently, JASP offers the following\n",
      "    frequentist (parametric and non-parametric standard statistics) and alternative Bayesian tests:\n",
      "\n",
      "Descriptives\n",
      " â€¢         Descriptive stats\n",
      " â€¢         Raincloud plots\n",
      " â€¢         Time Series Descriptives\n",
      " â€¢         Flexplot\n",
      "Regression\n",
      " â€¢     Correlation\n",
      " â€¢     Linear regression\n",
      " â€¢     Logistic regression\n",
      " â€¢     Generalised Linear Model*\n",
      "\n",
      "     T-Tests                                       Frequencies\n",
      "      â€¢         Independent                         â€¢     Binomial test\n",
      "      â€¢         Paired                              â€¢     Multinomial test\n",
      "      â€¢         One sample                          â€¢     Contingency tables\n",
      "                                                    â€¢     Log-linear regression*\n",
      "     ANOVA                                         Factor\n",
      "      â€¢         Independent                         â€¢     Principal Component Analysis (PCA)*\n",
      "      â€¢         Repeated measures                   â€¢     Exploratory Factor Analysis (EFA)*\n",
      "      â€¢         ANCOVA                              â€¢     Confirmatory Factor Analysis (CFA)*\n",
      "      â€¢         MANOVA *\n",
      "     Mixed Models*                                 Meta-Analysis\n",
      "      â€¢         Linear Mixed Models                 â€¢     Effect size computation\n",
      "      â€¢         Generalised linear mixed models     â€¢     Meat-Analysis\n",
      "                                                    â€¢     Forest Plots\n",
      "    * Not covered in this guide\n",
      "\n",
      "    BY clicking on the + icon on the top-right menu bar, you can also access advanced options that allow\n",
      "    the addition of optional advanced modules. Once ticked, they will be added to the main analysis\n",
      "    ribbon.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    See the JASP website for more information on these advanced modules.\n",
      "\n",
      "    12 | P a g e\n",
      "\n",
      "\n",
      "    Once you have selected your required analysis, all the possible statistical options appear in the left\n",
      "    window and the output appears in the right window.\n",
      "\n",
      "    JASP provides the ability to rename and â€˜stackâ€™ the results output, thereby organising multiple\n",
      "    analyses.\n",
      "\n",
      "    Descriptive Statistics\n",
      "\n",
      "    ANOVA\n",
      "\n",
      "    Correlation\n",
      "\n",
      "    Descriptive Statistics England injuries\n",
      "\n",
      "    ANOVA 5 countries played\n",
      "\n",
      "    Correlation -Spearmans injury correlation\n",
      "\n",
      "    The individual analyses can be renamed using the pen icon or deleted using the red cross.\n",
      "\n",
      "    Clicking on the analysis in this list will then take you to the appropriate part of the results output\n",
      "    window. They can also be rearranged by dragging and dropping each of the analyses.\n",
      "\n",
      "    The green + icon produces a copy of the chosen analysis.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "     Descriptive Statistics England injuries\n",
      "\n",
      "     ANOVA 5 countries played\n",
      "\n",
      "     Correlation -Spearmans injury correlation\n",
      "\n",
      "     Copy of Correlation -Spearmans injury correlation\n",
      "\n",
      "    The blue information icon provides detailed information on each of the statistical procedures used\n",
      "    and includes a search option.\n",
      "\n",
      "    13 | P a g e\n",
      "\n",
      "\n",
      "     JASP Help                                                             Ã—\n",
      "\n",
      "     Correlation\n",
      "     The Correlation analysis allows estimation of the population\n",
      "    correlation, as well as testing the null hypothesis that the population\n",
      "    correlation between pairs of variables equals 0. All possible pairs of\n",
      "    the specified variables are analyzed.\n",
      "\n",
      "     Assumptions (Pearson's rho)\n",
      "\n",
      "      Continuous variables.\n",
      "      The data are a random sample from the population.\n",
      "      The pairs of variables follow a bivariate normal distribution\n",
      "      in the population.\n",
      "      The relationship between the pairs of variables is linear.\n",
      "\n",
      "     Assumptions (Spearman's rho & Kendall's tau)\n",
      "\n",
      "     â€¢ Ordinal or continuous variables.\n",
      "     The data are a random sample from the nonulation\n",
      "     \n",
      "\n",
      "\n",
      "\n",
      "    Search for:\n",
      "\n",
      "    14 | P a g e\n",
      "\n",
      "\n",
      "    DESCRIPTIVE STATISTICS\n",
      "    Presentation of all the raw data is very difficult for a reader to visualise or draw any inference from.\n",
      "    Descriptive statistics and related plots are a succinct way of describing and summarising data, but do\n",
      "    not test any hypotheses. Various types of statistics are used to describe data:\n",
      "\n",
      "     â€¢     Measures of central tendency\n",
      "     â€¢     Measures of dispersion\n",
      "     â€¢     Percentile values\n",
      "     â€¢     Measures of distribution\n",
      "     â€¢     Descriptive plots\n",
      "\n",
      "    To explore these measures, load Descriptive data.csv into JASP. Go to Descriptives > Descriptive\n",
      "    statistics and move the Variable data to the Variables box on the right.\n",
      "\n",
      "           Descriptive Statistics\n",
      "\n",
      "           Group                       Variables\n",
      "                                       Variable\n",
      "\n",
      "    Split\n",
      "\n",
      "    Transpose descriptives table\n",
      "\n",
      "    You also have options to change and add tables in this section:\n",
      "\n",
      "    â€¢     Split analyses by a categorical variable (i.e., group)\n",
      "    â€¢     Transpose the main descriptive table (switch columns and rows)\n",
      "\n",
      "    15 | P a g e\n",
      "\n",
      "\n",
      "    The Statistics menu can now be opened to see the various options available.\n",
      "\n",
      "         Statistics\n",
      "    Sample size                                      Quantiles\n",
      "     Valid                                            Quartiles\n",
      "            Missing                                   Cut points for:    equal groups\n",
      "                                                      Percentiles:\n",
      "    Central tendency                                 Distribution\n",
      "     Mode                                             Skewness\n",
      "     Median                                           Kurtosis\n",
      "     Mean                                             Shapiro-Wilk test\n",
      "                                                      Sum\n",
      "    Dispersion\n",
      "     Std. deviation          Coefficient of variation\n",
      "     MAD                     MAD robust\n",
      "     IQR                     Variance\n",
      "     Range                   Minimum\n",
      "     Maximum\n",
      "    Inference                                        Association matrix\n",
      "     S.E. mean                                        Covariance\n",
      "     Confidence interval for mean                     Correlation\n",
      "     Width 95.0         %                            Use Everything\n",
      "     Method T model\n",
      "     Confidence interval for std. deviation\n",
      "     Width 95.0         %\n",
      "                   Analytical (chi-square)\n",
      "     Method\n",
      "     Confidence interval for variance\n",
      "     Width 95.0                 %\n",
      "                   MethodAnalytical (chi-square\n",
      "\n",
      "\n",
      "    CENTRAL TENDENCY.\n",
      "\n",
      "    This can be defined as the tendency for variable values to cluster around a central value. The three\n",
      "    ways of describing this central value are mean, median and mode. If the whole population is\n",
      "    considered, the term population mean / median/mode is used. If a sample/subset of the population\n",
      "    is being analysed, the term sample mean/ median/mode is used. The measures of central tendency\n",
      "    move toward a constant value when the sample size is sufficient to be representative of the\n",
      "    population.\n",
      "\n",
      "    16 | P a g e\n",
      "\n",
      "\n",
      "    Central Tendency                     Descriptive Statistics\n",
      "              Mode                                            Variable\n",
      "              Median                     Valid                     810\n",
      "                                         Missing                     0\n",
      "              Mean                       Mean                    17.71\n",
      "                                         Median                  17.90\n",
      "                                         Mode                    20.00\n",
      "\n",
      "    The mean, M or xÌ… (17.71), is equal to the sum of all the values divided by the number of values in the\n",
      "    dataset, i.e. the average of the values. It is used for describing continuous data. It provides a simple\n",
      "    statistical model of the centre of distribution of the values and is a theoretical estimate of the â€˜typical\n",
      "    valueâ€™. However, it can be influenced heavily by â€˜extremeâ€™ scores.\n",
      "\n",
      "    The median, Mdn (17.9), is the middle value in a dataset that has been ordered from the smallest to\n",
      "    the largest value and is the normal measure used for ordinal or non-parametric continuous data. Less\n",
      "    sensitive to outliers and skewed data\n",
      "\n",
      "    The mode (20.0) is the most frequent value in the dataset and is usually the highest bar in a distribution\n",
      "    histogram.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    DISPERSION\n",
      "\n",
      "                  Descriptive Statistics\n",
      "    Dispersion    Coefficient of variation                                Variable\n",
      "    Std. deviation\n",
      "    MAD           MAD robust                  Valid                            810\n",
      "                                              Missing                            0\n",
      "    IQR           /Variance                   Mean                        17.711\n",
      "    Range         Minimum                     Std. Error of Mean             0.244\n",
      "                                              Std. Deviation                 6.935\n",
      "    Maximum                                   Coefficient of variation       0.392\n",
      "                                              MAD                            4.700\n",
      "    Inference                                 MAD robust                     6.968\n",
      "    S.E. mean                                 IQR                            9.175\n",
      "                                              Variance                      48.100\n",
      "\n",
      "    The standard error of the mean, SE (0.244), is a measure of how far the sample mean of the data is\n",
      "    expected to be from the true population mean. As the size of the sample data grows larger, the SE\n",
      "    decreases compared to S, and the true mean of the population is known with greater specificity.\n",
      "\n",
      "    Standard deviation, S or SD (6.935), is used to quantify the amount of dispersion of data values around\n",
      "    the mean. A low standard deviation indicates that the values are close to the mean, while a high\n",
      "    standard deviation indicates that the values are dispersed over a wider range.\n",
      "\n",
      "    17 | P a g e\n",
      "\n",
      "\n",
      "    The coefficient of variation (0.392) provides the relative dispersion of the data, in contrast to the\n",
      "    standard deviation, which gives the absolute dispersion.\n",
      "\n",
      "    MAD, (4.7) median absolute deviation, a robust measure of the spread of data. It is relatively\n",
      "    unaffected by data that is not normally distributed. Reporting median +/- MAD for data that is not\n",
      "    normally distributed is equivalent to mean +/- SD for normally distributed data.\n",
      "\n",
      "    MAD Robust: (6.968) median absolute deviation of the data points, adjusted by a factor for\n",
      "    asymptotically normal consistency.\n",
      "\n",
      "    IQR (9.175) Interquartile Range is similar to the MAD but is less robust (see Boxplots).\n",
      "\n",
      "    Variance (48.1) is another estimate of how far the data is spread from the mean. It is also the square\n",
      "    of the standard deviation.\n",
      "\n",
      "    Confidence intervals (CI), although not shown in the general Descriptive statistics output, are used in\n",
      "    many other statistical tests. When sampling from a population to get an estimate of the mean,\n",
      "    confidence intervals are a range of values within which you are n% confident the true mean is\n",
      "    included. A 95% CI is, therefore, a range of values that one can be 95% certain contains the true mean\n",
      "    of the population. This is not the same as a range that contains 95% of ALL the values.\n",
      "\n",
      "    For example, in a normal distribution, 95% of the data are expected to be within Â± 1.96 SD of the mean\n",
      "    and 99% within Â± 2.576 SD.\n",
      "\n",
      "    95% CI = M Â± 1.96 * the standard error of the mean.\n",
      "\n",
      "    Based on the data so far, M = 17.71, SE = 0.24; this will be 17.71 Â± (1.96 * 0.24) or 17.71 Â± 0.47.\n",
      "\n",
      "    Therefore, the 95% CI for this dataset is 17.24 - 18.18 and suggests that the true mean is likely to be\n",
      "    within this range 95% of the time\n",
      "\n",
      "\n",
      "    QUARTILES\n",
      "\n",
      "    In the Statistics options, make sure that everything is unticked apart from Quartiles.\n",
      "\n",
      "                                          Descriptive Statistics\n",
      "    Percentile Values                                        Variable\n",
      "    Quartiles                             Valid                   810\n",
      "    Cut points for:      equal groups     Missing                   0\n",
      "    Percentiles:                          25th percentile       13.05\n",
      "                                          50th percentile       17.90\n",
      "                                          75th percentile       22.30\n",
      "\n",
      "    18 | P a g e\n",
      "\n",
      "\n",
      "    Quartiles are where datasets are split into 4 equal quarters, normally based on the rank ordering of\n",
      "    median values. For example, in this dataset\n",
      "\n",
      "    1  1  2  2  3  3  4  4  4  4  5                     5  5  6       7  8  8  9  10  10              10\n",
      "                25%              50%                                     75%\n",
      "\n",
      "    The median value that splits the data by 50% = 50th percentile = 5\n",
      "\n",
      "    The median value of left side = 25th percentile = 3\n",
      "\n",
      "    The median value of right side = 75th percentile = 8\n",
      "\n",
      "    From this, the Interquartile range (IQR) can be calculated, which is the difference between the 75th\n",
      "    and 25th percentiles, i.e. 5. These values are used to construct the descriptive box plots later. The\n",
      "    IQR can also be shown by ticking this option in the Dispersion menu.\n",
      "\n",
      "    DISTRIBUTION\n",
      "\n",
      "                Descriptive Statistics\n",
      "    Distribution                                                        Variable\n",
      "    Skewness\n",
      "    âœ“                          Skewness                                    -0.004\n",
      "    Kurtosis                   Std. Error of Skewness                       0.086\n",
      "         Shapiro-Wilk test     Kurtosis                                    -0.410\n",
      "                               Std. Error of Kurtosis                       0.172\n",
      "    Sum                        Shapiro-Wilk                             0.996\n",
      "                               P-value of Shapiro-Wilk                      0.032\n",
      "                               Sum                                      14346.200\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Skewness describes the shift of the distribution away from a normal distribution. Negative skewness\n",
      "    shows that the mode moves to the right, resulting in a dominant left tail. Positive skewness shows\n",
      "    that the mode moves to the left, resulting in a dominant right tail.\n",
      "\n",
      "    Negative skewness    Positive skewness\n",
      "\n",
      "    19 | P a g e\n",
      "\n",
      "\n",
      "    Kurtosis describes how heavy or light the tails are. Positive kurtosis results in an increase in the\n",
      "    â€œpointinessâ€ of the distribution with heavy (longer) tails, while negative kurtosis exhibits a much more\n",
      "    uniform or flatter distribution with light (shorter) tails.\n",
      "\n",
      "    + kurtosis\n",
      "\n",
      "    Normal\n",
      "\n",
      "          - kurtosis\n",
      "\n",
      "    In the Statistics options, make sure that everything is unticked apart from skewness, kurtosis and the\n",
      "    Shapiro-Wilk test.\n",
      "\n",
      "    We can use the Descriptives output to calculate skewness and kurtosis. For a normal data distribution,\n",
      "    both values should be close to zero. The Shapiro-Wilk test is used to assess whether the data is\n",
      "    significantly different from a normal distribution. (see - Exploring data integrity in JASP for more\n",
      "    details).\n",
      "\n",
      "    INFERENCE\n",
      "\n",
      "    Confidence intervals provide a measure of how the data sample represents the population being\n",
      "    studied. The probability that the confidence interval includes the true mean of the population is\n",
      "    termed the confidence level and is typically set at 95%.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Inference\n",
      "    S.E. mean\n",
      "    âœ“ Confidence interval for mean\n",
      "    Width95.0  %\n",
      "    Method T model\n",
      "    Confidence interval for std. deviation\n",
      "    Width95.0  %\n",
      "             Analytical (chi-square)\n",
      "    Method\n",
      "    âœ“ Confidence interval for variance\n",
      "    Width\n",
      "             95.0  %\n",
      "    Method Analytical (chi-square)\n",
      "\n",
      "    20 | P a g e\n",
      "\n",
      "\n",
      "    SPLITTING DATA FILES\n",
      "    If there is a grouping variable (categorical or ordinal), descriptive statistics and plots can be produced\n",
      "    for each group. Using Descriptive data.csv with the variable data in the Variables box, now add Group\n",
      "    to the Split box.\n",
      "\n",
      "    Variables             Descriptive Statistics\n",
      "             Variable                                                         Variable\n",
      "\n",
      "                                                                            Group 1    Group 2\n",
      "                                                    Mean                     16.021     18.787\n",
      "                                                    Std. Error of Mear        0.362      0.316\n",
      "                                                    Std. Deviation            6.424      7.040\n",
      "                                                    Skewness                  0.200     -0.176\n",
      "                                                    Std. Error of Skewness    0.137      0.110\n",
      "                                                    Kurtosis                 -0.101     -0.397\n",
      "    Split                                           Std. Error of Kurtosis    0.274      0.219\n",
      "                                                    Shapiro-Wilk              0.993      0.993\n",
      "             Group                                  P-value of Shapiro-Wilk   0.119      0.029\n",
      "\n",
      "    DESCRIPTIVE DATA VISUALISATION\n",
      "    JASP produces a comprehensive range of descriptive and analysis-specific plots. These plots will be\n",
      "    explained in their relevant chapters.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    BASIC PLOTS\n",
      "\n",
      "    Firstly, to look at examples of the basic plots, open Descriptive data.csv with the variable data in the\n",
      "    Variables box, go to Plots and tick Distribution plots, Display density, Interval plots, Q-Q plots, and dot\n",
      "    plots.\n",
      "\n",
      "      Basic plots\n",
      "\n",
      "      Distribution plots  Correlation plots                                            Interval plots\n",
      "              Display density                                                          Q-Q plots\n",
      "              Display rug marks                                                        Pie charts\n",
      "     Bin width type                                                                    Dot plots\n",
      "                          Sturges\n",
      "     Number of bins 30\n",
      "\n",
      "    Categorical plots\n",
      "              Pareto plots\n",
      "                 Pareto rule     95.0  %\n",
      "              Likert plots\n",
      "                 Assume all variables share the same levels\n",
      "              Adjustable font size for vertical axis\n",
      "                                        Normal\n",
      "\n",
      "    21 | P a g e\n",
      "\n",
      "\n",
      "    The Distribution plot is based on splitting the data into frequency bins, which are then overlaid with\n",
      "    the distribution curve. As mentioned before, the highest bar is the mode (the most frequent value of\n",
      "    the dataset. In this case, the curve looks approximately symmetrical, suggesting that the data is\n",
      "    approximately normally distributed. The second distribution plot is from another dataset, which\n",
      "    shows that the data is positively skewed.\n",
      "\n",
      "    The dot plot displays the distribution where each dot represents a value. If a value occurs more than\n",
      "    once, the dots are placed one above the other so that the height of the column of dots represents the\n",
      "    frequency for that value.\n",
      "\n",
      "    The interval plot shows a 95% confidence interval for the mean of each variable.\n",
      "\n",
      "    Dot Plots    Interval plots\n",
      "    Variable     Variable\n",
      "                                 18.2\n",
      "\n",
      "                                 18.0\n",
      "\n",
      "                 0 17.8\n",
      "                                 17.6\n",
      "\n",
      "                                 17.4\n",
      "    0            10  20  30  40  17.2\n",
      "\n",
      "\n",
      "    The Q-Q plot (quantile-quantile plot) can be used to visually assess if a set of data comes from a normal\n",
      "    distribution. Q-Q plots take the sample data, sort it in ascending order, and then plot it against\n",
      "    quantiles (percentiles) calculated from a theoretical distribution. If the data is normally distributed,\n",
      "    the points will fall on or close to the 45-degree reference line. If the data is not normally distributed,\n",
      "    the points will deviate from the reference line.\n",
      "\n",
      "                                                    22 | P a g e\n",
      "\n",
      "\n",
      " Q-Q Plot\n",
      " Variable\n",
      "        4\n",
      "\n",
      "    20  2\n",
      "        0\n",
      "\n",
      "    -2\n",
      "\n",
      "    -4\n",
      "      -4  -2  0  2  4\n",
      "    Theoretical Quantiles\n",
      "\n",
      "    Depending on the data sets, basic correlation graphs and pie charts for non-scale data can also be\n",
      "    produced, as can Pareto and Likert plots.\n",
      "\n",
      "\n",
      "    Surface\n",
      "           0/100                             Surface\n",
      "                                             Astroturf\n",
      "\n",
      "           80                                20  Clay\n",
      "                                                 Grass\n",
      "\n",
      "    60    40\n",
      "\n",
      "    23 | P a g e\n",
      "\n",
      "                                                        9                   JASP\n",
      "\n",
      "    CUSTOMISABLE PLOTS\n",
      "\n",
      "    Customizable plots\n",
      "\n",
      "    Color paletteColorblind\n",
      "    Boxplots\n",
      "    Boxplot element             Use color palette\n",
      "    Violin element              Label outliers\n",
      "    Jitter element\n",
      "\n",
      "    Scatter plots\n",
      "    Graph above scatter plot                     Graph right of scatter plot\n",
      "     Density                                     Density\n",
      "     Histogram                                   Histogram\n",
      "     None                                        None\n",
      "    Add regression line                          Show legend\n",
      "      Smooth\n",
      "      Linear\n",
      "      Show confidence interval  95.0          %\n",
      "    Density plots                                Separate densities:\n",
      "\n",
      "    Display density plots\n",
      "    Transparency 20\n",
      "    Tile heatmaps for selected variables    Horizontal axis:\n",
      "\n",
      "                                            Vertical axis:\n",
      "\n",
      "    Display legend\n",
      "    Display value\n",
      "    Relative text size\n",
      "    Width to height ratio of tiles\n",
      "\n",
      "    There are a variety of options depending on your datasets.\n",
      "\n",
      "    The boxplots visualise several statistics described above in one plot:\n",
      "\n",
      "     â€¢     Median value\n",
      "     â€¢     25 and 75% quartiles\n",
      "     â€¢     Interquartile range (IQR) i.e., 75% - 25% quartile values\n",
      "     â€¢     Maximum and minimum values plotted with outliers excluded\n",
      "     â€¢     Outliers are shown if requested\n",
      "\n",
      "    24 | P a g e\n",
      "\n",
      "\n",
      "    Outlier\n",
      "    Maximum value\n",
      "\n",
      "                                                                   Top 25%\n",
      "\n",
      "    75% quartile\n",
      "\n",
      "    Median value                                                   IQR\n",
      "    25% quartile\n",
      "\n",
      "                                                                   Bottom 25%\n",
      "\n",
      "    Minimum value\n",
      "\n",
      "    Go back to the statistics options, in Descriptive plots, tick both Boxplot and Violin Element, and look\n",
      "    at how the plot has changed. Next, tick Boxplot, Violin and Jitter Elements. The Violin plot has taken\n",
      "    the smoothed distribution curve from the Distribution plot, rotated it 90áµ’ and superimposed it on the\n",
      "    boxplot. The jitter plot has further added all the data points.\n",
      "\n",
      "    Boxplot + Violin plot    Boxplot + Violin + Jitter plot\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    If your data is split by group, for example, the boxplots for each group will be shown on the same\n",
      "    graph, and the colours of each will be different if the Colour palette is ticked. 5 colour palettes are\n",
      "    available.\n",
      "\n",
      "    25 | P a g e\n",
      "\n",
      "\n",
      "    Variable        Variable\n",
      "              50                          50\n",
      "              40                          40\n",
      "\n",
      "            0 30                        0 30\n",
      "              20                          20\n",
      "              10                          10\n",
      "               0                           0\n",
      "             -10                         -10\n",
      "                    Group 1    Group 2      Group 1    Group 2\n",
      "\n",
      "                 GGplot2 palette    Viridis palette\n",
      "\n",
      "    Scatter Plots\n",
      "\n",
      "    JASP can produce scatterplots of various types and can include smooth or linear regression lines.\n",
      "    There are also options to add distributions to these, either in the form of density plots or\n",
      "    histograms.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  69\n",
      "  68  o  c  .  69  O  69\n",
      "  67  O  8   O  OO C  68  o 0  68\n",
      "  66  0  O o  67  O  8  OO  67  Â¤\n",
      "  65  O  â€¢o  O  66  C  cO  66  C\n",
      "  64  65  O  oo  65  o  0o\n",
      "  63  C  64  O  O  64  â€¢  O\n",
      "  63  63\n",
      "  75   80  85  90  95  75   80  85  90   95  75 80  85 90 95\n",
      "\n",
      "    26 | P a g e\n",
      "\n",
      "                                   9                                JASP\n",
      "\n",
      "    Tile Heatmap\n",
      "\n",
      "    These plots provide an alternative way of visualising data. For example, using the Titanic survival\n",
      "    dataset to look at the relationship between the class of passage and survival.\n",
      "\n",
      "    Tile Heatmap\n",
      "      name                         $I\\frac{ 2 }$         Horizontal axis:\n",
      "      spouses on board                                              survived\n",
      "      parents with children                              Vertical axis:\n",
      "      embarked                                                      Class\n",
      "\n",
      "     Display legend\n",
      "     Display value\n",
      "     Relative text size\n",
      "     Width to heiqht ratio of tiles\n",
      "     Statistic to plot\n",
      "     For scale variables           For nominal and ordinal variables\n",
      "       Mean                        Mode\n",
      "       Median                      Value itself\n",
      "        Value itself               Number of observations\n",
      "        Number of observations\n",
      "\n",
      "    value\n",
      "\n",
      "    Third  528  181  500\n",
      "                     400\n",
      "\n",
      "    0      158  119  300\n",
      "       Second        200\n",
      "\n",
      "    First   123  200\n",
      "\n",
      "    No  Yes\n",
      "    survived\n",
      "\n",
      "\n",
      "    27 | P a g e\n",
      "\n",
      "\n",
      "    EDITING PLOTS\n",
      "    Clicking on the drop-down menu provided access to a range of options, including Edit Image.\n",
      "    Selecting this option provides some customisation for each graph.\n",
      "\n",
      "    Boxplots\n",
      "    Variable\n",
      "    40      D Copy\n",
      "                 Copy Citations\n",
      "                 5\n",
      "\n",
      "    30           .Save Image As\n",
      "            Edit Image\n",
      "\n",
      "    This will open the plot in a new window, which allows some modifications of each axis in terms of\n",
      "    axis title and range.\n",
      "\n",
      "     x-axis              y-axis\n",
      "\n",
      "     Show title\n",
      "     TitleGroup\n",
      "     Advanced\n",
      "\n",
      "     x-axis       y-axis\n",
      "\n",
      "     Show title\n",
      "     TitleVariable\n",
      "\n",
      "     Show axis\n",
      "     Ticks:    Specify sequence  Set manually\n",
      "     from 0\n",
      "     to      40\n",
      "        steps10\n",
      "\n",
      "    Advanced\n",
      "    Any changes are then updated in the results window. The new plot can be saved as an image or can\n",
      "    be reset to default values.\n",
      "\n",
      "    28 | P a g e\n",
      "\n",
      "\n",
      "    Do not forget that group labels can be changed in the spreadsheet editor.\n",
      "\n",
      "  40\n",
      "      :\n",
      "  30\n",
      "0 20\n",
      "    10\n",
      "\n",
      "    0\n",
      "      Group 1    Group 2\n",
      "                 Group\n",
      "\n",
      "    40\n",
      "    35    :\n",
      "    20 30\n",
      "    25     -\n",
      "    20\n",
      "    15\n",
      "    10\n",
      "    5\n",
      "    0\n",
      "          Drug A    Drug B\n",
      "                    Drug treatment\n",
      "\n",
      "\n",
      "    29 | P a g e\n",
      "\n",
      "\n",
      "    EXPLORING DATA INTEGRITY\n",
      "    Sample data is used to estimate parameters of the population, whereby a parameter is a measurable\n",
      "    characteristic of a population, such as a mean, standard deviation, standard error or confidence\n",
      "    intervals, etc.\n",
      "\n",
      "    What is the difference between a statistic and a parameter? If you randomly polled a selection of\n",
      "    students about the quality of their student bar, you may find that 75% of them were happy with it.\n",
      "    That is a sample statistic since only a sample of the population was asked. You calculated what the\n",
      "    population was likely to do based on the sample. If you asked all the students in the university, and\n",
      "    90% were happy, you have a parameter since you asked the whole university population.\n",
      "\n",
      "    Bias can be defined as the tendency of a measurement to over- or underestimate the value of a\n",
      "    population parameter. Many types of bias can appear in research design and data collection, including:\n",
      "\n",
      "     â€¢     Participant selection bias â€“ some being more likely to be selected for study than others\n",
      "     â€¢     Participant exclusion bias - due to the systematic exclusion of certain individuals from the\n",
      "           study\n",
      "     â€¢     Analytical bias - due to the way that the results are evaluated\n",
      "\n",
      "    However, statistical bias can affect a) parameter estimates, b) standard errors and confidence\n",
      "    intervals or c) test statistics and p values. So, how can we check for bias?\n",
      "\n",
      "    IS YOUR DATA CORRECT?\n",
      "\n",
      "    Outliers are data points that are abnormally outside all other data points. Outliers can be due to a\n",
      "    variety of things, such as errors in data input or analytical errors at the point of data collection Boxplots\n",
      "    are an easy way to visualise such data points where outliers are outside the upper (75% + 1.5 * IQR)\n",
      "    or lower (25% - 1.5 * IQR) quartiles\n",
      "\n",
      "    outlier\n",
      "    Max                             Boxplots show:\n",
      "                                     â€¢     Median value\n",
      "                         Top 25%     â€¢     25 & 75% quartiles\n",
      "                                     â€¢     IQR â€“ Inter quartile range\n",
      "         75% quartile                â€¢     Max & min values plotted\n",
      "                                           with outliers excluded\n",
      "                                     â€¢     Outliers shown if requested\n",
      "\n",
      "               Median    IQR\n",
      "\n",
      "    Min  25% quartile     Bottom\n",
      "                          25%\n",
      "\n",
      "    30 | P a g e\n",
      "\n",
      "\n",
      "    Load Exploring Data.csv into JASP. Under Descriptives > Descriptive Statistics, add Variable 1 to the\n",
      "    Variables box. In Plots, tick the following: Boxplots, Label Outliers, and BoxPlot Element.\n",
      "\n",
      "    Descriptive Statistics\n",
      "\n",
      "     Group         $\\frac{ 2 }$    Variables\n",
      "     Variable 2                    Variable 1\n",
      "     Variable 3\n",
      "\n",
      "    Split\n",
      "\n",
      "    Customizable plots\n",
      "    Color palette Colorblind\n",
      "    Boxplots\n",
      "    Boxplot element         Use color palette\n",
      "    Violin element          Label outliers\n",
      "    Jitter element\n",
      "\n",
      "    1200    1050\n",
      "\n",
      "    1000    1000\n",
      "     800     950\n",
      "\n",
      "     600     900\n",
      "     400     850\n",
      "             800\n",
      "     200     750\n",
      "\n",
      "             700\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "    The resulting Boxplot on the left looks very compressed, and an obvious outlier is labelled as being in\n",
      "    row 38 of the dataset. This can be traced back to a data input error in which 91.7 was input instead of\n",
      "    917. The graph on the right shows the BoxPlot for the â€˜cleanâ€™ data.\n",
      "\n",
      "    31 | P a g e\n",
      "\n",
      "\n",
      "    How you deal with an outlier depends on the cause. Most parametric tests are highly sensitive to\n",
      "    outliers, while non-parametric tests are generally not.\n",
      "\n",
      "    Correct it? â€“ Check the original data to make sure that it isnâ€™t an input error; if it is, correct it, and rerun\n",
      "    the analysis.\n",
      "\n",
      "    Keep it? - Even in datasets of normally distributed data, outliers may be expected for large sample\n",
      "    sizes and should not automatically be discarded if that is the case.\n",
      "\n",
      "    Delete it? â€“ This is a controversial practice in small datasets where a normal distribution cannot be\n",
      "    assumed. Outliers resulting from an instrument reading error may be excluded, but they should be\n",
      "    verified first.\n",
      "\n",
      "    Replace it? â€“ Also known as winsorizing. This technique replaces the outlier values with the relevant\n",
      "    maximum and/or minimum values found after excluding the outlier.\n",
      "\n",
      "    Whatever method you use must be justified in your statistical methodology and subsequent analysis.\n",
      "\n",
      "    WE MAKE MANY ASSUMPTIONS ABOUT OUR DATA.\n",
      "\n",
      "    When using parametric tests, we make a series of assumptions about our data and bias will occur if\n",
      "    these assumptions are violated:\n",
      "\n",
      "     â€¢     Normality\n",
      "     â€¢     Homogeneity of variance or homoscedasticity\n",
      "\n",
      "    Many statistical tests are an omnibus of tests, of which some will check these assumptions.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    TESTING THE ASSUMPTION OF NORMALITY\n",
      "\n",
      "    Normality does not necessarily mean that the data is normally distributed per se, but it is whether or\n",
      "    not the dataset can be modelled by a normal distribution. Normality can be explored in a variety of\n",
      "    ways:\n",
      "\n",
      "     â€¢     Numerically\n",
      "     â€¢     Visually / graphically\n",
      "     â€¢     Statistically\n",
      "\n",
      "    Numerically, we can use the Descriptives output to calculate skewness and kurtosis. For a normal data\n",
      "    distribution, both values should be close to zero. To determine the significance of skewness or\n",
      "    kurtosis, we calculate their z-scores by dividing them by their associated standard errors:\n",
      "\n",
      "    Skewness Z =  skewness       Kurtosis Z =  kurtosis\n",
      "                  Skewness standard error      kurtosis standard error\n",
      "    Z score significance:  p<0.05 if z >1.96  p<0.01 if z >2.58       p<0.001 if z >3.29\n",
      "\n",
      "    32 | P a g e\n",
      "\n",
      "\n",
      "     Using Exploring data.csv, go to Descriptives>Descriptive Statistics move Variable 3 to the Variables\n",
      "     box, in the Statistics drop-down menu select Mean, Std Deviation, Skewness and Kurtosis as shown\n",
      "     below with the corresponding output table.\n",
      "\n",
      "         Statistics                                             Descriptive Statistics\n",
      "    Sample size         Quantiles                                                         Variable 3\n",
      "      Valid              Quartiles                              Valid                                  50\n",
      "            Missing      Cut points for:       equal groups     Missing                                 0\n",
      "\n",
      "    Central tendency     Percentiles:                           Mean                                0.893\n",
      "                        Distribution                            Std. Deviation                      0.673\n",
      "      Mode               Skewness                               Skewness                            0.839\n",
      "      Median             Kurtosis                               Std. Error of Skewness              0.337\n",
      "      Mean               Shapiro-Wilk test                      Kurtosis                           -0.407\n",
      "                         Sum                                    Std. Error of Kurtosis              0.662\n",
      "\n",
      "    Neither skewness nor kurtosis is close to 0. The positive skewness suggests that the data is distributed\n",
      "    more on the left (see graphs later), while the negative kurtosis suggests a flat distribution. When\n",
      "    calculating their z-scores, it can be seen that the data is significantly skewed, p<0.05.\n",
      "\n",
      "    Skewness Z = 0.839  =   2.49    Kurtosis Z = -0.407 = 0.614\n",
      "    0.337                           0.662\n",
      "    [As a note of caution, skewness and kurtosis may appear significant in large datasets even though the\n",
      "    distribution is normal.]\n",
      "\n",
      "    Now add Variable 2 to the Variables box, and in Plots, tick Distribution plot. This will show the\n",
      "    following two graphs:\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    33 | P a g e\n",
      "\n",
      "\n",
      "    It is quite easy to visualise that Variable 2 has a symmetrical distribution. Variable 3 is skewed to the\n",
      "    left, as confirmed by the skewness Z score.\n",
      "\n",
      "    Another graphical check for normality is a Q-Q plot. Q-Q plots are available in Descriptives and are\n",
      "    also produced as part of the Assumption Checks used in linear regression and ANOVA. Q-Q plots show\n",
      "    the quantiles of the actual data against those expected for a normal distribution.\n",
      "    If the data are normally distributed, all the points will be close to the diagonal reference line. If the\n",
      "    points â€˜sagâ€™ above or below the line, there is a problem with kurtosis. If the points snake around the\n",
      "    line, then the problem is skewness. Below are Q-Q plots for Variables 2 and 3. Compare these to the\n",
      "    previous distribution plots and the skewness/kurtosis z scores above.\n",
      "\n",
      "       Variable 2                                        Variable 3\n",
      "\n",
      "  The following Q-Q plot scenarios are possible:\n",
      "\n",
      "  Normal  Bimodal distribution\n",
      "\n",
      "  :  o  2052  o  o\n",
      "  1  ,000\n",
      "  5 o  2 0  0\n",
      "  -2  -1  0  1  2  -2  -1  0  2\n",
      "  Light tailed  Left skew\n",
      "  2  o  20â¸\n",
      "  D  o\n",
      "\n",
      "  o  8 o\n",
      "  -2  -1  0  1  2  -2  -1  0  1  2\n",
      "\n",
      "  Heavy tailed  Right skew\n",
      "\n",
      "  5  o  o  20 0  o\n",
      "\n",
      "  0  2\n",
      "  4?  o   o  0 o\n",
      "\n",
      "  -2  -1  0  1  2  -2  -1  0  1  2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    34 | P a g e\n",
      "\n",
      "\n",
      "    The Shapiro-Wilk test is a statistical test used by JASP to check the assumption of normality. It is also\n",
      "    used in the Independent (distribution of the two groups) and Paired (distribution of differences\n",
      "    between pairs) t-tests. The test results in a W value, where small values indicate your sample is not\n",
      "    normally distributed (the null hypothesis that your population is normally distributed, if your values\n",
      "    are under a certain threshold, can, therefore, be rejected).\n",
      "\n",
      "    Distribution          Descriptive Statistics     Variable 2  Variable 3\n",
      "    Skewness              Valid                         50           50\n",
      "    Kurtosis              Missing                        0       0\n",
      "    Shapiro-Wilk test     Shapiro-Wilk               0.982        0.885\n",
      "                          P-value of Shapiro-Wilk    0.650       < .001\n",
      "\n",
      "    In Descriptives, the Shapiro-Wilk test can be selected in the Distribution tests. The Shapiro-Wilk\n",
      "    output table shows no significant deviation in normality for Variable 2 but a significant deviation\n",
      "    (p<.001) for Variable 3.\n",
      "\n",
      "    The most important limitation is that the test can be biased by sample size. The larger the sample, the\n",
      "    more likely youâ€™ll get a statistically significant result.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Testing the assumption of normality â€“ A cautionary note!\n",
      "\n",
      "    For most parametric tests to be reliable, one of the assumptions is that the data is approximately\n",
      "    normally distributed. A normal distribution peaks in the middle and is symmetrical about the mean.\n",
      "    However, data does not need to be perfectly normally distributed for the tests to be reliable.\n",
      "\n",
      "    So, having gone on about testing for normality, is it necessary?\n",
      "\n",
      "    The Central Limit Theorem states that as the sample size gets larger, i.e. >30 data points, the\n",
      "    distribution of the sampling means approaches a normal distribution. So the more data points you\n",
      "    have, the more normal the distribution will look and the closer your sample mean approximates the\n",
      "    population mean.\n",
      "\n",
      "    Large datasets may result in significant tests of normality, i.e. Shapiro-Wilk or significant skewness and\n",
      "    kurtosis z-scores when the distribution graphs look fairly normal. Conversely, small datasets will\n",
      "    reduce the statistical power to detect non-normality.\n",
      "\n",
      "    However, data that does not meet the assumption of normality is going to result in poor results for\n",
      "    certain types of tests (i.e. ones that state that the assumption must be met!). How closely does your\n",
      "    data need to be normally distributed? This is a judgment call best made by eyeballing the data.\n",
      "\n",
      "    35 | P a g e\n",
      "\n",
      "\n",
      "    WHAT DO I DO IF MY DATA IS NOT NORMALLY DISTRIBUTED?\n",
      "\n",
      "    Transform the data and redo the normality checks on the transformed data. Common transformations\n",
      "    include taking the log or square root of the data. Please refer to the next chapter.\n",
      "\n",
      "    Use non-parametric tests since these are distribution-free tests and can be used instead of their\n",
      "    parametric equivalent.\n",
      "\n",
      "    TESTING HOMOGENEITY OF VARIANCE\n",
      "\n",
      "    Leveneâ€™s test is commonly used to test the null hypothesis that variances in different groups are equal.\n",
      "    The result from the test (F) is reported as a p-value; if not significant, then you can say that the null\n",
      "    hypothesis stands â€” that the variances are equal; if the p-value is significant, then the implication is\n",
      "    that the variances are unequal. Leveneâ€™s test is included in the Independent t-test and ANOVA in\n",
      "    JASP as part of the Assumption Checks.\n",
      "\n",
      "    Using Exploring data.csv, go to T-Tests>Independent Samples t-test, move Variable 1 to the Variables\n",
      "    box and Group to the Grouping variable and tick Assumption Checks > Equality of variances.\n",
      "\n",
      "    Independent Samples T-Test\n",
      "\n",
      "    Variable 2    Ifa2}$      Dependent Variables\n",
      "    Variable 3                Variable 1\n",
      "\n",
      "                              Grouping Variable\n",
      "                                    Group\n",
      "\n",
      "    Assumption Checks        Missing Values\n",
      "    Â¸Normality                Exclude cases per dependent variable\n",
      "    Equality of variances     Exclude cases listwise\n",
      "    Brown-Forsythe\n",
      "    Levene's\n",
      "\n",
      "    Test of Equality of Variances (Levene's)\n",
      "    F                 df                    p\n",
      "    Variable 1  0.218  1                    0.643\n",
      "\n",
      "    36 | P a g e\n",
      "\n",
      "\n",
      "    In this case, there is no significant difference in variance between the two groups, F (1) = 0.218, p\n",
      "    =.643.\n",
      "\n",
      "    The assumption of homoscedasticity (equal variance) is important in linear regression models, as is\n",
      "    linearity. It assumes that the variance of the data around the regression line is the same for all\n",
      "    predictor data points. Heteroscedasticity (the violation of homoscedasticity) is present when the\n",
      "    variance differs across the values of an independent variable. This can be visually assessed in linear\n",
      "    regression by plotting actual residuals against predicted residuals.\n",
      "\n",
      "         Plots\n",
      "\n",
      "    Residuals Plots\n",
      "    Residuals vs. dependent\n",
      "    Residuals vs. covariates\n",
      "    Residuals vs. predicted\n",
      "    Residuals vs. histoqram\n",
      "    Standardized residuals\n",
      "    Q-Q plot standardized residuals\n",
      "    Partial plots\n",
      "\n",
      "    If homoscedasticity and linearity are not violated, there should be no relationship between what the\n",
      "    model predicts and its errors, as shown in the graph on the left. Any sort of funnelling (middle graph)\n",
      "    suggests that homoscedasticity has been violated, and any curve (right graph) suggests that linearity\n",
      "    assumptions have not been met.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    No problem                                Heteroscedasticity       Nonlinear\n",
      "\n",
      "                                         O                             3\n",
      "                                                                       2\n",
      "\n",
      "                  o                      A                             0\n",
      "    20  0                         20 2                              20 *\n",
      "        T                                O                             q\n",
      "\n",
      "    Î³             0       s    3\n",
      "\n",
      "       0.0 0.2  0.4    0.6 0.8  1.0    0.0 0.2 0.4 0.6 0.8 1.0    -0.8 -0.6 -0.4 --0.2 0.0 0.2\n",
      "                Fitted                         Fitted                       Fitted\n",
      "\n",
      "    37 | P a g e\n",
      "\n",
      "\n",
      "    DATA TRANSFORMATION\n",
      "    JASP provides the ability to compute new variables or transform data. In some cases, it may\n",
      "    be useful to compute the differences between repeated measures, or, to make a dataset\n",
      "    more normally distributed, you can apply a log transform, for example.\n",
      "\n",
      "    When a dataset is opened, there will be a plus sign (+) at the end of the columns.\n",
      "\n",
      "    SGroup  S                            +\n",
      "             Variable 1  Variable 2  Variable 3\n",
      "\n",
      "    1  1     912         2.78        0.29\n",
      "\n",
      "   2   1     826         4.89        0.55\n",
      "\n",
      "   3   1     1004        6.79        0.47\n",
      "\n",
      "   4   1     982         6.24        1.58\n",
      "\n",
      "   5   1     920         8.59        0.76\n",
      "\n",
      "   6   1     814         5.86        0.76\n",
      "\n",
      "    Clicking on the + opens a small dialogue window where you can;\n",
      "\n",
      "    â€¢  Enter the name of a new variable or the transformed variable\n",
      "    â€¢  Select whether you enter the R code directly or use the commands built into JASP\n",
      "    â€¢  Select what data type is required\n",
      "\n",
      "    Create Computed Column\n",
      "\n",
      "    Name:\n",
      "\n",
      "    Scale  Ordinal  Nominal  Text\n",
      "\n",
      "           Create Column        x\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "    Once you have named the new variable and chosen the other options, click create.\n",
      "\n",
      "    38 | P a g e\n",
      "\n",
      "\n",
      "    If you choose the manual option rather than the R code, this opens all the built-in create and\n",
      "    transform options. Although not obvious, you can scroll the left and right-hand options to see\n",
      "    more variables or more operators, respectively.\n",
      "\n",
      "                    +-*Ã·/^âˆš% = â‰  < â‰¤ > â‰¥  V | -\n",
      "     G...p                                                                      lyl\n",
      "      Var...e 1                                                                               Ïƒy\n",
      "      Var...e 2                                                                 ÏƒÂ²y\n",
      "     Var...e 3                  Computed columns code dear(ed)                  âˆ‘y\n",
      "     Di..-3                                                                                    y\n",
      "      R                                    Compute column            ? x\n",
      "\n",
      "    For example, we want to create a column of data showing the difference between variable 2\n",
      "    and variable 3. Once you have entered the column name in the Create Computed Column\n",
      "    dialogue window, its name will appear in the spreadsheet window. The mathematical\n",
      "    operation now needs to be defined. In this case, drag variable 2 into the equation box, drag\n",
      "    the â€˜minusâ€™ sign down and then drag in variable 3.\n",
      "\n",
      "                                              Diff 2-3\n",
      "                    +-*Ã·/^âˆš% = â‰  < â‰¤ > â‰¥  v | -\n",
      "     G...p          Var..e 2 - Var..e 3                                                      lyl\n",
      "       Var...e 1                                                                              Ïƒy\n",
      "      Var...e 2                                                                               Ïƒ^\n",
      "      Var...e 3                                                                               âˆ‘y\n",
      "      Di...-3                                                                                 Iy\n",
      "      E R                                  Compute column            ? x\n",
      "\n",
      "                 Group  , Variable 1       Variable 2  Variable 3  fxDiff 2-3  +\n",
      "      1       1         912           2.78             0.29\n",
      "      2       1         826           4.89             0.55\n",
      "      3       1         1004          6.79             0.47\n",
      "\n",
      "    If you have made a mistake, i.e. used the wrong variable or operator, remove it by dragging\n",
      "    the item into the dustbin in the bottom right corner.\n",
      "\n",
      "    39 | P a g e\n",
      "\n",
      "\n",
      "    When you are happy with the equation/operation, click â€˜compute columnâ€™ and the data will\n",
      "    be entered.\n",
      "\n",
      "                                                          Diff 2-3\n",
      "                       +-*Ã·/^âˆš%= â‰  < â‰¤ > â‰¥ ^ v | -\n",
      "      G...p              Var...e 2 - Var..e 3                                                               lyl\n",
      "      Var...e 1                                                                                              Ïƒy\n",
      "      Var...e 2                                                                                             $Ïƒ^\n",
      "      Var...e 3                        Computed columns code applied                                        âˆ‘y\n",
      "            Di..-3                                                                                          â…¡y\n",
      "            R                                            Compute column                                  ? x\n",
      "                       Group         Variable 1          Variable 2  , Variable 3    fxDiff 2-3          +\n",
      "       1         1             912                2.78               0.29        2.49\n",
      "       2         1             826                4.89               0.55        4.34\n",
      "       3          1            1004               6.79               0.47        6.32\n",
      "\n",
      "    If you decide that you do not want to keep the derived data, you can remove the column by\n",
      "    clicking the other dustbin icon next to the R.\n",
      "\n",
      "    Another example is to do a log transformation of the data. In the following case, variable 1\n",
      "    has been transformed by scrolling the operators on the left and selecting the log10(y) option.\n",
      "    Replace the â€œyâ€ with the variable that you want to transform, and then click â€˜Compute\n",
      "    columnâ€™. When finished, click the X to close the dialogue.\n",
      "\n",
      "                                          Log10 Variable 1\n",
      "\n",
      "     G...p               +-* Ã· / ^âˆš % =#                     <       â‰¥V                             log(y)\n",
      "     Var...e 1           log10(  Var...e 1)                                                        log2(y)\n",
      "      Var...e 2                                                                                   log10(y)\n",
      "     Var...e 3                                                                                     logb(y)\n",
      "     Log10...ble 1                     Computed columns code applied                                exp(y)\n",
      "            R                                     Compute column                                         ? x\n",
      "                  Group       Variable 1         Variable 2          Variable 3      fxLog10 Variable 1  +\n",
      "       1     1                912                2.78        0.29             2.95999\n",
      "       2     1                826                4.89        0.55             2.91698\n",
      "       3     1                1004               6.79        0.47             3.00173\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    The Export function will also export any new data variables that have been created.\n",
      "\n",
      "                                             40 | P a g e\n",
      "\n",
      "\n",
      "    The two graphs below show the untransformed and the log10-transformed data. The skewed\n",
      "    data has been transformed into a profile with a more normal distribution.\n",
      "\n",
      "    20\n",
      "\n",
      "    0  0.5  1  1.5  2  2.5  3  3.5\n",
      "               day 3\n",
      "               Untransformed\n",
      "\n",
      "    20\n",
      "\n",
      "    -2  -1.5  -1  -0.5  0  0.5  1\n",
      "                  log day 3\n",
      "              Log10 transformed\n",
      "\n",
      "    41 | P a g e\n",
      "\n",
      "\n",
      "    EFFECT SIZE\n",
      "    When performing a hypothesis test on data, we determine the relevant statistic (r, t, F, etc) and p-\n",
      "    value to decide whether to accept or reject the null hypothesis. A small p-value, <0.05 in most\n",
      "    analyses, provides evidence against the null hypothesis, whereas a large p-value >0.05 only means\n",
      "    that there is not enough evidence to reject the null hypothesis. A lower p-value is sometimes\n",
      "    incorrectly interpreted as meaning there is a stronger relationship or difference between variables. So\n",
      "    what is needed is not just null hypothesis testing but also a method of determining precisely how large\n",
      "    the effects seen in the data are.\n",
      "\n",
      "                                     THE\n",
      "                                     SMALL MEDIUM LARGE\n",
      "                                     GANG\n",
      "\n",
      "    An effect size is a statistical measure used to determine the strength of the relationship or difference\n",
      "    between variables. Unlike a p-value, effect sizes can be used to quantitatively compare the results\n",
      "    of different studies.\n",
      "\n",
      "    For example, comparing heights between 11 and 12-year-old children may show that the 12-year-\n",
      "    olds are significantly taller, but it is difficult to visually see a difference, i.e. small effect size.\n",
      "    However, a significant difference in height between 11 and 16-year-old children is obvious (large\n",
      "    effect size).\n",
      "\n",
      "    The effect size is usually measured in three ways:\n",
      "\n",
      "      â€¢       The standardised mean difference\n",
      "      â€¢       correlation coefficient\n",
      "      â€¢       odds ratio\n",
      "\n",
      "    When looking at differences between groups, most techniques are primarily based on the differences\n",
      "    between the means divided by the average standard deviations. The values derived can then be used\n",
      "    to describe the magnitude of the differences. The effect sizes calculated in JASP for t-tests and ANOVA\n",
      "    are shown below:\n",
      "\n",
      "     Test                Measure                       Trivial   Small    Medium   Large\n",
      "\n",
      "     Between means       Cohen's d                     <0.2      0.2               0.8\n",
      "     Parametric          Hedge's g                     <0.2      0.2      0.5      0.8\n",
      "                         Rank -biserial (rB)           <0.1      0.1      0.5\n",
      "     Non-parametric                                                       0.3      0.5\n",
      "     ANOVA               Eta squared (nÂ²)              <0.1      0.1      0.25    0.37\n",
      "                         Partial Eta squared (nÂ²p)     <0.01     0.01     0.06     0.14\n",
      "                         Omega squared (Ï‰Â²)            <0.01     0.01     0.06     0.14\n",
      "\n",
      "    42 | P a g e\n",
      "\n",
      "\n",
      "    When analysing bivariate or multivariate relationships, the effect sizes are the correlation\n",
      "    coefficients:\n",
      "\n",
      "    Test         Measure    Trivial Small Medium Large\n",
      "\n",
      "    Correlation     Correlation coefficient (r)          <0.1     0.1    0.3     0.5\n",
      "                    Spearman's rho                       <0.1     0.1    0.3     0.5\n",
      "                    Kendall's tau                        <0.1     0.1    0.3     0.5\n",
      "    Multiple        Multiple correlation coefficient     <0.1     0.1    0.3    0.5\n",
      "    Regression      (R)\n",
      "\n",
      "    When analysing categorical relationships via contingency tables, i.e. chi-square test, Phi is only used\n",
      "    for 2x2 tables while Cramerâ€™s V and be used for any table size.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Contingency  df        Small   Medium  Large\n",
      "    tables\n",
      "Phi (2x2 only)     1     0.1     0.3     0.5\n",
      "  Cramer's V\n",
      "  Cramer's V       2     0.07    0.21    0.35\n",
      "\n",
      "  Cramer's V       3     0.06    0.17    0.29\n",
      "\n",
      "  Cramer's V       4     0.05    0.15    0.25\n",
      "\n",
      "  Cramer's V       5     0.04    0.13    0.22\n",
      "\n",
      "    For a 2 Ã— 2 contingency table, we can also define the odds ratio measure of effect size.\n",
      "\n",
      "    43 | P a g e\n",
      "\n",
      "                                                   9                     JASP\n",
      "\n",
      "    ONE-SAMPLE T-TEST\n",
      "    Research is normally carried out in sample populations, but how closely does the sample reflect the\n",
      "    whole population? The parametric one-sample t-test determines whether the sample mean is\n",
      "    statistically different from a known or hypothesised population mean.\n",
      "\n",
      "    The null hypothesis (Hâ‚’) tested is that the sample mean is equal to the population mean.\n",
      "\n",
      "    ASSUMPTIONS\n",
      "\n",
      "    Three assumptions are required for a one-sample t-test to provide a valid result:\n",
      "\n",
      "     â€¢     The test variable should be measured on a continuous scale.\n",
      "     â€¢     The test variable data should be independent, i.e. no relationship between any of the data\n",
      "           points.\n",
      "     â€¢     The data should be approximately normally distributed.\n",
      "     â€¢     There should be no significant outliers.\n",
      "\n",
      "    One Sample T-Test\n",
      "\n",
      "    mass             $\\frac{{ 2 }$    Variables\n",
      "    height\n",
      "\n",
      "Tests\n",
      "  Student\n",
      "  Wilcoxon signed-rank\n",
      "  Z Test\n",
      " Test value:\n",
      " Std. deviation:\n",
      "Alternative Hypothesis\n",
      "         # Test value\n",
      "  > Test value\n",
      "         < Test value\n",
      "Assumption checks\n",
      "  Normality\n",
      "         Q-Q plot residuals\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Missing Values\n",
      "         Exclude cases per variable\n",
      "         Exclude cases listwise\n",
      "Additional Statistics\n",
      "     Location estimate\n",
      "      Confidence interval        95.0        %\n",
      "     Effect size\n",
      "      Confidence interval        95.0        %\n",
      "     Descriptives\n",
      "     Vovk-Sellke maximum p-ratio\n",
      "\n",
      "Plots\n",
      "     Descriptives plots\n",
      "     Confidence interval 95.0           %\n",
      "     Raincloud plots\n",
      "      Horizontal display\n",
      "     Bar plots\n",
      "      Confidence interval            95.0    %\n",
      "      Standard error\n",
      "\n",
      "                                                   Fix horizontal axis to 0\n",
      "\n",
      "                                                                                           44 | P a g e\n",
      "\n",
      "                                 9                               JASP\n",
      "\n",
      "    RUNNING THE ONE-SAMPLE T-TEST\n",
      "\n",
      "    Open one sample t-test.csv, which contains two columns of data representing the height (cm) and\n",
      "    body mass (kg) of a sample population of males used in a study. In 2017, the average adult male in the\n",
      "    UK population was 178 cm tall and had a body mass of 83.4 kg.\n",
      "\n",
      "    Go to T-Tests > One-Sample t-test and in the first instance, add height to the analysis box on the right.\n",
      "    Then tick the following options above and add 178 as the test value.\n",
      "\n",
      "    UNDERSTANDING THE OUTPUT\n",
      "\n",
      "    The output should contain three tables and two graphs.\n",
      "\n",
      "    Test of Normality (Shapiro-Wilk)\n",
      "    w                               p\n",
      "    height    0.983                 0.954\n",
      "    Note. Significant results suggest a\n",
      "    deviation from normality.\n",
      "\n",
      "    The assumption check of normality (Shapiro-Wilk) is not significant, suggesting that the heights are\n",
      "    normally distributed; therefore, this assumption is not violated. If this showed a significant difference,\n",
      "    the analysis should be repeated using the non-parametric equivalent, Wilcoxonâ€™s signed-rank test,\n",
      "    tested against the population median height.\n",
      "\n",
      "    One Sample T-Test\n",
      "                     t      df            p     Mean Difference      Cohen's d  SE Cohen's d\n",
      "     height  -0.382         22            0.706                      -0.391  -0.080      0.209\n",
      "     Note. For the Student t-test, effect size is given by Cohen's d.\n",
      "     Note. For the Student t-test, location difference estimate is qiven by the sample mean difference d.\n",
      "     Note. For the Student t-test, the alternative hypothesis specifies that the mean is different from 178.\n",
      "     Note. Student's t-test.\n",
      "\n",
      "    This table shows that there are no significant differences between the means, p =.706\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "             Descriptives\n",
      "                                N         Mean                       SD      SE\n",
      "             height         23.000        177.609                    4.915   1.025\n",
      "\n",
      "    The descriptive data shows that the mean height of the sample population was 177.6 cm compared\n",
      "    to the average of 178 cm for UK males.\n",
      "\n",
      "    45 | P a g e\n",
      "\n",
      "\n",
      "    The two plots show essentially the same data but in different ways. The standard Descriptive plot is\n",
      "    an Interval plot showing the sample mean (black bullet), and the 95% confidence interval (whiskers),\n",
      "    relative to the test value (dashed line).\n",
      "\n",
      "     height\n",
      "     180\n",
      "\n",
      "    178\n",
      "\n",
      "          175\n",
      "    The Raincloud Plot shows the data as individual data points, a box plot, and the distribution plot.\n",
      "    This can be shown as either a vertical or horizontal display.\n",
      "\n",
      "    height\n",
      "     195\n",
      "\n",
      "     190\n",
      "\n",
      "     185\n",
      "    20Â¹â¸â°\n",
      "     175\n",
      "     170\n",
      "     165\n",
      "          height\n",
      "     160\n",
      "\n",
      "    160  165  170 175  180  185  190 195\n",
      "                  height\n",
      "\n",
      "\n",
      "                                        46 | P a g e\n",
      "\n",
      "\n",
      "    Repeat the procedure by replacing height with mass and changing the test value to 83.4.\n",
      "\n",
      "                         Test of Normality (Shapiro-Wilk)\n",
      "                         w                               p\n",
      "                         mass  0.941                     0.185\n",
      "                         Note. Significant results suggest a\n",
      "                         deviation from normality.\n",
      "\n",
      "    The assumption check of normality (Shapiro-Wilk) is not significant, suggesting that the masses are\n",
      "    normally distributed.\n",
      "\n",
      "    One Sample T-Test\n",
      "                     t     df              p         Mean Difference           Cohen's d  SE Cohen's d\n",
      "\n",
      "     mass     -7.159       22              <.001                     -10.487   -1.493     0.303\n",
      "     Note. For the Student t-test, effect size is given by Cohen's d.\n",
      "     Note. For the Student t-test, location difference estimate is given by the sample mean difference d.\n",
      "     Note. For the Student t-test, the alternative hypothesis specifies that the mean is different from 83.4.\n",
      "     Note, Student's t-test\n",
      "\n",
      "    This table shows that there is a significant difference between the mean sample (72.9 kg) and\n",
      "    population body mass (83.4 kg), p <.001\n",
      "\n",
      "              Descriptives\n",
      "                               N           Mean                      SD        SE\n",
      "\n",
      "              mass         23.000          72.913                    7.025     1.465\n",
      "\n",
      "      mass                                           Raincloud Plots\n",
      "      83.6                                           mass\n",
      "\n",
      "    68.0                             50  60  70  80  90  100\n",
      "                                                 mass\n",
      "    \n",
      "\n",
      "    REPORTING THE RESULTS\n",
      "\n",
      "    A one-sample t-test showed no significant difference in height compared to the population mean (t\n",
      "    (22) = -0.382, p .706); however, the participants were significantly lighter than the UK male population\n",
      "    average (t (22) =-7.159, p<.001).\n",
      "\n",
      "    47 | P a g e\n",
      "\n",
      "                                                               9           JASP\n",
      "\n",
      "    BINOMIAL TEST\n",
      "    The binomial test is effectively a non-parametric version of the one-sample t-test for use with\n",
      "    dichotomous (i.e. yes/no) categorical datasets. This tests if the sample frequency is statistically\n",
      "    different from a known or hypothesised population frequency.\n",
      "\n",
      "    The null hypothesis (Hâ‚’) tested is that the sample data frequency is equal to the expected population\n",
      "    frequency.\n",
      "\n",
      "    ASSUMPTIONS\n",
      "    Three assumptions are required for a binomial test to provide a valid result:\n",
      "     â€¢     The test variable should be a dichotomous scale (such as yes/no, male/female, etc.).\n",
      "     â€¢     The sample responses should be independent\n",
      "     â€¢     The sample size is smaller, but representative of the population\n",
      "\n",
      "    RUNNING THE BINOMIAL TEST\n",
      "\n",
      "    Open binomial.csv; this contains one column of data showing the number of students using either a\n",
      "    Windows laptop or a MacBook at university. In January 2021, when comparing just the two operating\n",
      "    systems, the relative UK market share of Windows was 72% and macOS 28%.Â³\n",
      "\n",
      "    Go to Frequencies >Binomial test. Move the Laptop variable to the data window and set the Test value\n",
      "    to 0.72 (72%). Also, tick the Descriptive plots.\n",
      "\n",
      "    Binomial Test\n",
      "\n",
      "                 Variables\n",
      "                 Laptop\n",
      "\n",
      "    Test value: 0.72\n",
      "    Alt. Hypothesis               Additional Statisics\n",
      "         â‰  Test value              Confidence interval\n",
      "         > Test value              Interval95.0       %\n",
      "         < Test value              Vovk-Sellke maximum p-ratio\n",
      "    Plots\n",
      "         Descriptive plots\n",
      "         Confidence interval95.0  %\n",
      "\n",
      "    3https://www.statista.com/statistics/487002/market-share-of-desktop-operating-systems-\n",
      "    uk/#:~:text=Apple%20and%20Microsoft%20own%20a,26.48%20percent%20of%20the%20market.\n",
      "\n",
      "\n",
      "    48 | P a g e\n",
      "\n",
      "                                                       9           JASP\n",
      "\n",
      "    The following table and graph show that the frequencies of both laptops are significantly less than\n",
      "    72%. In particular, students are using significantly fewer Windows laptops than was expected\n",
      "    compared to the UK market share.\n",
      "\n",
      "    Binomial Test\n",
      "       Variable      Level          Counts      Total  Proportion  p\n",
      "    Laptop           Mac            36          90        0.400    < .001\n",
      "                     Windows        54          90        0.600    0.014\n",
      "    Note. Proportions tested against value: 0.72\n",
      "\n",
      "    Laptop\n",
      "              Mac                        Windows\n",
      "\n",
      "              1.00-                         1.00\n",
      "\n",
      "    0.72    0.72\n",
      "\n",
      "    0.00    0.00\n",
      "            Mac    Windows\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Is this the same for MacBook users? Go back to the Options window and change the test value to\n",
      "    0.28 (14%). This time, both frequencies are significantly higher than 28%. This shows that students\n",
      "    are using significantly more MacBooks than was expected compared to the UK market share.\n",
      "\n",
      "Binomial Test\n",
      "   Variable    Level      Counts                 Total      Proportion  p\n",
      "    Laptop     Mac         36                         90     0.400      0.014\n",
      "               Windows     54                         90     0.600      <.001\n",
      "    Note. Proportions tested against value: 0.28.\n",
      "\n",
      "    49 | P a g e\n",
      "\n",
      "\n",
      "    Laptop\n",
      "    Mac    Windows\n",
      "\n",
      "    1.00    1.00\n",
      "\n",
      "    0.28    0.28\n",
      "\n",
      "    0.00    0.00\n",
      "            Mac    Windows\n",
      "\n",
      "    REPORTING THE RESULTS\n",
      "\n",
      "    The UK relative proportion of Windows and MacBook users was reported to be 72% and 28%\n",
      "    respectively. In a cohort of university students (N=90), a Binomial test revealed that the proportion of\n",
      "    students using Windows laptops was significantly less (60%, p=.014) and those using MacBooks\n",
      "    significantly more (40%, p=.014) than expected.\n",
      "\n",
      "    50 | P a g e\n",
      "\n",
      "\n",
      "    MULTINOMIAL TEST\n",
      "    The multinomial test is effectively an extended version of the Binomial test for use with categorical\n",
      "    datasets containing three or more factors. This tests whether or not the sample frequency is\n",
      "    statistically different from a hypothesised population frequency (multinomial test) or a known (Chi-\n",
      "    square â€˜goodness-of-fitâ€™ test).\n",
      "\n",
      "    The null hypothesis (Hâ‚’) tested is that the sample frequency is equal to the expected population\n",
      "    frequency.\n",
      "\n",
      "    ASSUMPTIONS\n",
      "    Three assumptions are required for a multinomial test to provide a valid result:\n",
      "     â€¢     The test variable should be a categorical scale containing 3 or more factors\n",
      "     â€¢     The sample responses should be independent\n",
      "     â€¢     The sample size is smaller, but representative of the population\n",
      "\n",
      "    RUNNING THE MULTINOMIAL TEST\n",
      "\n",
      "    Open multinomial.csv. This contains three columns of data showing the number of different coloured\n",
      "    M&Ms counted in five bags.     Without any prior knowledge, it could be assumed that the different\n",
      "    coloured M&Ms are equally distributed.\n",
      "\n",
      "    Go to Frequencies > Multinomial test. Move the colour of the M&Ms to Factor and the observed\n",
      "    number of M&Ms to counts. Tick Descriptives and Descriptives Plots.\n",
      "\n",
      "    Multinomial Test\n",
      "\n",
      "    Expected        Factor\n",
      "                    Colour\n",
      "                    Counts\n",
      "                    Observed\n",
      "                    Expected Counts\n",
      "\n",
      "    Test Values\n",
      "     Equal proportions (multinomial test)\n",
      "     Expected proportions (xÂ² test)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Additional Statistics                Display\n",
      "      Descriptives                             Counts\n",
      "      Confidence interval    95.0    %         Proportions\n",
      "      Vovk-Sellke maximum p-ratio         Plots\n",
      "                                               Descriptives plot\n",
      "                                               Confidence interval 95.0  %\n",
      "\n",
      "    51 | P a g e\n",
      "\n",
      "\n",
      "    As can be seen in the Descriptive table, the test assumes an equal expectation for the proportions of\n",
      "    coloured M&Ms (36 of each colour). The Multinomial test results show that the observed distribution\n",
      "    is significantly different (p<.001) from an equal distribution.\n",
      "\n",
      "    Multinomial Test\n",
      "                    $xÂ²    df  p\n",
      "    Multinomial     35.932  5  <.001\n",
      "\n",
      "    Descriptives\n",
      "     Colour     Observed  Expected: Multinomial\n",
      "     Blue       31         36\n",
      "    Brown           63     36\n",
      "     Green          43     36\n",
      "     Orange         19     36\n",
      "    Red         41         36\n",
      "    Yellow          22     36\n",
      "\n",
      "    Blue-\n",
      "\n",
      "     Brown -\n",
      "\n",
      "    0 Green-\n",
      "     Orange-\n",
      "\n",
      "        Red-\n",
      "\n",
      "     Yellow-\n",
      "\n",
      "            0            20  40                                 60  80\n",
      "                         Observed counts\n",
      "\n",
      "\n",
      "    REPORTING THE RESULTS\n",
      "\n",
      "    A multinomial test showed that there was a significant difference between the observed\n",
      "    and expected M&M colour distribution: Ï‡2 (5) = 35.9, p<.001.\n",
      "\n",
      "    52 | P a g e\n",
      "\n",
      "\n",
      "    CHI-SQUARE â€˜GOODNESS-OF-FITâ€™ TEST.\n",
      "\n",
      "    However, further research shows that the manufacturer produces coloured M&Ms in different ratios:\n",
      "\n",
      "     Colour         Blue     Brown          Green          Orange      Red     Yellow\n",
      "     Proportion     24       13             16             20          13      14\n",
      "\n",
      "    These values can now be used as the expected counts, so move the Expected variable to the Expected\n",
      "    Counts box. This automatically runs the Ï‡2 â€˜goodness-of-fitâ€™ test, leaving the Hypothesis options\n",
      "    greyed out.\n",
      "\n",
      "    As can be seen in the Descriptives table, JASP has calculated the expected numbers of the different\n",
      "    coloured M&Ms based on the manufacturers' reported production ratio. The results of the test show\n",
      "    that the observed proportions of the different coloured M&Ms are significantly different (Ï‡2 =74.5,\n",
      "    p<.001) from those proportions stated by the manufacturer.\n",
      "\n",
      "                            Multinomial Test\n",
      "                                            xÂ²2      df              p\n",
      "                            Expected        74.535   5           <.001\n",
      "\n",
      "    Descriptives\n",
      "    Colour      Observed  Expected: Expected\n",
      "    Blue      31          52\n",
      "    Brown     63          28\n",
      "    Green     43          35\n",
      "    Orange    19          43\n",
      "    Red       41          28\n",
      "    Yellow    22          30\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   Blue -\n",
      "\n",
      "  Brown -\n",
      "\n",
      "00 Green-\n",
      "   Orange\n",
      "\n",
      "     Red-\n",
      "\n",
      "    Yellow-\n",
      "\n",
      "           0  20  40  60  80\n",
      "              Observed counts\n",
      "\n",
      "    53 | P a g e\n",
      "\n",
      "                                                   9                 JASP\n",
      "\n",
      "    MULTINOMIAL AND Î§Â² â€˜GOODNESS-OF-FITâ€™ TEST.\n",
      "    JASP also provides another option whereby both tests can be run at the same time. Go back to the\n",
      "    Options window and only add Colour to the Factor and Observed to the Counts boxes, and remove\n",
      "    the expected counts if the variable is still there. In Hypotheses, now tick the Ï‡2 test. This will open a\n",
      "    small spreadsheet window showing the colour and Hâ‚’ (a) with each cell having 1 in it. This is assuming\n",
      "    that the proportions of each colour are equal (multinomial test).\n",
      "\n",
      "    In this window, add another column which will automatically be labelled Hâ‚’ (b). The expected\n",
      "    proportions of each colour can now be typed in.\n",
      "\n",
      "               Test Values\n",
      "                   Equal proportions (multinomial test)\n",
      "                   Custom expected proportions (xÂ² test)\n",
      "\n",
      "                     Add Column          Row #         Ho (a)  Ho (b)\n",
      "\n",
      "                   Delete Column         Blue   1            24\n",
      "                                            Brown 1          13\n",
      "                       Reset                Green 1          16\n",
      "\n",
      "                                           Orange 1          20\n",
      "\n",
      "    Now, when the analysis is run, the results of the tests for the two hypotheses are shown. Hâ‚’ (a) is\n",
      "    testing the null hypothesis that the proportions of each colour are equally distributed, while Hâ‚’ (b) is\n",
      "    testing the null hypothesis that the proportions are the same as those expected. As can be seen, both\n",
      "    hypotheses are rejected. Evidence indicates that the       colours of M&M's do not match the\n",
      "    manufacturer's published proportions.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Multinomial Test\n",
      "                    xÂ²      df    p\n",
      "    Ho (a)          35.932  5     <.001\n",
      "    Ho (b)          74.535  5     <.001\n",
      "\n",
      "     Descriptives\n",
      "                          Expected\n",
      "        Colour  Observed  Ho (a)  Ho (b)\n",
      "     Blue      31       36        52\n",
      "     Brown     63       36        28\n",
      "     Green     43       36        35\n",
      "     Orange    19       36        43\n",
      "    Red        41       36        28\n",
      "    Yellow     22       36        30\n",
      "\n",
      "    54 | P a g e\n",
      "\n",
      "\n",
      "    Reporting the results\n",
      "\n",
      "    A Ï‡2 â€˜goodness of fitâ€™ test was carried out to assess the distributions of M&Ms in retail packets. This\n",
      "    showed that firstly, the proportions of each colour are not equally distributed, Ï‡2 (5) = 35.9, p<.001.\n",
      "    Secondly, the distribution of colours was significantly different to the manufacturer's stated\n",
      "    distribution, Ï‡2 (5) = 74.5, p<.001.\n",
      "\n",
      "    55 | P a g e\n",
      "\n",
      "\n",
      "    COMPARING TWO INDEPENDENT GROUPS\n",
      "    INDEPENDENT T-TEST\n",
      "    The parametric independent t-test, also known as Studentâ€™s t-test, is used to determine if there is a\n",
      "    statistical difference between the means of two independent groups. The test requires a continuous\n",
      "    dependent variable (i.e. body mass) and an independent variable comprising 2 groups (i.e. males and\n",
      "    females).\n",
      "\n",
      "    This test produces a t-score, which is a ratio of the differences between the two groups and the\n",
      "    differences within the two groups:\n",
      "\n",
      "                      t =  ð’Žð’†ð’‚ð’ ð’ˆð’“ð’ð’–ð’‘ ðŸ âˆ’ ð’Žð’†ð’‚ð’ ð’ˆð’“ð’ð’–ð’‘ ðŸ\n",
      "                           ð’”ð’•ð’‚ð’ð’…ð’‚ð’“ð’… ð’†ð’“ð’“ð’ð’“ ð’ð’‡ ð’•ð’‰ð’† ð’Žð’†ð’‚ð’ ð’…ð’Šð’‡ð’‡ð’†ð’“ð’†ð’ð’„ð’†ð’”\n",
      "\n",
      "                                                                                                  X = mean\n",
      "\n",
      "             t =           X _1 -X_{2                                                             S = standard deviation\n",
      "                      (S1)2           (S2)2                                                       n = number of data points\n",
      "                           n1         n2\n",
      "\n",
      "    A large t-score indicates that there is a greater difference between groups. The smaller the t-score,\n",
      "    the more similarity there is between groups. A t-score of 5 means that the groups are five times as\n",
      "    different from each other as they are within each other.\n",
      "\n",
      "    The null hypothesis (Hâ‚’) tested is that the population means from the two unrelated groups are\n",
      "    equal.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    ASSUMPTIONS OF THE PARAMETRIC INDEPENDENT T-TEST\n",
      "\n",
      "    Group independence:\n",
      "\n",
      "    Both groups must be independent of each other. Each participant will only provide one data point for\n",
      "    one group. For example, participant 1 can only be in either a male or female group, not both. Repeated\n",
      "    measures are assessed using the Paired t-test.\n",
      "\n",
      "    Normality of the dependent variable:\n",
      "\n",
      "    The dependent variable should also be measured on a continuous scale and be approximately\n",
      "    normally distributed with no significant outliers. This can be checked using the Shapiro-Wilk test. The\n",
      "    t-test is fairly robust, and small deviations from normality are normally acceptable. However, this is\n",
      "    not the case if the group sizes are very different. A rule of thumb is that the ratio between the group\n",
      "    sizes should be <1.5 (i.e. group A = 12 participants and group B = >8 participants).\n",
      "\n",
      "    If normality is violated, you can try transforming your data (for example, log values, square root values)\n",
      "    or, if the group sizes are very different, use the Mann-Whitney U test, which is a non-parametric\n",
      "    equivalent that does not require the assumption of normality (see later).\n",
      "\n",
      "    56 | P a g e\n",
      "\n",
      "\n",
      "    Homogeneity of variance:\n",
      "\n",
      "    The variances of the dependent variable should be equal in each group. This can be tested using\n",
      "    Levene's Test of Equality of Variances.\n",
      "\n",
      "    Unequal variance                       Equal variance\n",
      "\n",
      "    ..    20  20\n",
      "\n",
      "    :\n",
      "    1     2    1  2\n",
      "    If Levene's test is statistically significant, indicating that the group variances are unequal, we can\n",
      "    correct for this violation by using an adjusted t-statistic based on the Welch method.\n",
      "\n",
      "    RUNNING THE INDEPENDENT T-TEST\n",
      "\n",
      "    Open Independent t-test.csv, which contains weight loss on a self-controlled 10-week diet between\n",
      "    men and women. It's good practice to check the Distribution and boxplots in Descriptives to visually\n",
      "    check for distribution and outliers.\n",
      "\n",
      "    Go to T-Tests > Independent Samples t-test and put weight loss in the Dependent variable box and\n",
      "    gender (independent variable) in the Grouping Variable box.\n",
      "\n",
      "    Independent Samples T-Test\n",
      "\n",
      "                                                               Dependent Variables\n",
      "                                                               Weight loss\n",
      "\n",
      "    Grouping Variable\n",
      "    Gender\n",
      "\n",
      "    57 | P a g e\n",
      "\n",
      "\n",
      "    In the analysis window, tick the following options:\n",
      "\n",
      "    Dependent Variables\n",
      "    Weight loss\n",
      "\n",
      "                                                                       Grouping Variable\n",
      "                                                                          Gender\n",
      "\n",
      " Tests\n",
      "          Student\n",
      "          Welch\n",
      "          Mann-Whitney\n",
      "\n",
      " Alternative Hypothesis\n",
      " Group 1 â‰  Group 2\n",
      "          Group 1 > Group 2\n",
      "          Group 1 < Group 2\n",
      "\n",
      " Assumption Checks\n",
      " Normality\n",
      " Equality of variances\n",
      "          Brown-Forsythe\n",
      "          I Levene's\n",
      "          Q-Q plot residuals\n",
      "Missing Values\n",
      "          Exclude cases per dependent variable\n",
      "          Exclude cases listwise\n",
      "Additional Statistics\n",
      "     Location parameter\n",
      "       Confidence interval      95.0   %\n",
      "     Effect size\n",
      "       Cohen's d\n",
      "       Glass' delta\n",
      "       Hedges'g\n",
      "       Confidence interval      95     %\n",
      "     Descriptives\n",
      "     Vovk-Sellke maximum p-ratio\n",
      "Plots\n",
      "     Descriptives plots\n",
      "     Confidence interval95.0         %\n",
      "     Raincloud plots\n",
      "       Horizontal display\n",
      "     Bar plots\n",
      "       Confidence interval        95.0 %\n",
      "       Standard error\n",
      "       Fix horizontal axis to 0\n",
      "\n",
      "    UNDERSTANDING THE OUTPUT\n",
      "\n",
      "    The output should consist of four tables and               three  graphs.     Firstly,     we need to check that the\n",
      "    parametric assumptions required are not violated.\n",
      "\n",
      "                            Test of Normality (Shapiro-Wilk)\n",
      "                                                                       w                p\n",
      "\n",
      "                               Weight loss            Females          0.968            0.282\n",
      "                                                      Males            0.971            0.310\n",
      "                            Note. Significant results suggest a deviation from\n",
      "                            normality.\n",
      "\n",
      "    The Shapiro-Wilk test shows that both groups have normally distributed data; therefore, the\n",
      "    assumption of normality is not violated. If one or both were significant, you should consider using the\n",
      "    non-parametric equivalent Mann-Whitney test.\n",
      "\n",
      "                                                                                 58 | P a g e\n",
      "\n",
      "\n",
      "                                Test of Equality of Variances (Levene's)\n",
      "                                                       F           df            p\n",
      "                                Weight loss            2.278       1    0.135\n",
      "\n",
      "    Leveneâ€™s test shows that there is no difference in             the variance;    therefore, the assumption of\n",
      "    homogeneity of variance is not violated. If Leveneâ€™s test was significant, Welchâ€™s adjusted t-statistic,\n",
      "    degrees of freedom and p-values should be reported.\n",
      "\n",
      "    This table shows the two computed t-statistics (Student and Welch). Remember, the t-statistic is\n",
      "    derived from the mean difference divided by the standard error of the difference. Both show that\n",
      "    there is a significant statistical difference between the two groups (p<.001), and Cohenâ€™s d suggests\n",
      "    that this is a large effect.\n",
      "\n",
      "    Independent Samples T-Test\n",
      "                    Test        Statistic    df           p        Mean Difference  SE Difference  Cohen's d  SE Cohen's d\n",
      "    Weight loss     Student     6.160        85.000       <.001         3.209       0.521          1.322        0.259\n",
      "                    Welch       6.191        84.544       <.001         3.209       0.518          1.325        0.259\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Group Descriptives\n",
      "                  Group   N        Mean       SD        SE\n",
      "    Weight loss  Females     42     6.929     2.242     0.346\n",
      "                 Males       45     3.720     2.588     0.386\n",
      "\n",
      "    2\n",
      "     Females    Males\n",
      "\n",
      "    59 | P a g e\n",
      "\n",
      "\n",
      "    Weight loss\n",
      "       15\n",
      "\n",
      "      10\n",
      "    20 5\n",
      "       0\n",
      "\n",
      "      -5\n",
      "\n",
      "     -10\n",
      "        Females  Males\n",
      "                 Gender\n",
      "\n",
      "Weight loss\n",
      "     8\n",
      "\n",
      "    20â¶\n",
      "     4\n",
      "\n",
      "     2\n",
      "\n",
      "     0\n",
      "                                Females    Males\n",
      "                                           Gender\n",
      "\n",
      "    From the descriptive data and plots (use whichever you want), it can be seen that females had a higher\n",
      "    weight loss than males.\n",
      "\n",
      "    REPORTING THE RESULTS\n",
      "\n",
      "    A Levene test found that the assumption of homogeneity of variance was met: F(1) = 2.28, p=.135. A\n",
      "    Shapiro-Wilk test shows that both groups have normally distributed data: Females (W=0.97, p=.282)\n",
      "    and males (W=0.97, p=0.31). Therefore, an independent sample Student t-test based on equal\n",
      "    variances was carried out. This showed that females lost significantly more weight (M = 6.93, SD =\n",
      "    2.24) over 10 weeks of dieting than males (M =3.72, SD = 2.56): t(85)=6.16, p<.001. Cohenâ€™s d (1.322)\n",
      "    suggests that this is a large effect.\n",
      "\n",
      "    NB if the Levene test is significant, the Welch t-statistic and corrected df should be reported.\n",
      "\n",
      "    60 | P a g e\n",
      "\n",
      "\n",
      "    MANN-WITNEY U TEST\n",
      "    If you find that your data is not normally distributed (such as a significant Shapiro-Wilk test result) or\n",
      "    is ordinal by nature, the equivalent non-parametric independent test is the Mann-Whitney U test.\n",
      "\n",
      "    Open Mann-Whitney pain.csv, which contains subjective pain scores (0-10) with and without ice\n",
      "    therapy. NOTE: Make sure that Treatment is categorical, and the pain score is ordinal. Go to T-Tests >\n",
      "    Independent t-tests, put pain score in the Dependent variable box and use Treatment as the grouping\n",
      "    variable.\n",
      "\n",
      "    In the analysis options, only tick:\n",
      "\n",
      "     âœ“ Mann-Whitney\n",
      "     âœ“ Location parameter\n",
      "     âœ“ Effect size\n",
      "\n",
      "    There is no reason to repeat the assumption checks since Mann-Whitney does not require the\n",
      "    assumption of normality or homogeneity of variance required by parametric tests.\n",
      "\n",
      "    UNDERSTANDING THE OUTPUT\n",
      "\n",
      "    This time, you will only get one table:\n",
      "\n",
      "    Independent Samples T-Test\n",
      "                U             df         p         Hodges-Lehmann Estimate                 Rank-Biserial Correlation  SE Rank-Biserial Correlation\n",
      "    Pain score  207.00                   <.001           3.00                              0.84                       0.21\n",
      "    Note. For the Mann-Whitney test, effect size is qiven by the rank biserial correlation.\n",
      "    Note. Mann-Whitney U test.\n",
      "\n",
      "     The Mann-Whitney U-statistic is highly significant. W=207, p<.001.\n",
      "\n",
      "     The        location      parameter, the      Hodgesâ€“Lehmann      estimate,            is  a  measure             of  the median\n",
      "     difference between the two groups. The rank-biserial correlation (rB) can be considered as an effect\n",
      "     size and is interpreted the same as Pearsonâ€™s r, so 0.84 is a large effect size.\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "     For non-parametric data, you should report median values as your descriptive statistics and use\n",
      "     boxplots instead of line graphs and confidence intervals, SD/SE bars. Go to Descriptive statistics, put\n",
      "     the Pain score into the variable box and split the file by Treatment.\n",
      "\n",
      "     You can alternatively show the Raincloud plots for more information on the differences and\n",
      "     distributions.\n",
      "                                  Descriptive Statistics\n",
      "                                                         Pain score\n",
      "                                                           Control     Ice\n",
      "                                         Median              7.000     3.000\n",
      "                                         Std, Deviation  2.167         1.512\n",
      "                                         MAD                 2.000     1.000\n",
      "                                         IQR                 4.000     1.500\n",
      "\n",
      "    61 | P a g e\n",
      "\n",
      "\n",
      "    Pain score\n",
      "    10\n",
      "\n",
      "        8\n",
      "    20  6\n",
      "        4\n",
      "\n",
      "        2\n",
      "\n",
      "        0\n",
      "              Control    Ice\n",
      "\n",
      "    15\n",
      "\n",
      "20 10\n",
      "    5\n",
      "\n",
      "    0\n",
      "\n",
      "   -5\n",
      "     Control    Ice\n",
      "\n",
      "    REPORTING THE RESULTS\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    A Mann-Whitney test showed that Ice therapy significantly reduces pain scores (Mdn = 3) compared\n",
      "    to the control group (Mdn = 7): W=207, p<.001. The rB= 0.84 suggests that this is a large effect size.\n",
      "\n",
      "    62 | P a g e\n",
      "\n",
      "\n",
      "    COMPARING TWO RELATED GROUPS\n",
      "    PAIRED SAMPLES T-TEST\n",
      "    As with the Independent t-test, there are both parametric and non-parametric options available in\n",
      "    JASP. The parametric paired-samples t-test (also known as the dependent sample t-test or repeated\n",
      "    measures t-test) compares the means between two related groups on the same continuous,\n",
      "    dependent variable. For example, looking at weight loss pre- and post-10 weeks of dieting.\n",
      "\n",
      "    The paired t-statistic = mean of the differences between group pairs\n",
      "                             the standard error of the mean differences\n",
      "\n",
      "    With the paired t-test, the null hypothesis (Hâ‚’) is that the pairwise difference between the two\n",
      "    groups is zero.\n",
      "\n",
      "    ASSUMPTIONS OF THE PARAMETRIC PAIRED SAMPLES T-TEST\n",
      "\n",
      "    Four assumptions are required for a paired t-test to provide a valid result:\n",
      "\n",
      "     â€¢     The dependent variable should be measured on a continuous scale.\n",
      "     â€¢     The independent variable should consist of 2 categorical related/matched groups, i.e. each\n",
      "           participant is matched in both groups.\n",
      "     â€¢     The differences between the matched pairs should be approximately normally distributed.\n",
      "     â€¢     There should be no significant outliers in the differences between the 2 groups.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    RUNNING THE PAIRED SAMPLES T-TEST\n",
      "\n",
      "    Open Paired t-test.csv in JASP. This contains two columns of paired data, pre-diet body mass and post-\n",
      "    weeks of dieting. Go to T-Tests > Paired Samples t-test. Ctrl-click both variables and add them to the\n",
      "    analysis box on the right.\n",
      "\n",
      "    Paired Samples T-Test\n",
      "\n",
      "    Pre diet body mass    $$\\frac{ 2 }$    Variable pairs\n",
      "    Post 4 weeks diet                      Pre diet body mass Post 4 weeks diet\n",
      "\n",
      "    63 | P a g e\n",
      "\n",
      "\n",
      "    In the analysis options, tick the following:\n",
      "\n",
      "    Tests                                            Additional Statistics\n",
      "             Student                                    ) Location parameter\n",
      "             Wilcoxon signed-rank                         Confidence interval     95.0     %\n",
      "                                                          Effect size\n",
      "     Alternative Hypothesis                               Confidence interval     95.0     %\n",
      "             Measure 1 â‰  Measure 2                        Correct for correlation\n",
      "     Measure 1 > Measure 2                              âœ“Descriptives\n",
      "             Measure 1 < Measure 2\n",
      "                                                          Vovk-Sellke maximum p-ratio\n",
      "\n",
      "     Assumption Checks                               Plots\n",
      "     Normality                                          ) Descriptives plots\n",
      "                                                        Â¸\n",
      "     Q-Q plot residuals                                 Confidence interval95.0      %\n",
      "                                                        Raincloud plots\n",
      "                                                        Raincloud difference plots\n",
      "                                                          Horizontal display\n",
      "                                                        Bar plots\n",
      "                                                          Confidence interval     95.0    %\n",
      "                                                          Standard error\n",
      "                                                          Fix horizontal axis to 0\n",
      "\n",
      "    Missing Values\n",
      "             Exclude cases per variable\n",
      "             Exclude cases listwise\n",
      "\n",
      "    UNDERSTANDING THE OUTPUT\n",
      "\n",
      "    The output should consist of three tables and three graphs.\n",
      "\n",
      "                Test of Normality (Shapiro-Wilk)\n",
      "                                                                     w           p\n",
      "                        Pre diet body mass      Post 4 weeks diet    0.975   0.124\n",
      "                Note. Significant results suggest a deviation from normality.\n",
      "\n",
      "    The assumption check of normality (Shapiro-Wilk) is not significant, suggesting that the pairwise\n",
      "    differences are normally distributed; therefore, the assumption is not violated. If this showed a\n",
      "    significant difference,    the analysis   should be repeated   using     the non-parametric equivalent,\n",
      "    Wilcoxonâ€™s signed-rank test.\n",
      "\n",
      "    64 | P a g e\n",
      "\n",
      "\n",
      "    Paired Samples T-Test\n",
      "    Measure 1                     Measure 2         t               df  p         Mean Difference  SE Difference  Cohen's d  SE Cohen's d\n",
      "        Pre diet body mass    Post 4 weeks diet     13.04           77  <.001      3.78            0.29           1.48       0.05\n",
      "    Note, Student's t-test\n",
      "\n",
      "    This shows that there is a significant difference in body mass between the pre- and post-dieting\n",
      "    conditions, with a mean difference (location parameter) of 3.78kg. Cohenâ€™s d states that this is a large\n",
      "    effect.\n",
      "\n",
      "    The descriptive statistics and plot show that there was a reduction in body mass following 4 weeks of\n",
      "    dieting.\n",
      "\n",
      "                 Descriptives\n",
      "                                                           N            Mean       SD              SE\n",
      "                              Pre diet body mass              78        72.526     8.723           0.988\n",
      "                              Post 4 weeks diet               78        68.744     9.009           1.020\n",
      "                              73\n",
      "\n",
      "                   68\n",
      "                     Pre diet body mass  Post 4 weeks diet\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "    The Raincloud plot shows the data for both groups and the distribution of the differences between\n",
      "    the two groups.\n",
      "\n",
      "    65 | P a g e\n",
      "\n",
      "\n",
      "    Pre diet body mass - Post 4 weeks diet\n",
      "    120\n",
      "\n",
      "    100 -\n",
      "\n",
      "     80\n",
      "\n",
      "     60\n",
      "\n",
      "     40\n",
      "     Pre diet body mass Post 4 weeks diet\n",
      "\n",
      "    The Q-Q plot reinforces the fact that the data is normally distributed; the closer to the diagonal line\n",
      "    the points lie, the more normally distributed the data.\n",
      "\n",
      "    Q-Q Plots\n",
      "    Pre diet body mass - Post 4 weeks diet\n",
      "\n",
      "    20  3\n",
      "        2                                 c00\n",
      "\n",
      "        1\n",
      "                                          a\n",
      "        0                                 000\n",
      "\n",
      "       -1    âˆž\n",
      "       -2    O\n",
      "       -3\n",
      "             -3  -2  -1                   0  1  2  3\n",
      "                     Theoretical quantiles\n",
      "\n",
      "    REPORTING THE RESULTS\n",
      "\n",
      "    The Shapiro-Wilk test was not significant, suggesting that the pairwise differences were normally\n",
      "    distributed; therefore, the assumption is not violated: W=0.98, p=.124.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Post-diet body mass was lower (M = 68.7, SD =9.0 kg) than at the start of the diet (M =725, SD = 8.7kg).\n",
      "    This mean difference (M = 3.78, SE = 0.29 kg) was shown to be significant: t (77) =13.04, p<.001.\n",
      "    Cohenâ€™s d (1.48) suggests that this is a large effect.\n",
      "\n",
      "                                                                           66 | P a g e\n",
      "\n",
      "\n",
      "    RUNNING THE NON-PARAMETRIC PAIRED SAMPLES TEST\n",
      "\n",
      "    WILCOXONâ€™S SIGNED RANK TEST\n",
      "\n",
      "    If you find that your data is not normally distributed (significant Shapiro-Wilk test result) or is ordinal\n",
      "    by nature, the equivalent non-parametric independent test is Wilcoxonâ€™s signed-rank test. Open\n",
      "    Wilcoxonâ€™s rank.csv. This has two columns, one with pre-anxiety and post-hypnotherapy anxiety\n",
      "    scores (from 0 - 50). In the dataset view, make sure that both variables are assigned to the ordinal\n",
      "    data type.\n",
      "\n",
      "    Go to T-Tests > Paired Samples t-test and follow the same instructions as above, but now only tick the\n",
      "    following options:\n",
      "\n",
      "    Paired Samples T-Test\n",
      "\n",
      "    Pre diet body mass    $\\frac{ 2 }$    Variable Pairs\n",
      "    Post 4 weeks diet                     Pre diet body mass Post 4 weeks diet\n",
      "\n",
      "    Tests                            Additional Statistics\n",
      "             Student                 Location parameter\n",
      "             Wilcoxon siqned-rank      Confidence interval     95.0  %\n",
      "                                     Effect size\n",
      "                                       Confidence interval     95.0  %\n",
      "\n",
      "    There will be only one table in the output:\n",
      "\n",
      "    Paired Samples T-Test\n",
      "\n",
      "    Paired Samples T-Test\n",
      "     Measure 1           Measure 2  w  Z       df        p          Hodges-Lehmann Estimate  Rank-Biserial Correlation  SE Rank-Biserial Correlation\n",
      "    Pre-anxiety          Post-anxiety  322.000  4.292    <.001                8.000             0.982                   0.225\n",
      "    Note. Wilcoxon signed-rank test.\n",
      "\n",
      "    The Wilcoxon W-statistic is highly significant, p<0.001.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    The location parameter, the Hodgesâ€“Lehmann estimate, is the median difference between the two\n",
      "    groups. The rank-biserial correlation (rB) can be considered as an effect size and is interpreted the\n",
      "    same as Pearsonâ€™s r, so 0.48 is a medium to large effect size.\n",
      "\n",
      "     Effect size                                         Trivial     Small     Medium        Large\n",
      "     Rank -biserial (rB)                                 <0.1        0.1       0.3           0.5\n",
      "\n",
      "    67 | P a g e\n",
      "\n",
      "\n",
      "    For non-parametric data, you should report median values as your descriptive statistics and use\n",
      "    boxplots or Rainbow plots instead of line graphs and confidence intervals, SD/SE bars.\n",
      "\n",
      "    Descriptive Statistics\n",
      "    Pre-anxiety           Post-anxiety\n",
      "    Median  22.000        15.000\n",
      "    MAD     5.000         2.000\n",
      "\n",
      "      35\n",
      "      30\n",
      "      25\n",
      "      20\n",
      "\n",
      "      15\n",
      "      10-\n",
      "\n",
      "      5\n",
      "                         Pre-anxiety                Post-anxiety\n",
      "\n",
      "    Pre diet body mass - Post 4 weeks diet\n",
      "     120\n",
      "     100\n",
      "      80\n",
      "      60\n",
      "      40\n",
      "      Pre diet body mass Post 4 weeks diet\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    REPORTING THE RESULTS\n",
      "\n",
      "    A Wilcoxon signed-rank test showed that hypnotherapy significantly reduces anxiety scores (Mdn =\n",
      "    15) compared to pre-therapy (Mdn =22) scores, W=322, p<.001. The rank-biserial correlation (rB) =\n",
      "    0.982 suggests that this is a large effect size.\n",
      "\n",
      "    68 | P a g e\n",
      "\n",
      "\n",
      "    CORRELATION ANALYSIS\n",
      "    Correlation is a statistical technique that can be used to determine if, and how strongly, pairs of\n",
      "    variables are associated. Correlation is only appropriate for quantifiable data in which numbers are\n",
      "    meaningful, such as continuous or ordinal data. It cannot be used for purely categorical data, for which\n",
      "    we have to use contingency table analysis (see Chi-square analysis in JASP).\n",
      "\n",
      "    Essentially, do different variables co-vary? i.e. are changes in one variable reflected in similar changes\n",
      "    to another variable? If one variable deviates from its mean, does the other variable deviate from its\n",
      "    mean in either the same or opposite direction? This can be assessed by measuring covariance;\n",
      "    however, this is not standardised. For example, we can measure the covariance of two variables that\n",
      "    are measured in meters; however, if we convert the same values to centimetres, we get the same\n",
      "    relationship but with a completely different covariance value.\n",
      "\n",
      "    Covariance = 4.7    Covariance = 470\n",
      "\n",
      "    0.15  0.25  0.35  0.45  15  25  35  45\n",
      "                Meters          Centimeters\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    To overcome this, standardised covariance is used, which is known as Pearsonâ€™s correlation\n",
      "    coefficient (or \"r\"). It ranges from -1.0 to +1.0. The closer r is to +1 or -1, the more closely the two\n",
      "    variables are related. If r is close to 0, there is no relationship. If r is (+), then as one variable increases,\n",
      "    the other also increases. If r is (-), then as one increases, the other decreases (sometimes referred to\n",
      "    as an \"inverse\" correlation).\n",
      "\n",
      "    The correlation coefficient (r) should not be confused with RÂ² (coefficient of determination) or R\n",
      "    (multiple correlation coefficient as used in the regression analysis).\n",
      "\n",
      "    The main assumption in this analysis is that the data have a normal distribution and are linear. This\n",
      "    analysis will not work well with curvilinear relationships.\n",
      "\n",
      "    69 | P a g e\n",
      "\n",
      "\n",
      "    RUNNING CORRELATION\n",
      "\n",
      "    The analysis tests the null hypothesis (Hâ‚€) that there is no association between the two variables.\n",
      "\n",
      "    From the example data, open Jump height correlation.csv, which contains 2 columns of data, jump\n",
      "    height (m) and explosive leg power (W). Firstly, run the Descriptive statistics and check the box plots\n",
      "    for any outliers.\n",
      "\n",
      "    To run the correlation analysis, go to Regression > Correlation. Move the 2 variables to the analysis\n",
      "    box on the right. Tick\n",
      "\n",
      "     âœ“ Pearson,\n",
      "     âœ“ Report significance,\n",
      "     âœ“ Flag significant correlations\n",
      "\n",
      "     Under Plots\n",
      "\n",
      "     âœ“ Scatter plots\n",
      "     âœ“ Heatmap\n",
      "\n",
      "     Correlation\n",
      "                                    Variables\n",
      "                                    Jump height\n",
      "                                    Leg power\n",
      "\n",
      "                                    Condition on\n",
      "\n",
      "    Sample Correlation Coefficient     Additional Options\n",
      "    Pearson's r                             Display pairwise\n",
      "    Spearman's rho                          Report significance\n",
      "    Kendall's tau-b                         Flag significant correlations\n",
      "                                            Confidence intervals\n",
      "                                            Interval95.0  %\n",
      "                                            Vovk-Sellke maximum p-ratio\n",
      "                                            Sample size\n",
      "    Alt. Hypothesis                    Plots\n",
      "    Correlated                              Scatter plots\n",
      "    Correlated positively                    Densities for variables\n",
      "    Correlated negatively                    Statistics\n",
      "                                             Confidence intervals   95.0  %\n",
      "                                             Prediction intervals  95.0   %\n",
      "                                       Heatmap\n",
      "\n",
      "\n",
      "    70 | P a g e\n",
      "\n",
      "\n",
      "    UNDERSTANDING THE OUTPUT\n",
      "\n",
      "    The first table shows the correlation matrix with Pearsonâ€™s r-value and its p-value. This shows a highly\n",
      "    significant correlation (p<.001) with a large r value close to 1 (r= 0.984), and we can reject the null\n",
      "    hypothesis.\n",
      "\n",
      "    Pearson Correlations\n",
      "                                       Jump height  Leg power\n",
      "    Jump height     Pearson's r\n",
      "                    p-value\n",
      "    Leg power       Pearson's r        0.984***\n",
      "                    p-value            <.001\n",
      "    * p < .05, ** p < .01, *** p < .001\n",
      "\n",
      "    For simple correlations like this, it is easier to look at the pairwise table (go back to analysis and tick\n",
      "    the Display pairwise table option. This replaces the correlation matrix in the results, which may be\n",
      "    easier to read.\n",
      "\n",
      "                   Pearson Correlations\n",
      "                                                Pearson's r  p\n",
      "                   Jump height         Leg power  0.984***  <.001\n",
      "                   * p < .05, ** p < .01, *** p < .001\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Pearsonâ€™s r value is an effect size where <0.1 is trivial, 0.1 -0.3 is a small effect, 0.3 â€“ 0.5 is a moderate\n",
      "    effect, and >0.5 is a large effect.\n",
      "\n",
      "    The plot provides a simple visualisation of this strong positive correlation (r = 0.984, p<.001), which is\n",
      "    also highlighted by the heatmap (more relevant when looking at multiple correlations).\n",
      "\n",
      "                                                      Pearson's r heatmap\n",
      "\n",
      "    Leg power    0.984***\n",
      "\n",
      "    gâ€¢    Jump height â€” 0.984***\n",
      "\n",
      "          Junpre\n",
      "          Leyoert\n",
      "\n",
      "                                71 | P a g e\n",
      "\n",
      "\n",
      "    GOING ONE STEP FURTHER.\n",
      "\n",
      "    If you take the correlation coefficient r and square it, you get the coefficient of determination (RÂ²).\n",
      "    This is a statistical measure of the proportion of variance in one variable that is explained by the other\n",
      "    variable. Or:\n",
      "\n",
      "                 RÂ²= Explained variation / Total variation\n",
      "\n",
      "    RÂ² is always between 0 and 100% where:\n",
      "\n",
      "     â€¢     0% indicates that the model explains none of the variability of the response data around its\n",
      "           mean, and\n",
      "     â€¢     100% indicates that the model explains all the variability of the response data around its\n",
      "           mean.\n",
      "\n",
      "    In the example above, r = 0.984, so RÂ² = 0.968. This suggests that jump height accounts for 96.8% of\n",
      "    the variance in explosive leg power.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    REPORTING THE RESULTS\n",
      "\n",
      "    Pearsonâ€™s correlation showed a significant correlation between jump height and leg power (r = 0.984,\n",
      "    p<.001), with jump height accounting for 96.8% of the variance in leg power.\n",
      "\n",
      "    72 | P a g e\n",
      "\n",
      "\n",
      "    RUNNING NON-PARAMETRIC CORRELATION â€“ Spearmanâ€™s and Kendallâ€™s tau\n",
      "\n",
      "    If your data is ordinal or is continuous data that has violated the assumptions required for parametric\n",
      "    testing (normality and/or variance), you need to use the non-parametric alternatives to Pearsonâ€™s\n",
      "    correlation coefficient.\n",
      "\n",
      "    The alternatives are Spearmanâ€™s (rho) or Kendallâ€™s (tau) correlation coefficients. Both are based on\n",
      "    ranking data and are not affected by outliers or normality/variance violations.\n",
      "\n",
      "    Spearman's rho is usually used for ordinal scale data, and Kendall's tau is used in small samples or\n",
      "    when many values with the same score (ties). In most cases, Kendallâ€™s tau and Spearmanâ€™s rank\n",
      "    correlation coefficients are very similar and thus invariably lead to the same inferences.\n",
      "\n",
      "    The effect sizes are the same as Pearsonâ€™s r. The main difference is that rhoÂ² can be used as an\n",
      "    approximate non-parametric coefficient of determination, but the same is not true for Kendallâ€™s tau.\n",
      "\n",
      "    From the example data, open Non-parametric correlation.csv, which contains 2 columns of data, a\n",
      "    creativity score and position in the â€˜Worldâ€™s biggest liarâ€™ competition (thanks to Andy Field).\n",
      "\n",
      "    Run the analysis as before, but now using Spearman and Kendallâ€™s tau-b coefficients instead of\n",
      "    Pearsonâ€™s.\n",
      "                                            7\n",
      "\n",
      "    Sample Correlation Coefficient          6         C C\n",
      "     Pearson's r                        20  5         o  O                         O\n",
      "     Spearman's rho                         4             MM  OO\n",
      "     Kendall's tau-b                        3            C O QCD\n",
      "                                            2             â€¢\n",
      "                                            1            o\n",
      "                                                         00O ammam\n",
      "\n",
      "                                        0e+00\n",
      "                                                 10   20 30   40 50                 60        70\n",
      "                                                          Creativity\n",
      "     Correlation Table\n",
      "                                     Spearman            Kendall\n",
      "                                        rho      p    tau B      p\n",
      "              Creativity    Position  0.373**  0.002  0.300**  0.001\n",
      "     * p < .05, ** p < .01, *** p < .001\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "    REPORTING THE RESULTS\n",
      "\n",
      "    The relationship between creativity scores and final position in the â€˜Worldâ€™s biggest liarâ€™ competition\n",
      "    was assessed. A Spearmanâ€™s correlation test showed a significant relationship: rho = -0.373, p=.002.\n",
      "\n",
      "    73 | P a g e\n",
      "\n",
      "                    9  JASP\n",
      "\n",
      "    NOTE OF CAUTION.\n",
      "\n",
      "    The correlation only gives information on the strength of association. It gives no information on the\n",
      "    direction, i.e. which variable causes the other to change. So, it cannot be used to state that one thing\n",
      "    causes the other. Often, a significant correlation means absolutely nothing and is purely by chance,\n",
      "    especially if you correlate thousands of variables. This can be seen in the following strange\n",
      "    correlations:\n",
      "\n",
      "    Pedestrians killed in a collision with a railway train correlate with rainfall in Missouri:\n",
      "\n",
      "    Pearson Correlations\n",
      "                                       Pearson's r  p\n",
      "    Train Deaths             Rainfall    0.928      <.001\n",
      "\n",
      "                    5\n",
      "                 4.5\n",
      "                   4\n",
      "               0 3.5\n",
      "                   3\n",
      "                 2.5     O\n",
      "                   2\n",
      "                 1.5\n",
      "                        40             60 80 100 120 140\n",
      "                                          Train Deaths\n",
      "\n",
      "\n",
      "    The number of honey-producing bee colonies (1000s) correlates strongly with the marriage rate in\n",
      "    South Carolina (per 1000 marriages)\n",
      "\n",
      "    Pearson Correlations\n",
      "                                                 Pearson's r  p\n",
      "    Honey bees                         Marriage rate  0.938   <.001\n",
      "\n",
      "                           13\n",
      "                           12\n",
      "\n",
      "                    20 11\n",
      "                           10\n",
      "                            9\n",
      "                            8\n",
      "                            7\n",
      "                            6\n",
      "                            5\n",
      "                                       2  2.2  2.4    2.6  2.8  3\n",
      "                                               Honey bees\n",
      "\n",
      "    74 | P a g e\n",
      "\n",
      "\n",
      "    REGRESSION\n",
      "    Whereas correlation tests for associations between variables, regression is the next step commonly\n",
      "    used for predictive analysis, i.e. to predict a dependent outcome variable from one (simple regression)\n",
      "    or more (multiple regression) independent predictor variables.\n",
      "\n",
      "    Regression results in a hypothetical model of the relationship between the outcome and predictor\n",
      "    variable(s). The model used is a linear one defined by the formula;\n",
      "\n",
      "                                           y = c + b*x + Îµ\n",
      "\n",
      "                     â€¢        y = estimated dependent outcome variable score,\n",
      "                     â€¢        c = constant,\n",
      "                     â€¢        b = regression coefficient and\n",
      "                     â€¢        x = score on the independent predictor variable\n",
      "                     â€¢        Îµ = random error component (based on residuals)\n",
      "\n",
      "           Linear regression provides both the constant and regression coefficient(s).\n",
      "\n",
      "    Linear regression makes the following assumptions:\n",
      "\n",
      "     â€¢     Data (1 dependent variable of continuous level, independent variables that are measured\n",
      "           either at the continuous or nominal level, sample size, etc.)\n",
      "     â€¢     Outliers, there should be no significant outliers, high-leverage points or highly influential\n",
      "           points.\n",
      "\n",
      "     â€¢     Linear relationship, there needs to be a linear relationship between (a) the dependent\n",
      "           variable and each of your independent variables, and (b) the dependent variable and the\n",
      "           independent variables collectively.\n",
      "     â€¢     Independence, there should be independence of observations (i.e., independence of\n",
      "           residuals)\n",
      "     â€¢     Normality, a) check that the residuals (errors) are approximately normally distributed; and\n",
      "           b) check that the dependent variable is approximately normally distributed.\n",
      "\n",
      "     â€¢     Equal error variances, data needs to show homoscedasticity of residuals (equal error\n",
      "           variances)\n",
      "     â€¢     Multicollinearity, data must show minimal multicollinearity. This occurs when you have\n",
      "           two or more independent variables that are highly correlated with each other.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Concerning sample sizes, there are many different â€˜rules of thumbâ€™ in the literature, ranging from 10-\n",
      "    15 data points per predictor in the model, i.e. 4 predictor variables will each require between 40 and\n",
      "    60 data points each, to 50 +(8 * number of predictors) for each variable. So, for 4 variables, that would\n",
      "    require 82 data points for each variable. Effectively, the bigger your sample size, the better your\n",
      "    model.\n",
      "\n",
      "    75 | P a g e\n",
      "\n",
      "\n",
      "    SUMS OF SQUARES (Boring, but the basis of evaluating the regression model.)\n",
      "\n",
      "    Most regression analyses will produce the best model available, but how good is it actually, and how\n",
      "    much error is in the model?\n",
      "\n",
      "    This can be determined by looking at â€˜the goodness of fitâ€™ using the sums of squares. This is a measure\n",
      "    of how close the actual data points are to the modelled regression line.\n",
      "\n",
      "    Values above the\n",
      "    line are positive\n",
      "\n",
      "    Values below the\n",
      "    line are negative\n",
      "\n",
      "    The vertical difference between the data points and the predicted regression line is known as the\n",
      "    residuals. These values are squared to remove the negative numbers and then summed to give SSR.\n",
      "    This is effectively the error of the model or the â€˜goodness of fitâ€™, obviously, the smaller the value, the\n",
      "    less error in the model.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    I\n",
      "\n",
      "    76 | P a g e\n",
      "\n",
      "\n",
      "    The vertical difference between the data points and the mean of the outcome variable can be\n",
      "    calculated. These values are squared to remove the negative numbers and then summed to give the\n",
      "    total sum of the squares, SST. This shows how good the mean value is as a model of the outcome\n",
      "    scores.\n",
      "\n",
      "    The vertical difference between the mean of the outcome variable and the predicted regression line\n",
      "    is now determined. Again, these values are squared to remove the negative numbers and then\n",
      "    summed to give the model sum of squares (SSM). This indicates how better the model is compared to\n",
      "    just using the mean of the outcome variable. SST is the total sum of the squares.\n",
      "\n",
      "    So, the larger the SSM, the better the model is at predicting the outcome compared to the mean value\n",
      "    alone. If this is accompanied by a small SSR, the model also has a small error.\n",
      "\n",
      "    RÂ² is similar to the coefficient of determination in correlation in that it shows how much of the\n",
      "    variation in the outcome variable can be predicted by the predictor variable(s).\n",
      "\n",
      "       RÂ² =     SSM\n",
      "                SST\n",
      "\n",
      "    In regression, the model is assessed by the F statistic based on the improvement in the prediction of\n",
      "    the model SSM and the residual error SSR. The larger the F value, the better the model.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    F =      Mean SSM\n",
      "                Mean SSR\n",
      "\n",
      "    77 | P a g e\n",
      "\n",
      "\n",
      "    SIMPLE REGRESSION\n",
      "    Regression tests the null hypothesis (Hâ‚’) that there will be no significant prediction of the dependent\n",
      "    (outcome) variable by the predictor variable(s).\n",
      "\n",
      "    Open Rugby kick regression.csv.  This dataset contains rugby kick data, including distance kicked,\n",
      "    right/left leg strength and flexibility and bilateral leg strength. Firstly, go to Descriptives > Descriptive\n",
      "    statistics and check the boxplots for any outliers. In this case, there should be none, though it is good\n",
      "    practice to check.\n",
      "\n",
      "    For this simple regression, go to Regression > Linear regression and put distance into the Dependent\n",
      "    Variable (outcome) and R_Strength into the Covariates (Predictor) box. Tick the following options in\n",
      "    the Statistics options:\n",
      "\n",
      "     Statistics\n",
      "\n",
      "Coefficients\n",
      "   Estimates\n",
      "        From    5000   bootstraps\n",
      " Confidence intervals  95.0     %\n",
      " Covariance matrix\n",
      " Vovk-Sellke maximum p-ratio\n",
      "\n",
      "Model fit\n",
      "R squared change\n",
      "Descriptives\n",
      "Part and partial correlations\n",
      "Collinearity diagnostics\n",
      "\n",
      "     Residuals\n",
      "     Statistics\n",
      "      Durbin-Watson\n",
      "      Casewise diagnostics\n",
      "\n",
      "    UNDERSTANDING THE OUTPUT\n",
      "\n",
      "    You will now get the following outputs:\n",
      "    Model Summary - Distance\n",
      "                                                           Durbin-Watson\n",
      "     Model    R        RÂ²       Adjusted RÂ²     RMSE      Autocorrelation  Statistic      p\n",
      "\n",
      "     Mo     0.000    0.000      0.000           85.250     0.588           0.762        0.010\n",
      "     M1     0.784    0.614      0.579           55.285     0.225               1.524    0.287\n",
      "    Note. M, includes R_Strength\n",
      "    Here it can be seen that the correlation (R) between the two variables is high (0.784)., while that for\n",
      "    the null model Mâ‚€ is 0. The RÂ² value of 0.614 tells us that right leg strength accounts for 61.4% of the\n",
      "    variance in kick distance.  Durbin-Watson checks for correlations between residuals, which can\n",
      "    invalidate the test. This should be above 1 and below 3, and ideally around 2.\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "                                                                                        78 | P a g e\n",
      "\n",
      "\n",
      "    ANOVA\n",
      "      Model                      Sum of Squares       df  Mean Square                F           p\n",
      "      M1         Regression      53589.863            1   53589.863                  17.533      0.002\n",
      "                 Residual        33621.061            11  3056.460\n",
      "                 Total           87210.923            12\n",
      "     Note. M, includes R Strenqth\n",
      "     Note. The intercept model is omitted, as no meaninqful information can be shown.\n",
      "\n",
      "    The ANOVA table shows all the sums of squares mentioned earlier. With regression being the model\n",
      "    and Residual being the error. The F-statistic is significant - p=.002. This tells us that the model is a\n",
      "    significantly better predictor of kicking distance than the mean distance.\n",
      "    Report as F (1, 11) = 17.53, p=.002.\n",
      "\n",
      "    Coefficients\n",
      "      Model                      Unstandardized       Standard Error  Standardized      t         p\n",
      "      Mo        (Intercept)                486.077    23.644                            20.558    <.001\n",
      "      M1        (Intercept)             57.105        103.588                           0.551     0.592\n",
      "                R_Strength                   6.425        1.534       0.784             4.187     0.002\n",
      "\n",
      "    This table gives the coefficients (unstandardized) that can be put into the linear equation.\n",
      "                                 y = c + b*x\n",
      "\n",
      "     y = estimated dependent outcome variable score,\n",
      "\n",
      "     c = constant (intercept)\n",
      "\n",
      "     b = regression coefficient (R_strength)\n",
      "\n",
      "     x = score on the independent predictor variable\n",
      "\n",
      "    For example, for a leg strength of 60 kg, the distance kicked can be predicted by the following:\n",
      "\n",
      "     Distance = 57.105 + (6.452 * 60) = 454.6 m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                        Plots\n",
      "    FURTHER ASSUMPTION CHECKS                           Residuals Plots\n",
      "    In Plots checks, tick the following two options:     Residuals vs. dependent\n",
      "                                                         Residuals ys, covariates\n",
      "                                                         Residuals vs. predicted\n",
      "                                                         Residuals vs. histogram\n",
      "                                                             Standardized residuals\n",
      "                                                         Q-Q plot standardized residuals\n",
      "                                                         Partial plots\n",
      "\n",
      "    79 | P a g e\n",
      "\n",
      "\n",
      "    This will result in two graphs:\n",
      "\n",
      "    0\n",
      "\n",
      "    This graph shows a balanced random distribution of the residuals around the baseline, suggesting that\n",
      "    the assumption of homoscedasticity has not been violated. (See Exploring data integrity in JASP for\n",
      "    further details.\n",
      "\n",
      "    The Q-Q plot shows that the standardised residuals fit nicely along the diagonal, suggesting that both\n",
      "    assumptions of normality and linearity have also not been violated.\n",
      "\n",
      "    REPORTING THE RESULTS\n",
      "\n",
      "    A simple linear regression was used to predict rugby kicking distance from right leg strength. Leg\n",
      "    strength was shown to explain a significant amount of the variance in the kicking distance: F(1, 11) =\n",
      "    17.53, p.002, RÂ² = 0.614. The regression coefficient (b = 6.452) allows the kicking distance to be\n",
      "    predicted using the following regression equation:\n",
      "\n",
      "    Distance = 57.105 + (6.452 * Right leg strength)\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "    80 | P a g e\n",
      "\n",
      "\n",
      "    MULTIPLE REGRESSION\n",
      "    The model used is still a linear one defined by the formula.\n",
      "\n",
      "                                    y = c + b*x + Îµ\n",
      "\n",
      "             â–ª         y = estimated dependent outcome variable score,\n",
      "             â–ª         c = constant,\n",
      "             â–ª         b = regression coefficient and\n",
      "             â–ª         x = score on the independent predictor variable\n",
      "             â–ª         Îµ = random error component (based on residuals)\n",
      "\n",
      "    However, we now have more than 1 regression coefficient and predictor score, i.e.\n",
      "\n",
      "                       y = c + bâ‚*xâ‚ + bâ‚‚*xâ‚‚ + bâ‚ƒ*xâ‚ƒ â€¦â€¦.. bâ‚™*xâ‚™\n",
      "\n",
      "    Data entry methods.\n",
      "    If predictors are uncorrelated, their order of entry has little effect on the model. In most cases,\n",
      "    predictor variables are correlated to some extent, and thus, the order in which the predictors are\n",
      "    entered can make a difference. The different methods are subject to much debate in the area.\n",
      "\n",
      "    Enter: This is the default method in which all the predictors are forced into the model in the order\n",
      "    they appear in the Covariates box. This is considered to be the best method.\n",
      "\n",
      "    Blockwise entry (Hierarchical entry): The researcher, normally based on prior knowledge and previous\n",
      "    studies, decides the order in which the known predictors are entered first, depending on their\n",
      "    importance in predicting the outcome. Additional predictors are added in further steps.\n",
      "\n",
      "    Backwards: All predictors are initially entered into the model, and then the contribution of each is\n",
      "    calculated. Predictors with less than a given level of contribution (p<0.1) are removed. This process\n",
      "    repeats until all the predictors are statistically significant.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Forward: The predictor with the highest simple correlation with the outcome variable is entered first.\n",
      "    Subsequent predictors are selected based on the size of their semi-partial correlation with the\n",
      "    outcome variable. This is repeated until all predictors that contribute significant unique variance to\n",
      "    the model have been included in the model.\n",
      "\n",
      "    Stepwise entry: Same as the Forward method, except that every time a predictor is added to the\n",
      "    model, a removal test is made of the least useful predictor. The model is constantly reassessed to see\n",
      "    whether any redundant predictors can be removed.\n",
      "\n",
      "    There are many reported disadvantages of using stepwise data entry methods; however, backwards\n",
      "    entry methods can be useful for exploring previously unused predictors or for fine-tuning the model\n",
      "    to select the best predictors from the available options.\n",
      "\n",
      "    81 | P a g e\n",
      "\n",
      "\n",
      "    RUNNING MULTIPLE REGRESSION\n",
      "\n",
      "    Open Rugby kick regression.csv that we used for simple regression. Go to Regression > Linear\n",
      "    regression and put distance into the Dependent Variable (outcome), and now add all the other\n",
      "    variables into the Covariates (Predictor) box.\n",
      "\n",
      "    Linear Regression\n",
      "                                                  Dependent Variable\n",
      "                                                    Distance\n",
      "                                                  Method\n",
      "                                                   Enter\n",
      "                                                   Covariates\n",
      "                                                    R_Strength\n",
      "                                                    L_Strength\n",
      "                                                    R_Flexibility\n",
      "                                                    L_Flexibility\n",
      "                                                    Bilateral Strength\n",
      "\n",
      "    WLS Weights (optional)\n",
      "\n",
      "    In the Variable section, leave the Method as Enter. Tick the following options in the Statistics options,\n",
      "    Durbin-Watson, Model fit, Estimates, statistics and Casewise diagnostics.\n",
      "\n",
      "Statistics\n",
      "Model Summary\n",
      "R squared change\n",
      "F change\n",
      "AIC and BIC\n",
      "Durbin-Watson\n",
      "\n",
      "Display\n",
      "Model fit\n",
      "Descriptives\n",
      "Part and partial correlations\n",
      "Coefficients covariance matrix\n",
      "Collinearity diagnostics\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Coefficients\n",
      "       Estimates\n",
      "       From      5000       bootstraps\n",
      "       Confidence intervals 95.0      %\n",
      "       Tolerance and VIF\n",
      "       Vovk-Sellke maximum p-ratio\n",
      "Residuals\n",
      "       Statistics\n",
      "       Casewise diagnostics\n",
      "        Std. residual >     3          DFBETAS\n",
      "        Cook's dist. >                 DFFITS\n",
      "        All                            Cov ratio\n",
      "                                       Leverage\n",
      "                                       Mahalanobis\n",
      "\n",
      "                                                                                      82 | P a g e\n",
      "\n",
      "\n",
      "    UNDERSTANDING THE OUTPUT\n",
      "\n",
      "    You will now get the following outputs:\n",
      "\n",
      "    Model Summary - Distance\n",
      "                                                        Durbin-Watson\n",
      "     Model  R             RÂ²  Adjusted RÂ³     RMSE      Autocorrelation  Statistic           p\n",
      "\n",
      "     Mo     0.000      0.000  0.000           85.250    0.588                       0.762  0.010\n",
      "     M1     0.902      0.814  0.681           48.132    0.287                       1.328  0.133\n",
      "    Note. M, includes R_Strength, L_Strength, R_Flexibility, L_Flexibility, Bilateral Strength\n",
      "\n",
      "    This provides information on a model based on the Mâ‚€ (no predictors) and the alternative HÂ¹.\n",
      "    The adjusted RÂ² (used for multiple predictors) shows that they can predict 68.1% of the outcome\n",
      "    variance. Durbin-Watson checks for correlations between residuals are between 1 and 3 as required.\n",
      "    ANOVA\n",
      "     Model                    Sum of Squares  df        Mean Square                           F  p\n",
      "\n",
      "    M1        Regression    70994.078               5   14198.816                   6.129        0.017\n",
      "              Residual      16216,845               7   2316.692\n",
      "              Total         87210.923         12\n",
      "    Note. M, includes R_Strength, L_Strength, R_Flexibility, L_Flexibility, Bilateral Strength\n",
      "    Note. The intercept model is omitted, as no meaningful information can be shown.\n",
      "\n",
      "    The ANOVA table shows the F-statistic to be significant at p=0.017, suggesting that the model is a\n",
      "    significantly better predictor of kicking distance than the mean distance.\n",
      "\n",
      "    Coefficients\n",
      "    Model                             Unstandardized  Standard Error  Standardized        t            p\n",
      "    Mo          (Intercept)         486.077     23.644                                 20.558    <.001\n",
      "    M1          (Intercept)         -92.367    218.389                                 -0.423     0.685\n",
      "                R_Strength            1.747      3.321                   0.213          0.526     0.615\n",
      "                L_Strength            0.703      3.590                   0.086          0.196     0.850\n",
      "                R_Flexibility         4.078      4.759                   0.373          0.857     0.420\n",
      "                L_Flexibility        -1.339      2.447                  -0.135         -0.547     0.601\n",
      "                Bilateral Strength    1.665      0.946                   0.423            1.759  0.122\n",
      "\n",
      "    This table shows both the Mâ‚€ and Mâ‚ models and the constant (intercept) and regression coefficients\n",
      "    (unstandardized) for all the predictors forced into the model. Even though the ANOVA shows the\n",
      "    model to be significant, none of the predictor regression coefficients is significant!\n",
      "\n",
      "    83 | P a g e\n",
      "\n",
      "\n",
      "    The casewise diagnostics table is empty! This is good news. This will highlight any cases (rows) that\n",
      "    have residuals that are 3 or more standard deviations away from the mean. These cases with the\n",
      "    largest errors may well be outliers. Too many outliers will have an impact on the model and should be\n",
      "    dealt with in the usual way (see Exploring Data Integrity).\n",
      "\n",
      "    Influential Cases\n",
      "     Case Number         Std. Residual     Distance    Predicted Value  Residual         Cook's Distance\n",
      "\n",
      "    Note. No influential cases found.\n",
      "    As a comparison, re-run the analyses but now choose Backwards as the method of data entry.\n",
      "\n",
      "    The outputs are as follows:\n",
      "    Model Summary - Distance\n",
      "                                                                        Durbin-Watson\n",
      "     Model      R         RÂ²         Adjusted RÂ²     RMSE      Autocorrelation           Statistic      p\n",
      "     Mo         0.902     0.814            0.681    48.132              0.287            1.328      0.133\n",
      "     M1         0.902     0.813            0.720    45.146              0.303            1.296      0.088\n",
      "         M2     0.897     0.805            0.740    43.505              0.284            1.313      0.144\n",
      "         M3     0.884     0.782           0.738     43.618              0.132            1.676      0.439\n",
      "\n",
      "    JASP has now calculated 4 potential regression models. It can be seen that each consecutive model\n",
      "    increases the adjusted RÂ², with model 4 accounting for 73.5% of the outcome variance.\n",
      "    The Durbin-Watson score is also higher than the forced entry method.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    ANOVA\n",
      "     Model                         Sum of Squares      df      Mean Square               F               p\n",
      "     Mo          Regression               70994.078    5                14198.816              6.129     0.017\n",
      "                 Residual                 16216.845    7                     2316.692\n",
      "                 Total                    87210.923      12\n",
      "     M1          Regression               70905.329    4                    17726.332          8.697     0.005\n",
      "                 Residual                 16305.594    8                     2038.199\n",
      "                 Total                    87210.923      12\n",
      "     Mz          Regression               70176.855    3                23392.285        12.359          0.002\n",
      "                 Residual                 17034.068    9                     1892.674\n",
      "                 Total                    87210.923    12\n",
      "     M:          Regression               68185.712    2                34092.856        17.920          <.001\n",
      "                 Residual                 19025.211      10             1902.521\n",
      "                 Total                    87210.923      12\n",
      "\n",
      "    The ANOVA table indicates that each successive model is better, as shown by the increasing F-value\n",
      "    and improving p-value.\n",
      "\n",
      "    84 | P a g e\n",
      "\n",
      "\n",
      "    Coefficients\n",
      "    Model                             Unstandardized  Standard Error  Standardized  t         p\n",
      "    Mo          (Intercept)                -92.367    218.389                      -0.423     0.685\n",
      "                R_Strength            1.747             3.321         0.213         0.526     0.615\n",
      "                L_Strength                   0.703      3.590         0.086         0.196     0.850\n",
      "                R_Flexibility                4.078      4.759         0.373         0.857     0.420\n",
      "                L_Flexibility         -1.339            2.447            -0.135    -0.547     0.601\n",
      "                Bilateral Strength           1.665      0.946         0.423         1.759     0.122\n",
      "    M1          (Intercept)           -110.347        185.840                      -0.594     0.569\n",
      "                R_Strength                   2.218      2.148         0.271         1.033     0.332\n",
      "                R_Flexibility                4.501      3.978         0.411         1.131     0.291\n",
      "                L_Flexibility               -1.370      2.291            -0.138    -0.598     0.566\n",
      "                Bilateral Strength           1.605      0.840         0.408         1.910     0.092\n",
      "    Mz          (Intercept)           -116.892        178.772                      -0.654     0.530\n",
      "                R_Strength                   2.710      1.911         0.331         1.418     0.190\n",
      "                R_Flexibility                2.886      2.814         0.264         1.026     0.332\n",
      "                Bilateral Strength           1.642      0.807         0.418         2.033     0.073\n",
      "    M3          (Intercept)           46.251           81.820                       0.565     0.584\n",
      "                R_Strength                   3.914      1.512         0.478         2.588     0.027\n",
      "                Bilateral Strength           2.009      0.725         0.511         2.770     0.020\n",
      "\n",
      "    Model 1 is the same as the forced entry method first used. The table shows that as the least\n",
      "    significantly contributing predictors are sequentially removed, we end up with a model with two\n",
      "    significant predictor regression coefficients, right leg strength and bilateral leg strength.\n",
      "\n",
      "    We can now report the Backwards predictor entry results in a highly significant model F(2, 10) = 17.92,\n",
      "    p<.001 and a regression equation of\n",
      "\n",
      "    Distance = 46.251 + (3.914 * R_Strength) + (2.009 * Bilateral Strength)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    TESTING FURTHER ASSUMPTIONS.\n",
      "    As for the simple linear regression example, tick the following options.\n",
      "\n",
      "          Plots\n",
      "\n",
      "     Residuals Plots\n",
      "     Residuals vs. dependent\n",
      "     Residuals vs. covariates\n",
      "     Residuals vs. predicted\n",
      "     Residuals vs. histogram\n",
      "     Standardized residuals\n",
      "     Q-Q plot standardized residuals\n",
      "     Partial plots\n",
      "\n",
      "                                                                            85 | P a g e\n",
      "\n",
      "\n",
      "    Residuals vs. Predicted\n",
      "\n",
      "    100\n",
      "\n",
      "           50 -    O o                                  2 20\n",
      "    20      0 -                            O      O     1\n",
      "                                   o       O            0\n",
      "\n",
      "        -50 -      oo                   o  O O          -1\n",
      "                          O                             -2\n",
      "        -100\n",
      "               300350 400 450 500 550 600 650\n",
      "                      Predicted Values\n",
      "\n",
      "    Q-Q Plot Standardized Residuals\n",
      "\n",
      "        2\n",
      "    20  1                                  C â€¢                         O\n",
      "        0\n",
      "\n",
      "       -1    C\n",
      "\n",
      "       -2    O\n",
      "             -2  -1                        0  1                         2\n",
      "                 Theoretical Quantiles\n",
      "\n",
      "    The balanced distribution of the residuals around the baseline suggests that the assumption of\n",
      "    homoscedasticity has not been violated.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    The Q-Q plot shows that the standardised residuals fit along the diagonal, suggesting that both\n",
      "    assumptions of normality and linearity have also not been violated.\n",
      "\n",
      "    86 | P a g e\n",
      "\n",
      "\n",
      "    IN SUMMARY\n",
      "\n",
      "    RÂ² provides information on how much variance is explained by the model using the predictors\n",
      "    provided.\n",
      "\n",
      "    F-statistics provide information as to how good the model is.\n",
      "\n",
      "    The unstandardized (b)-value provides a constant which reflects the strength of the relationship\n",
      "    between the predictor(s) and the outcome variable.\n",
      "\n",
      "    Violation of assumptions can be checked using the Durbin-Watson value, tolerance/VIF values,\n",
      "    Residual vs predicted and Q-Q plots.\n",
      "\n",
      "    REPORTING THE RESULTS\n",
      "\n",
      "    Multiple linear regression using backwards data entry shows that right leg and bilateral strength can\n",
      "    significantly explain 78.2% of the variance in kicking distance, F(2,10) = 17.92, p<.001, RÂ² = 0.782. Two\n",
      "    significant regression coefficients were found, right leg strength (bâ‚= 3.91, t=2.59, p=.027) and bilateral\n",
      "    strength (bâ‚‚ = 2.009, t =2.77, p=0.02). Kicking distance could be predicted using a regression equation\n",
      "    of;\n",
      "\n",
      "       Distance = 57.105 + (3.914 * R_Strength) + (2.009 * Bilateral Strength)\n",
      "\n",
      "    87 | P a g e\n",
      "\n",
      "\n",
      "    LOGISTIC REGRESSION\n",
      "    In simple and multiple linear regression outcome and predictor variable(s) were continuous data.\n",
      "    What if the outcome was a binary/categorical measure? Can, for example, a yes or no outcome be\n",
      "    predicted by other categorical or continuous variables? The answer is yes if binary logistic regression\n",
      "    is used. This method is used to predict the probability of a binary yes or no outcome.\n",
      "\n",
      "    The null hypothesis tested is that there is no relationship between the outcome and the predictor\n",
      "    variable(s).\n",
      "\n",
      "    As can be seen in the graph below, a linear regression line between the yes and no responses would\n",
      "    be meaningless as a prediction model. Instead, a sigmoidal logistic regression curve is fitted with a\n",
      "    minimum of 0 and a maximum of 1. Some predictor values overlap between yes and no. For example,\n",
      "    a prediction value of 5 would give an equal 50% probability of being a yes or no outcome. Thresholds\n",
      "    are therefore calculated to determine if a predictor data value will be classified as a yes or no outcome.\n",
      "\n",
      "           1.0               Outcome = Yes\n",
      "\n",
      "           0.8\n",
      "\n",
      "           0.6\n",
      "\n",
      "           0.4\n",
      "\n",
      "           0.2\n",
      "                                              Outcome = No\n",
      "           0.0\n",
      "\n",
      "                0               2         4   6  8        10\n",
      "\n",
      "    ASSUMPTIONS FOR BINARY LOGISTIC REGRESSION\n",
      "\n",
      "    â€¢     The dependent variable must be binary, i.e. yes or no, male or female, good or bad.\n",
      "    â€¢     One or more independent (predictor variables) can be continuous or categorical variables.\n",
      "    â€¢     A linear relationship exists between any continuous independent variables and the logit\n",
      "          transformation (natural log of the odds that the outcome equals one of the categories) of the\n",
      "          dependent variable.\n",
      "\n",
      "    LOGISTIC REGRESSION METRICS\n",
      "\n",
      "    AIC (Akaike Information Criteria) and BIC (Bayesian Information Criteria) are measures of fit for the\n",
      "    model; the best model will have the lowest AIC and BIC values.\n",
      "\n",
      "    88 | P a g e\n",
      "\n",
      "\n",
      "    Four pseudo RÂ² values are calculated in JASP: McFadden, Nagelkerke, Tjur and Cox & Snell. These are\n",
      "    analogous to RÂ² in linear regression and all give different values.  What constitutes a good RÂ² value\n",
      "    varies; however, they are useful when comparing different models for the same data. The model with\n",
      "    the largest RÂ² statistic is considered to be the best.\n",
      "\n",
      "    The Wald test is used to determine the statistical significance of each of the independent variables.\n",
      "\n",
      "    The confusion matrix is a table showing actual vs predicted outcomes and can be used to determine\n",
      "    the accuracy of the model. From this, sensitivity and specificity can be derived.\n",
      "\n",
      "    Sensitivity is the percentage of cases in which the observed outcome was correctly predicted by the\n",
      "    model (i.e., true positives).\n",
      "\n",
      "    Specificity    is the percentage of observations that were also correctly predicted as not having the\n",
      "    observed outcome (i.e., true negatives).\n",
      "\n",
      "    RUNNING LOGISTIC REGRESSION\n",
      "\n",
      "    Open Heart attack.csv in JASP. This contains 4 columns of data: Patient ID, did they have a second\n",
      "    heart attack (yes/no), whether they were prescribed exercise (yes/no) and their stress levels (high\n",
      "    value = high stress).\n",
      "    Put the outcome variable (2â¿áµˆ heart attack) into the Dependent variable, add the stress levels to the\n",
      "    Covariates and Exercise prescription to Factors. Leave the data entry method as Enter.\n",
      "\n",
      "    Logistic Regression\n",
      "\n",
      "    ID                         Dependent Variable\n",
      "                               V2nd.HeartAttack\n",
      "                               Method\n",
      "                               Enter\n",
      "                               Covariates\n",
      "                               Stress level\n",
      "\n",
      "    Factors\n",
      "    Exercise prescription\n",
      "\n",
      "    In the Statistics options, tick Estimates, Odds ratios, Confusion matrix, Sensitivity and Specificity.\n",
      "\n",
      "    89 | P a g e\n",
      "\n",
      "\n",
      "            Statistics\n",
      "\n",
      "     Descriptives                                              Performance Diagnostics\n",
      "            Factor descriptives                                               Confusion matrix\n",
      "\n",
      "Reqression Coefficients\n",
      "       Estimates\n",
      "        From              5000  bootstraps\n",
      "        Standardized coefficients\n",
      "        Odds ratios\n",
      "        Confidence intervals\n",
      "        Interval 95.0           %\n",
      "                 Odds ratio scale\n",
      "        Robust standard errors\n",
      "        Vovk-Sellke maximum p-ratio\n",
      "       Multicollinearity Diagnostics\n",
      "Performance Metrics\n",
      "               Accuracy\n",
      "               AUC\n",
      "               Sensitivity / Recall\n",
      "               Specificity\n",
      "               Precision\n",
      "               F-measure\n",
      "               Brier score\n",
      "               H-measure\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    UNDERSTANDING THE OUTPUT\n",
      "    The initial output should comprise 4 tables.\n",
      "\n",
      "    The model summary shows that H1 (with the lowest AIC and BIC scores) suggests a significant\n",
      "    relationship (XÂ²(37) =21.257, p<.001) between the outcome (2â¿áµˆ heart attack) and the predictor\n",
      "    variables (exercise prescription and stress levels).\n",
      "\n",
      "    McFadden's RÂ² = 0.383. It is suggested that a range from 0.2 to 0.4 indicates a good model fit.\n",
      "    Model Summary - 2nd.Heart Attack\n",
      "      Model  Deviance           AIC       BIC            df    \\XÂ²  p  McFadden RÂ²     Nagelkerke RÂ²  Tjur RÂ²  Cox & Snell R\n",
      "      Mo             55.452     57.452    59.141         39                   0.000                   0.000\n",
      "      M1             34.195     40.195    45.261         37    21.257  <.001  0.383      0.550        0.446    0.412\n",
      "    Note. M, includes Stress level, Exercise prescription\n",
      "\n",
      "    Coefficients\n",
      "                                                                                                       Wald Test\n",
      "    Model                                    Estimate      Standard Error  Odds Ratio    Z          Wald Statistic    df     p\n",
      "    Mo          (Intercept)                      -0.000     0.316          1.000       -4.441Ã—10-16    1.972Ã—10-31    1    1.000\n",
      "    M1          (Intercept)                      -4.368     2.550          0.013         -1.713              2.933    1    0.087\n",
      "                Stress level                      0.089     0.041          1.093              2.159          4.662    1    0.031\n",
      "                Exercise prescription (Yes)  -2.043         0.890          0.130             -2.295          5.268    1    0.022\n",
      "    Note. 2nd.Heart Attack level 'Yes' coded as class 1\n",
      "\n",
      "    90 | P a g e\n",
      "\n",
      "\n",
      "    Both stress level and exercise prescription are significant predictor variables (p=.031 and .022,\n",
      "    respectively). The most important values in the coefficients table are the odds ratios. For the\n",
      "    continuous predictor, an odds ratio of greater than 1 suggests a positive relationship, while < 1\n",
      "    implies a negative relationship. This suggests that high-stress levels are significantly related to an\n",
      "    increased probability of having a second heart attack.\n",
      "\n",
      "    Thus, the odds ratio of 1.093 means that for each additional point on the stress scale, the odds of\n",
      "    having a second heart attack are increased 1.1 times. Or presented in percentage, for every\n",
      "    additional point on the stress scale, the odds of having a second heart attack increase by 9.3%.\n",
      "    The odds ratio of 0.130 regarding the exercise prescription variable can be interpreted as having a\n",
      "    second heart attack undergoing an exercise intervention is 0.13 times the odds of not having such an\n",
      "    intervention. Or presented in percentage, those having exercise prescription are 87% less likely to\n",
      "    have a second heart attack compared to those not having such an intervention.\n",
      "\n",
      "    Confusion matrix\n",
      "                          Predicted\n",
      "           Observed  No   Yes                % Correct    Performance metrics\n",
      "     No              15                 5     75.000      Value\n",
      "     Yes                  5            15     75.000      Sensitivity        0.750\n",
      "     Overall % Correct                        75.000      Specificity        0.750\n",
      "    Note. The cut-off value is set to 0.5\n",
      "\n",
      "    The confusion matrix shows (where agreement (yes/yes) or disagreement (yes/no) occurred between\n",
      "    the predicted and observed) that the 15 true negative and positive cases were predicted by the model,\n",
      "    while the error, false negatives and positives, were found in 5 cases. This is confirmed in the\n",
      "    Performance metrics, where both sensitivity (% of cases that had the outcome correctly predicted)\n",
      "    and specificity (% of cases correctly predicted as not having the outcome (i.e., true negatives) are both\n",
      "    75%.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    PLOTS\n",
      "    These findings can be easily visualised through the inferential plots.\n",
      "\n",
      "     Plots\n",
      "     Inferential Plots                      Residual Plots\n",
      "        Conditional estimates plots          Predicted - residual plot\n",
      "        Confidence interval [95.0      %     Predictor - residual plots\n",
      "         Show data points                    Squared Pearson residuals plot\n",
      "     Residual Type                          Performance Plots\n",
      "     Deviance                                ROC plot\n",
      "        Pearson                              Cutoff step0.2\n",
      "                                             Add cutoff labels\n",
      "                                             PR plot\n",
      "                                             Cutoff step0.2\n",
      "                                             Add cutoff labels\n",
      "\n",
      "                                                                           91 | P a g e\n",
      "\n",
      "\n",
      "    1.00\n",
      "\n",
      "    0.75\n",
      "\n",
      "    0.50\n",
      "\n",
      "    0.25\n",
      "\n",
      "    0.00                -\n",
      "            30  40  50  60  70  80  90\n",
      "\n",
      "    As stress levels increase, the probability of having a second heart attack increases.\n",
      "\n",
      "                      1.00     ges8    â€¢\n",
      "\n",
      "                      0.75\n",
      "\n",
      "                      0.50\n",
      "\n",
      "                      0.25\n",
      "\n",
      "                      0.00     @8      00\n",
      "                               No      Yes\n",
      "\n",
      "    No exercise intervention increases the probability of a 2â¿áµˆ heart attack, while it is reduced when it has\n",
      "    been put in place.\n",
      "\n",
      "    REPORTING THE RESULTS\n",
      "\n",
      "    Logistic regression was performed to ascertain the effects of stress and exercise intervention on the\n",
      "    likelihood that participants have a 2â¿áµˆ heart attack. The logistic regression model was statistically\n",
      "    significant, Ï‡2 (37) = 21.257, p< .001. The model correctly classified 75.0% of cases. Increasing stress\n",
      "    was associated with an increased likelihood of a 2â¿áµˆ heart attack, but decreasing stress was associated\n",
      "    with a reduction in the likelihood. The presence of an exercise intervention programme reduced the\n",
      "    probability of a 2â¿áµˆ heart attack to 13%.\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "    92 | P a g e\n",
      "\n",
      "\n",
      "    COMPARING MORE THAN TWO INDEPENDENT GROUPS\n",
      "    ANOVA\n",
      "    Whereas t-tests compare the means of two groups/conditions, one-way analysis of variance (ANOVA)\n",
      "    compares the means of 3 or more groups/conditions. There are both independent and repeated\n",
      "    measures ANOVAs available in JASP. ANOVA has been described as an â€˜omnibus testâ€™ which results in\n",
      "    an F-statistic that compares whether the dataset's overall explained variance is significantly greater\n",
      "    than the unexplained variance. The null hypothesis tested is that there is no significant difference\n",
      "    between the means of all the groups. If the null hypothesis is rejected, ANOVA just states that there\n",
      "    is a significant difference between the groups, but not where those differences occur. To determine\n",
      "    where the group differences are, post hoc (From the Latin post hoc, \"after this\") tests are subsequently\n",
      "    used.\n",
      "\n",
      "    Why not just multiple pairwise comparisons? If there are 4 groups (A, B, C, D), for example and the\n",
      "    differences were compared using multiple t-tests:\n",
      "\n",
      "            â€¢     A vs. B     P<0.05               95% no type I error\n",
      "            â€¢     A vs. C     P<0.05               95% no type I error\n",
      "            â€¢     A vs. D     P<0.05               95% no type I error\n",
      "            â€¢     B vs. C     P<0.05               95% no type I error\n",
      "            â€¢     B vs. D     P<0.05               95% no type I error\n",
      "            â€¢     C vs. D     P<0.05               95% no type I error\n",
      "\n",
      "    Assuming that each test was independent, the overall probability would be:\n",
      "\n",
      "                             0.95 * 0.95 * 0.95 * 0.95 * 0.95 * 0.95 = 0.735\n",
      "\n",
      "    This is known as familywise error or, cumulative Type I error, and in this case, results in only a 73.5%\n",
      "    probability of no Type I error whereby the null hypothesis could be rejected when it is true. This is\n",
      "    overcome by using post hoc tests that make multiple pairwise comparisons with stricter acceptance\n",
      "    criteria to prevent familywise error.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    ASSUMPTIONS\n",
      "\n",
      "    The independent ANOVA makes the same assumptions as most other parametric tests.\n",
      "\n",
      "     â€¢     The independent variable must be        categorical, and the dependent variable must be\n",
      "           continuous.\n",
      "     â€¢     The groups should be independent of each other.\n",
      "     â€¢     The dependent variable should be approximately normally distributed.\n",
      "     â€¢     There should be no significant outliers.\n",
      "     â€¢     There should be homogeneity of variance between the groups; otherwise, the p-value for the\n",
      "           F-statistic may not be reliable.\n",
      "\n",
      "    The first 2 assumptions are usually controlled using an appropriate research method design.\n",
      "\n",
      "    If the last three assumptions are violated, then the non-parametric equivalent, Kruskal-Wallis, should\n",
      "    be considered instead.\n",
      "\n",
      "    93 | P a g e\n",
      "\n",
      "\n",
      "    CONTRASTS\n",
      "    Contrasts are â€˜a prioriâ€™ tests (i.e. planned comparisons before any data were collected). As an\n",
      "    example, researchers may want to compare the effects of some new drugs to the currently\n",
      "    prescribed ones. These should only be a small set of comparisons to reduce family-wise error.\n",
      "    The choice must be based on the scientific questions being asked and chosen during the\n",
      "    experimental design. Hence, the term planned comparisons. Therefore, they are looking at\n",
      "    specified mean differences and can be used if the ANOVA F test is insignificant.\n",
      "    JASP provides 6 planned contrasts enabling different types of comparisons:\n",
      "    Deviation: the mean of each level of the independent variable is compared to the overall\n",
      "    mean (the mean when all the levels are taken together).\n",
      "    Simple: the mean of each level is compared to the mean of a specified level, for example, with\n",
      "    the mean of the control group.\n",
      "    Difference: the mean of each level is compared to the mean of the previous levels.\n",
      "    Helmert: the mean of each level is compared to the mean of the subsequent levels.\n",
      "    Repeated: By selecting this contrast, the mean of each level is compared to the mean of the\n",
      "    following level.2\n",
      "    Polynomial: tests polynomial trends in the data.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    POST HOC TESTING\n",
      "    Post hoc tests are tests that were decided upon after the data had been collected. They can only be\n",
      "    carried out if the ANOVA F test is significant.\n",
      "    JASP provides 4 types of post hoc testing\n",
      "    Standard\n",
      "    Games-Howell â€“ used when you are unsure about the equality of group variances.\n",
      "    Dunnettâ€™s â€“ used to compare all the groups to one group, i.e. the control group\n",
      "    Dunn â€“ a non-parametric post hoc test used for testing small sub-sets of pairs.\n",
      "\n",
      "    JASP also provides 5 types of corrections for use with the independent group ANOVA tests:\n",
      "    Bonferroni â€“ can be very conservative but gives guaranteed control over Type I errors at the risk of\n",
      "    reducing statistical power. Does not assume independence of the comparisons.\n",
      "    Holm â€“ the Holm-Bonferroni test is a sequential Bonferroni method that is less conservative than the\n",
      "    original Bonferroni test.\n",
      "\n",
      "                                                                                94 | P a g e\n",
      "\n",
      "                                                  9  JASP\n",
      "\n",
      "    Tukey â€“ is one of the most commonly used tests and provides controlled Type I error for groups with\n",
      "    the same sample size and equal group variance.\n",
      "\n",
      "    Scheffe â€“ controls for the overall confidence level when the group sample sizes are different.\n",
      "\n",
      "    Sidak â€“ is similar to Bonferroni but assumes that each comparison is independent of the others.\n",
      "    Slightly more powerful than Bonferroni.\n",
      "\n",
      "    EFFECT SIZE\n",
      "\n",
      "    JASP provides 3 alternative effect size calculations for use with the independent group ANOVA tests:\n",
      "\n",
      "    Eta squared (Î·Â²) - accurate for the sample variance explained but overestimates the population\n",
      "    variance. This can make it difficult to compare the effect of a single variable in different studies.\n",
      "\n",
      "    Partial Eta squared (Î·â‚šÂ²) â€“ this solves the problem relating to population variance overestimation,\n",
      "    allowing for comparison of the effect of the same variable in different studies.\n",
      "\n",
      "    Omega squared (Ï‰Â²) â€“ Normally, statistical bias gets very small as sample size increases, but for small\n",
      "    samples (n<30), Ï‰Â² provides an unbiased effect size measure.\n",
      "\n",
      "     Test              Measure           Trivial                Small     Medium     Large\n",
      "\n",
      "     ANOVA             Eta               <0.1                   0.1       0.25       0.37\n",
      "\n",
      "                       Partial Eta       <0.01                  0.01      0.06       0.14\n",
      "\n",
      "                       Omega squared     <0.01                  0.01      0.06       0.14\n",
      "\n",
      "    RUNNING THE INDEPENDENT ANOVA\n",
      "\n",
      "    Load Independent ANOVA diets.csv. This contains A column containing the 3 diets used (A, B and C)\n",
      "    and another column containing the absolute amount of weight loss after 8 weeks on one of 3 different\n",
      "    diets. For good practice, check the descriptive statistics and the boxplots for any extreme outliers.\n",
      "\n",
      "    Go to ANOVA > ANOVA, put weight loss into the Dependent Variable and the Diet groupings into the\n",
      "    Fixed Factors box. In the first instance, tick Descriptive statistics and Ï‰Â² as the effect size.\n",
      "\n",
      "           ANOVA\n",
      "                                     Dependent Variable\n",
      "                                     Weight loss kg\n",
      "                                     Fixed Factors\n",
      "           Display                   Diet\n",
      "           Descriptive statistics\n",
      "             Estimates of effect size\n",
      "                    wÂ²     partial wÂ²\n",
      "                   nÂ²2    partial nÂ²2\n",
      "\n",
      "    95 | P a g e\n",
      "\n",
      "\n",
      "    In Assumptions checks, tick all options:\n",
      "\n",
      "     Assumption Checks\n",
      "\n",
      "     Homogeneity tests\n",
      "    Homogeneity corrections\n",
      "     None  Brown-Forsythe  Welch\n",
      "    Q-Q plot of residuals\n",
      "\n",
      "    This should result in 3 tables and one Q-Q plot.\n",
      "\n",
      "    UNDERSTANDING THE OUTPUT\n",
      "\n",
      "    ANOVA - Weight loss kg\n",
      "     Homogeneity Correction      Cases  Sum of Squares   df        Mean Square  F             p          Ï‰Â²\n",
      "     None                      Diet            92.369     2.000    46.184       10.826        < .001     0.214\n",
      "                               Residuals    294.371      69.000     4.266\n",
      "     Brown-Forsythe            Diet            92.369     2.000    46.184       10.826        < .001     0.214\n",
      "                               Residuals      294.371    64.352     4.574\n",
      "     Welch                     Diet            92.369     2.000    46.184       11.449        <.001      0.214\n",
      "                               Residuals      294.371    44.987     6.544\n",
      "    Note. Type III Sum of Squares\n",
      "\n",
      "    The main ANOVA table shows that the F-statistic is significant (p<.001) and that there is a large effect\n",
      "    size. Therefore, there is a significant difference between the means of the 3 diet groups.\n",
      "\n",
      "    TESTING ASSUMPTIONS\n",
      "\n",
      "    Before accepting this, any violations in the assumptions required for an ANOVA should be checked.\n",
      "\n",
      "    Test for Equality of Variances (Levene's)\n",
      "                       F         df1    df2  p\n",
      "                       1.298     2.000  69.000  0.280\n",
      "\n",
      "    Leveneâ€™s test shows that the homogeneity of variance is not significant. However, if Leveneâ€™s test\n",
      "    shows a significant difference in variance, the Brown-Forsythe or Welch correction should be\n",
      "    reported.\n",
      "\n",
      "    96 | P a g e\n",
      "\n",
      "\n",
      "                Q-Q Plot\n",
      "                20    3\n",
      "                      2\n",
      "\n",
      "                      1\n",
      "                      .\n",
      "                                 -3 -2    -1         0 1 2        3\n",
      "                                           Theoretical Quantiles\n",
      "    The Q-Q plot shows that the data appear to be normally distributed and linear.\n",
      "\n",
      "    Descriptives - Weight loss kg\n",
      "     Diet      N                 Mean      SD            SE        Coefficient of variation\n",
      "     Diet A     24               3.008     1.668         0.340     0.554\n",
      "     Diet B     24               3.413     2.361         0.482     0.692\n",
      "     Diet C     24               5.587    2.108          0.430     0.377\n",
      "\n",
      "    The descriptive statistics suggest that Diet 3 results in the highest weight loss after 8 weeks.\n",
      "\n",
      "    CONTRAST EXAMPLE\n",
      "\n",
      "    If, for example, one planned to compare the effects of diets B and C to diet A, click on the drop-\n",
      "    down menu and select â€˜simpleâ€™ next to diet. This will test the significance between the first category\n",
      "    in the list with the remaining categories.\n",
      "\n",
      "    Contrasts\n",
      "    Factors\n",
      "    Diet                                      simple\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Simple Contrast - Diet\n",
      "    Comparison         Estimate  SE        df         t        p\n",
      "    Diet B - Diet A    0.404     0.596     69.000     0.678                              0.500\n",
      "    Diet C - Diet A    2.579     0.596     69.000     4.326                              <.001\n",
      "\n",
      "    As can be seen, only diet C is significantly different from diet A (t(69) = 4.326, p<.001.\n",
      "\n",
      "    97 | P a g e\n",
      "\n",
      "\n",
      "    If the ANOVA reports no significant difference, you can go no further in the analysis.\n",
      "\n",
      "    POST HOC TESTING\n",
      "\n",
      "    If the ANOVA is significant, post hoc testing can now be carried out. In Post Hoc Tests, add Diet to the\n",
      "    analysis box on the right, tick Standard type, use Tukey for the post hoc correction and tick the flag\n",
      "    significant comparisons.\n",
      "\n",
      "    Post Hoc Tests\n",
      "\n",
      "                  Diet\n",
      "\n",
      "               Type                                               Correction\n",
      "                       Standard                                               Tukey\n",
      "                        From       1000      bootstraps                       Scheffe\n",
      "                        Effect size                                           Bonferroni\n",
      "                       Games-Howell                                           Holm\n",
      "                       Dunnett                                                SidÃ¡k\n",
      "                       Dunn\n",
      "               Display\n",
      "                       Confidence intervals  95.0  %\n",
      "                       Flag Significant Comparisons\n",
      "\n",
      "    Post hoc testing shows that there is no significant difference between weight loss in diets A and B.\n",
      "    However, It is significantly higher in diet C compared to diet A (p<.001) and diet B (p=.001). Cohenâ€™s d\n",
      "    shows that these differences have a large effect size.\n",
      "\n",
      "    Post Hoc Comparisons - Diet\n",
      "                                       Mean Difference     SE     t          Ptukey\n",
      "     Diet A             Diet B               -0.404        0.596  -0.678     0.777\n",
      "                        Diet C               -2.579        0.596  -4.326     <.001***\n",
      "     Diet B             Diet C               -2.175        0.596  -3.648     0.001**\n",
      "    ** p < .01, *** p < .001\n",
      "    Note, P-value adiusted for comparing a family of 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Also, in Descriptive Plots, add the Factor â€˜Dietâ€™ to the horizontal axis and tick display error bars and in\n",
      "    Raincloud plots, do the same but tick Horizontal display.\n",
      "\n",
      "    98 | P a g e\n",
      "\n",
      "\n",
      "    Descriptives Plots\n",
      "    Factors                                Horizontal Axis\n",
      "                                           Diet\n",
      "                                           Separate Lines\n",
      "\n",
      "                                           Separate Plots\n",
      "\n",
      "    Display\n",
      "    âœ“ Display error bars\n",
      "               Confidence interval  95.0  %\n",
      "\n",
      "    Weight loss kg\n",
      "\n",
      "    Diet C\n",
      "\n",
      "    B Diet B\n",
      "\n",
      "    Diet A\n",
      "    2\n",
      "     Diet A  Diet B  Diet C    -10  -5  0  5  10  15\n",
      "\n",
      "    REPORTING THE RESULTS\n",
      "\n",
      "    Leveneâ€™s test showed that there was equal variance for all three groups: F (2,69) = 1.3, p=.28*.\n",
      "\n",
      "    Independent one-way ANOVA showed a significant effect of the type of diet on weight loss after 10\n",
      "    weeks (F (2, 69) =46.184, p<.001, The Ï‰Â² = 0.214, suggesting that this is a large effect size.\n",
      "\n",
      "    Post hoc testing using pairwise comparisons of the estimated marginal means with Tukeyâ€™s correction\n",
      "    revealed that diet C resulted in significantly greater weight loss (M = 5.59, SD = 2.1 kg) than diet A (M\n",
      "    = 3.0, SD = 2.36 kg, p<.001) or diet B (M = 3.41, SD = 2.36 kg, p=.001). There were no significant\n",
      "    differences in weight loss between diets A and B (p=.777).\n",
      "\n",
      "    * If Leveneâ€™s test shows a significant difference in variance, the Brown-Forsythe or Welch\n",
      "    correction should be reported.\n",
      "\n",
      "                                             99 | P a g e\n",
      "\n",
      "\n",
      "    KRUSKAL-WALLIS â€“ NON-PARAMETRIC ANOVA\n",
      "    If your data fails parametric assumption tests or is nominal, the Kruskal-Wallis H test is a non-\n",
      "    parametric equivalent to the independent samples ANOVA. It can be used for comparing two or more\n",
      "    independent samples of equal or different sample sizes. Like the Mann-Whitney and Wilcoxon tests,\n",
      "    it is a rank-based test.\n",
      "\n",
      "    As with the ANOVA, the Kruskal-Wallis H test (also known as the \"one-way ANOVA on ranks\") is an\n",
      "    omnibus test that does not specify which specific groups of the independent variable are statistically\n",
      "    significantly different from each other. To do this, JASP provides the option for running Dunnâ€™s post\n",
      "    hoc test. These multiple comparison tests can be very conservative, particularly for large numbers of\n",
      "    comparisons.\n",
      "\n",
      "    Load the Kruskal-Wallis ANOVA.csv dataset into JASP. This dataset contains subjective pain scores for\n",
      "    participants undergoing no treatment (control), cryotherapy or combined cryotherapy-compression\n",
      "    for delayed onset muscle soreness after exercise.\n",
      "\n",
      "    RUNNING THE KRUSKAL-WALLIS TEST\n",
      "\n",
      "    Go to ANOVA >ANOVA. In the analysis window, add the Pain score to the dependent variable and\n",
      "    treatment to the fixed factors. Check that the pain score is set to ordinal. This will automatically run\n",
      "    the normal independent ANOVA. Under Assumption Checks, tick both Homogeneity tests and Q-Q\n",
      "    plots.\n",
      "\n",
      "          ANOVA - Pain Score\n",
      "                 Cases    Sum of Squares         df        Mean Square   F  p\n",
      "             Treatment           98.844          2.000     49.422        16.457  <.001\n",
      "             Residual           126.133          42.000    3.003\n",
      "          Note. Type IIl Sum of Squares\n",
      "                                                           Q-Q Plot\n",
      "                                                           2 3\n",
      "    Test for Equality of Variances (Levene's)                           2\n",
      "          F             df1  df2                 p                      1\n",
      "          3.832  2.000       42.000              0.030             2     O\n",
      "\n",
      "    -3 -2 -1 0 1 2 3\n",
      "   Theoretical Quantiles\n",
      "\n",
      "    100 | P a g e\n",
      "\n",
      "\n",
      "    Although the ANOVA indicates a significant result, the data have not met the assumptions of\n",
      "    homogeneity of variance as seen by the significant Leveneâ€™s test and only shows linearity in the middle\n",
      "    of the Q-Q plot and curves off at the extremities, indicating more extreme values. Added to the fact\n",
      "    that the dependent variable is based on subjective pain scores suggests the use of a non-parametric\n",
      "    alternative.\n",
      "\n",
      "    Return to the statistics options and open the Nonparametric option at the bottom. For the Kruskal-\n",
      "    Wallis test, move the Treatment variable to the box on the right and tick Dunnâ€™s post hoc test.\n",
      "\n",
      "    Nonparametrics\n",
      "\n",
      "    Kruskal-Wallis Test\n",
      "                       Diet\n",
      "\n",
      "    Estimates of effect size    âœ“Dunn's post hoc tests\n",
      "\n",
      "    UNDERSTANDING THE OUTPUT\n",
      "\n",
      "    Two tables are shown in the output. The Kruskal-Wallis test shows that there is a significant difference\n",
      "    between the three treatment modalities.\n",
      "\n",
      "                        Kruskal-Wallis Test\n",
      "                        Factor               Statistic         df        p\n",
      "                        Treatment               19.693         2         <.001\n",
      "\n",
      "    Dunn\n",
      "    Dunn's Post Hoc Comparisons - Treatment\n",
      "        Comparison                         Z      Wi           Wj           p     Pbonf       Pholm\n",
      "    Control - Cryo+Compression           4.317      34.600     14.200    <.001***  <.001***  <.001***\n",
      "    Control - Cryotherapy                3.048      34.600     20.200    0.001**  0.003**    0.002**\n",
      "    Cryo+Compression - Cryotherapy  -1.270          14.200     20.200    0.102    0.306      0.102\n",
      "    ** p < .01, *** p < .001\n",
      "\n",
      "    Dunnâ€™s post hoc test provides its p-value as well as those for Bonferroni and Holmâ€™s Bonferroni\n",
      "    correction. As can be seen, both treatment conditions are significantly different from the controls, but\n",
      "    not from each other.\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "    101 | P a g e\n",
      "\n",
      "\n",
      "    Descriptive Statistics\n",
      "                          Pain Score\n",
      "              Control     Cryo+Compression  Cryotherapy\n",
      "    Median     7.000      3.000             3.000\n",
      "    MAD        2.000      1.000             1.000\n",
      "    IQR        4.000      1.500             1.500\n",
      "\n",
      "              Cryotherapy\n",
      "      20 Cryo+Compression\n",
      "\n",
      "                         Control\n",
      "\n",
      "                                -5        0  5  10                 15\n",
      "                                         Pain Score\n",
      "\n",
      "    REPORTING THE RESULTS\n",
      "\n",
      "    Pain scores were significantly affected by treatment modality, H(2) = 19.693, p<.001. Pairwise\n",
      "    comparisons using Dunnâ€™s post hoc showed that both cryotherapy (Mdn = 3) and cryotherapy with\n",
      "    compression (Mdn = 3) significantly reduced pain scores (p=.002 and p<.001, respectively) compared\n",
      "    to the control group (Mdn = 7). There was no significant difference between   cryotherapy and\n",
      "    cryotherapy with compression (p=.102).\n",
      "\n",
      "    102 | P a g e\n",
      "\n",
      "\n",
      "    COMPARING MORE THAN TWO RELATED GROUPS\n",
      "    RMANOVA\n",
      "    The one-way repeated measures ANOVA (RMANOVA) is used to assess if there is a difference in\n",
      "    means between 3 or more groups (where the participants are the same in each group) that have been\n",
      "    tested multiple times or under different conditions. Such a research design, for example, could be that\n",
      "    the same participants were tested for an outcome measure at 1, 2 and 3 weeks or that the outcome\n",
      "    was tested under conditions 1, 2 and 3.\n",
      "\n",
      "    The null hypothesis tested is that there is no significant difference between the means of the\n",
      "    differences between all the groups.\n",
      "\n",
      "    The independent variable should be categorical, and the dependent variable needs to be a continuous\n",
      "    measure. In this analysis, the independent categories are termed levels, i.e. these are the related\n",
      "    groups. So in the case where an outcome was measured at weeks 1, 2 and 3, the 3 levels would be\n",
      "    week 1, week 2 and week 3.\n",
      "\n",
      "    The F-statistic is calculated by dividing the mean squares for the variable (variance explained by the\n",
      "    model) by its error mean squares (unexplained variance). The larger the F-statistic, the more likely it\n",
      "    is that the independent variable will have had a significant effect on the dependent variable.\n",
      "\n",
      "    ASSUMPTIONS\n",
      "\n",
      "    The RMANOVA makes the same assumptions as most other parametric tests.\n",
      "\n",
      "     â€¢     The dependent variable should be approximately normally distributed.\n",
      "     â€¢     There should be no significant outliers.\n",
      "     â€¢     Sphericity relates to the equality of the variances of the differences between levels of the\n",
      "           repeated measures factor.\n",
      "\n",
      "    If the assumptions are violated, then the non-parametric equivalent, Friedmanâ€™s test, should be\n",
      "    considered instead and is described later in this section.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    SPHERICITY\n",
      "\n",
      "    If a study has 3 levels (A, B and C), sphericity assumes the following:\n",
      "\n",
      "              Variance (A-B) â‰ˆ Variance (A-C) â‰ˆ Variance (B-C)\n",
      "\n",
      "    RMANOVA checks the assumption of sphericity using Mauchlyâ€™s (pronounced Mockleyâ€™s) test of\n",
      "    sphericity. This tests the null hypothesis that the variances of the differences are equal. In many\n",
      "    cases, repeated measures violate the assumption of sphericity, which can lead to Type I error. If this\n",
      "    is the case, corrections to the F-statistic can be applied.\n",
      "\n",
      "    JASP offers two methods of correcting the F-statistic, the Greenhouse-Geisser and the Huynh-Feldt\n",
      "    epsilon (Îµ) corrections. A general rule of thumb is that if the Îµ values are <0.75, then use the\n",
      "    Greenhouse-Geisser correction and if they are >0.75 then use the Huynh-Feldt correction.\n",
      "\n",
      "    103 | P a g e\n",
      "\n",
      "                               9                                           JASP\n",
      "\n",
      "    POST HOC TESTING\n",
      "\n",
      "    Post hoc testing is limited in RMANOVA. JASP provides two alternatives:\n",
      "\n",
      "    Bonferroni â€“ can be very conservative but gives guaranteed control over Type I errors at the risk of\n",
      "    reducing statistical power.\n",
      "\n",
      "    Holm â€“ the Holm-Bonferroni test is a sequential Bonferroni method that is less conservative than the\n",
      "    original Bonferroni test.\n",
      "\n",
      "    If you ask for either Tukey or Scheffe post hoc corrections, JASP will return a NaN (not a number) error.\n",
      "\n",
      "    EFFECT SIZE\n",
      "\n",
      "    JASP provides the same alternative effect size calculations that are used with the independent group\n",
      "    ANOVA tests:\n",
      "\n",
      "    Eta squared (Î·Â²) - accurate for the sample variance explained, but overestimates the population\n",
      "    variance. This can make it difficult to compare the effect of a single variable in different studies.\n",
      "\n",
      "    Partial Eta squared (Î·â‚šÂ²) â€“ this solves the problem relating to population variance overestimation,\n",
      "    allowing for comparison of the effect of the same variable in different studies. This appears to be the\n",
      "    most commonly reported effect size in repeated measures ANOVA.\n",
      "\n",
      "    Omega squared (Ï‰Â²) â€“ Normally, statistical bias gets very small as sample size increases, but for small\n",
      "    samples (n<30), Ï‰Â² provides an unbiased effect size measure.\n",
      "\n",
      "    Levels of effect size:\n",
      "\n",
      "     Test                 Measure           Trivial             Small     Medium     Large\n",
      "\n",
      "     ANOVA                Eta               <0.1                0.1       0.25       0.37\n",
      "\n",
      "                          Partial Eta       <0.01               0.01      0.06       0.14\n",
      "\n",
      "                          Omega squared     <0.01               0.01      0.06       0.14\n",
      "\n",
      "    RUNNING THE REPEATED MEASURES ANOVA\n",
      "\n",
      "    Load Repeated ANOVA cholesterol.csv. This contains one column with the participant IDs and 3\n",
      "    columns, one for each repeated measurement of blood cholesterol following an intervention. For\n",
      "    good practice, check the descriptive statistics and the boxplots for any extreme outliers.\n",
      "\n",
      "    Go to ANOVA > Repeated measures ANOVA. As stated above, the independent variable (repeated\n",
      "    measures factor) has levels; in this case, there are 3 levels. Rename RM Factor 1 to Time post-\n",
      "    intervention, and then rename 3 levels to Week 0, Week 3 and Week 6 accordingly.\n",
      "\n",
      "    104 | P a g e\n",
      "\n",
      "                                                        9         JASP\n",
      "\n",
      "    Once these have been done, they will appear in the  Repeated Measures Cells. Now add the\n",
      "    appropriate data to the appropriate level.\n",
      "\n",
      "    Repeated Measures ANOVA\n",
      "\n",
      "     Participant    $\\frac{{ 2 }$                  Repeated Measures Factors\n",
      "     Week 6                                                       Time post intervention\n",
      "                                                       Week O\n",
      "                                                       Week 3\n",
      "                                                       Week 6                           Ã—\n",
      "                                                       Level 4\n",
      "                                                                  RM Factor 2\n",
      "\n",
      "                                                   Repeated Measures Cells\n",
      "                                                        Week 0         Week O\n",
      "                                                        Week 3         Week 3\n",
      "                                                                       Week 6\n",
      "\n",
      "    Tick Descriptive Statistics, Estimates of effect size and Ï‰Â².\n",
      "\n",
      "    Display\n",
      "    âœ“Descriptive statistics\n",
      "    Estimates of effect size\n",
      "    Â¸\n",
      "      wÂ²            partial Ï‰Â²\n",
      "           n^Â²2     partial Î·Â²\n",
      "           general nÂ²2\n",
      "     Vovk-Sellke maximum p-ratio\n",
      "\n",
      "    Under Assumption Checks, tick Sphericity tests and all Sphericity correction options.\n",
      "\n",
      "     Assumption Checks\n",
      "\n",
      "     Sphericity tests\n",
      "     Sphericity corrections\n",
      "     None            Greenhouse-Geisser  Huynh-Feldt\n",
      "     Homogeneity tests\n",
      "\n",
      "    The output should consist of 4 tables. The third table, between-subject effects, can be ignored for\n",
      "    this analysis.\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "    105 | P a g e\n",
      "\n",
      "\n",
      "    UNDERSTANDING THE OUTPUT\n",
      "\n",
      "    Within Subjects Effects\n",
      "                               Sphericity Correction  Sum of Squares   df        Mean Square                    F         p          $w^{}$\n",
      "    Time post intervention     None                    4.320:          2.000:                      2.160:    212.321:     <.001:     0.058\n",
      "                               Greenhouse-Geisser      4.320:          1.235â€¢                      3.497:    212.321:     <.001:     0.058\n",
      "                               Huynh-Feldt             4.320:          1.284â€¢                      3.365â€¢    212.321â€¢     <.001:     0.058\n",
      "    Residual                   None                   0.346           34.000                       0.010\n",
      "                               Greenhouse-Geisser     0.346           21.001                       0.016\n",
      "                               Huynh-Feldt            0.346           21.822                       0.016\n",
      "    Note. Type II Sum of Squares\n",
      "    Mauchly's test of sphericity indicates that the assumption of sphericity is violated (p < .05).\n",
      "\n",
      "    The within-subjects effects table reports a large F-statistic, which is highly significant (p<.001) and has\n",
      "    a small to medium effect size (0.058). This table shows the statistics for sphericity assumed (none) and\n",
      "    the two correction methods. The main differences are in the degrees of freedom (df) and the value of\n",
      "    the mean square. Under the table, it is noted that the assumption of sphericity has been violated.\n",
      "\n",
      "    The following table gives the results of Mauchlyâ€™s test of sphericity. There is a significant difference\n",
      "    (p<.001) in the variances of the differences between the groups. Greenhouse-Geisser and the Huynh-\n",
      "    Feldt epsilon (Îµ) values are below 0.75. Therefore, the ANOVA result should be reported based on the\n",
      "    Greenhouse-Geisser correction:\n",
      "\n",
      "    Assumption Checks\n",
      "    Test of Sphericity\n",
      "                              Mauchly's W  Approx. XÂ²  dfSphericity  p-value  Greenhouse-Geisser E  Huynh-Feldt Îµ  Lower Bound Îµ\n",
      "    Time post intervention    0.381        15.440      2             <.001    0.618                 0.642          0.500\n",
      "\n",
      "    To provide a cleaner table, go back to Assumption Checks and only tick Greenhouse-Geisser for\n",
      "    sphericity correction.\n",
      "\n",
      "\n",
      "    Within Subjects Effects\n",
      "                               Sphericity Correction  Sum of Squares  df  Mean Square               F  p  Ï‰Â²\n",
      "    Time post intervention     Greenhouse-Geisser     4.320:          1.235â€¢                        3.497â€¢  212.321â€¢  <.001:  0.058\n",
      "    Residual                  Greenhouse-Geisser      0.346           21.001                        0.016\n",
      "    Note. Type III Sum of Squares\n",
      "    â€¢ Mauchly's test of sphericity indicates that the assumption of sphericity is violated (p < .05)\n",
      "\n",
      "    There is a significant difference between the means of the differences between all the groups, F\n",
      "    (1.235, 21.0) =212.3, p<.001, Ï‰Â² = 0.058.\n",
      "\n",
      "    106 | P a g e\n",
      "\n",
      "                                                      9           JASP\n",
      "\n",
      "Descriptives\n",
      "    Time post intervention  N     Mean       SD          SE       Coefficient of variation\n",
      "   Week 0                   18    6.408     1.191        0.281    0.186\n",
      "   Week 3                   18     5.842     1.123       0.265    0.192\n",
      "   Week 6                   18     5.779     1.102       0.260    0.191\n",
      "\n",
      "                                   The descriptive data suggest that blood cholesterol levels were higher at week 0 compared to weeks\n",
      "    3 and 6.\n",
      "\n",
      "                                         However, if the ANOVA reports no significant difference, you can go no further in the\n",
      "                                                                               analysis.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    POST HOC TESTING\n",
      "\n",
      "    If the ANOVA is significant, post hoc testing can now be carried out. In Post Hoc Tests, add Time post-\n",
      "    intervention to the analysis box on the right, tick Effect size, and, in this case, use Holm for the post\n",
      "    hoc correction.\n",
      "\n",
      "    Post Hoc Tests\n",
      "\n",
      "                    Time post intervention\n",
      "\n",
      "    Effect size                             Pool error term for follow-up tests\n",
      "    Conditional comparisons for interactions\n",
      "\n",
      "    Correction\n",
      "    Holm\n",
      "     Bonferroni\n",
      "    Tukey\n",
      "    ScheffÃ©\n",
      "    Display\n",
      "     Confidence intervals  95.0  %\n",
      "     Flag significant comparisons\n",
      "\n",
      "    107 | P a g e\n",
      "\n",
      "               9                                                           JASP\n",
      "\n",
      "    Also, in Descriptive Plots, add the Factor â€“ Time post-intervention to the horizontal axis and tick display\n",
      "    error bars.\n",
      "\n",
      "    Post hoc testing shows that there are significant differences in blood cholesterol levels between all of\n",
      "    the time point combinations and are associated with large effect sizes.\n",
      "\n",
      "    Post Hoc Comparisons - Time post intervention\n",
      "                            Mean Difference           SE       t         Cohen's d  Pholm\n",
      "    Week 0    Week 3    0.566                         0.037    15.439    0.497      <.001***\n",
      "              Week 6    0.629                         0.042    14.946    0.552      <.001***\n",
      "    Week 3    Week 6    0.063                         0.017     3.781    0.055      0.001**\n",
      "    ** p < .01, *** p < .001\n",
      "    Note. Computation of Cohen's d based on pooled error.\n",
      "    Note. P-value adjusted for comparing a family of 3\n",
      "\n",
      "    6.6-\n",
      "\n",
      "    5.6\n",
      "       Week 0  Week 3  Week 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    REPORTING THE RESULTS\n",
      "\n",
      "    Mauchlyâ€™s test of sphericity showed a significant difference in variation between the group\n",
      "    differences: W (2) = 0.381, p<.001. Therefore, the Greenhouse-Geisser correction was used. This\n",
      "    showed that cholesterol levels differed significantly between time   points, F(1.235, 21.0) =212.3,\n",
      "    p<.001. Ï‰Â² = 0.058, suggesting that this is a small to medium effect.\n",
      "\n",
      "    Post hoc testing using the Holm correction revealed that cholesterol levels decreased significantly as\n",
      "    time increased, weeks 0 â€“ 3 (M = 0.566, SE = 0.04, p<.001), weeks 1 â€“ 6 (M = 0.63 SE = 0.04, p=.004)\n",
      "    and weeks 3-6 (M=0.06, SE = 0.016).\n",
      "\n",
      "    108 | P a g e\n",
      "                                      9  JASP\n",
      "\n",
      "    FRIEDMANâ€™S REPEATED MEASURES ANOVA\n",
      "    If parametric assumptions are violated or the data is ordinal, you should consider using the non-\n",
      "    parametric alternative, Friedmanâ€™s test. Similar to the Kruskal-Wallis test, Friedmanâ€™s test is used for\n",
      "    one-way repeated measures analysis of variance by ranks and doesnâ€™t assume the data comes from a\n",
      "    particular distribution. This test is another omnibus test that does not specify which specific groups of\n",
      "    the independent variable are statistically significantly different from each other. To do this, JASP\n",
      "    provides the option for running Conoverâ€™s post hoc test if Friedmanâ€™s test is significant.\n",
      "\n",
      "    Load Friedman RMANOVA.csv into JASP. This has 3 columns of subjective pain ratings measured at\n",
      "    18-, 36- and 48-hours post-exercise. Check that the pain scores are set to ordinal data.\n",
      "\n",
      "    RUNNING THE FRIEDMANâ€™S TEST\n",
      "\n",
      "    Go to ANOVA > Repeated measures ANOVA. The independent variable (repeated measures factor)\n",
      "    has 3 levels. Rename RM Factor 1 to Time, and then rename the 3 levels to 18 hours, 36 hours and 48\n",
      "    hours accordingly.\n",
      "\n",
      "    Once these have been done, they will appear in the Repeated Measures Cells. Now add the\n",
      "    appropriate dataset to the appropriate level.\n",
      "\n",
      "    Repeated Measures ANOVA\n",
      "\n",
      "    Subject                                      Repeated Measures Factors\n",
      "                                                                   Time\n",
      "                                                 18 hours\n",
      "                                                 36 hours\n",
      "                                                 48 hours                   Ã—\n",
      "                                                 Level 4\n",
      "                                                             RM Factor 2\n",
      "\n",
      "                                                 Repeated Measures Cells\n",
      "                                                  Pain 18 hours     18 hours\n",
      "                                                  Pain 36 hours     36 hours\n",
      "                                                  Pain 48 hours     48 hours\n",
      "\n",
      "    This will automatically produce the standard repeated measures within-subjects ANOVA table. To run\n",
      "    a Friedmanâ€™s test, expand the Nonparametrics tab, move Time to the RM factor box and tick Conoverâ€™s\n",
      "    post hoc tests.\n",
      "\n",
      "    Nonparametrics\n",
      "    Factors        RM Factor\n",
      "                   Time\n",
      "\n",
      "    Optional Grouping Factor\n",
      "\n",
      "    Conover's post hoc tests\n",
      "    \n",
      "\n",
      "    109 | P a g e\n",
      "\n",
      "    UNDERSTANDING THE OUTPUT\n",
      "\n",
      "    Two tables should be produced.\n",
      "\n",
      "    Nonparametrics\n",
      "\n",
      "    Friedman Test\n",
      "    Factor       $x^}$  df    p   Kendall's W\n",
      "    Time         26.772  2    <.001  0.892\n",
      "\n",
      "    Conover Test\n",
      "    Conover's Post Hoc Comparisons - Time\n",
      "                             T-Stat      df       Wi                      Wj        Trb         p         Pbonf     Pholm\n",
      "    18 hours     36 hours    15.171        28     17.000                  44.500      -1.000    <.001     <.001     <.001\n",
      "\n",
      "    36 hours     48 hours     6.344        28     17.000                  28.500    -0.857      <.001  <.001        <.001\n",
      "                 48 hours     8.827        28     44.500                  28.500       1.000    <.001     <.001     <.001\n",
      "    Note. Grouped by subject.\n",
      "    Note. Rank-biserial correlation based on individual siqned-rank tests.\n",
      "\n",
      "    Friedmanâ€™s test shows that time has a significant effect on pain perception. Connorâ€™s post hoc pairwise\n",
      "    comparisons show that all pain perception is significantly different between each time point.\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "    Descriptive Statistics\n",
      "    Pain 18 hours                  Pain 36 hours  Pain 48 hours\n",
      "    Median                3.000     7.000         3.000\n",
      "    MAD                   1.000     2.000         1.000\n",
      "    IQR                   1.500     4.000         1.500\n",
      "\n",
      "    15\n",
      "\n",
      "20 10\n",
      "    5\n",
      "\n",
      "    0\n",
      "\n",
      "   -5\n",
      "     18 hours 36 hours                       48 hours\n",
      "                                             Time\n",
      "\n",
      "                                                     110 | P a g e\n",
      "\n",
      "\n",
      "    REPORTING THE RESULTS\n",
      "\n",
      "    Friedmannâ€™s test showed that time has a significant effect on subjective pain scores Ï‡Â²F (2) = 26.77,\n",
      "    p<.001. Conoverâ€™s pairwise post hoc comparisons showed that pain perception peaked at 36 hours\n",
      "    (Mdn = 7) and was significantly higher than at 18 hours (Mdn = 3: T(28) = 15.17, p<.001) and then\n",
      "    decreased by 48 hours (Mdn = 3: T(28) = 8.82 p<.001).\n",
      "\n",
      "    111 | P a g e\n",
      "\n",
      "\n",
      "    COMPARING INDEPENDENT GROUPS AND THE EFFECTS OF COVARIATES\n",
      "    ANCOVA\n",
      "\n",
      "    ANOVA can be used to compare the means of one variable (dependent) in two or more groups,\n",
      "    whereas analysis of covariance (ANCOVA) sits between ANOVA and regression and compares the\n",
      "    means of one (dependent) variable in two or more groups while considering the variability of other\n",
      "    continuous variables (COVARIATES). ANCOVA checks for differences in â€˜adjustedâ€™ means (i.e. adjusted\n",
      "    for the effects of the covariate). A covariate may not usually be part of the main research question,\n",
      "    but could influence the dependent variable and therefore needs to be adjusted or controlled for. If a\n",
      "    good covariate is used, ANCOVA will have improved statistical power and control over error.\n",
      "\n",
      "    Control for â€“ to subtract statistically the effects of a variable (a control variable) to see what a\n",
      "    relationship would be without it (Vogt 1977).\n",
      "\n",
      "    Hold constant â€“ to â€œsubtractâ€ the effects of a variable from a complex relationship to study what the\n",
      "    relationship would be if the variable were, in fact, a constant. Holding a variable constant essentially\n",
      "    means assigning it an average value (Vogt 1977).\n",
      "\n",
      "    Statistical control â€“ using statistical techniques to isolate or â€œsubtractâ€ variance in the dependent\n",
      "    variable attributable to variables that are not the subject of the study (Vogt, 1999).\n",
      "\n",
      "    For example, when looking for a difference in weight loss between the three diets, it would be\n",
      "    appropriate to take into account the individuals' pre-trial bodyweight since heavier people may lose\n",
      "    proportionately more weight.\n",
      "\n",
      "    ANCOVA\n",
      "\n",
      "    ANOVA\n",
      "\n",
      "    Independent    Type of diet    Starting body weight\n",
      "    variables      (Factor)        (Covariate)\n",
      "\n",
      "    Dependent    Weight loss\n",
      "    variable\n",
      "\n",
      "    112 | P a g e\n",
      "\n",
      "\n",
      "    The null hypothesis tested is that there is no significant difference between the â€˜adjustedâ€™ means of\n",
      "    all the groups.\n",
      "\n",
      "    ASSUMPTIONS\n",
      "\n",
      "    ANCOVA makes the same assumptions as the independent ANOVA. However, there are two further\n",
      "    assumptions:\n",
      "\n",
      "     â€¢     The relationship between the dependent and covariate variables is linear.\n",
      "     â€¢     Homogeneity of regression, i.e. the regression lines for each of the independent groups are\n",
      "           parallel to each other.\n",
      "\n",
      "                Homogeneity of regression     Assumption violated\n",
      "                                              Homogeneity of regression\n",
      "                                  Diet 1                                            Diet 1\n",
      "\n",
      "                                  Diet 2                                            Diet 2\n",
      "    Dependent variable            Diet 3     Dependent variable\n",
      "\n",
      "                              Diet 3\n",
      "\n",
      "                    Covariate    Covariate\n",
      "\n",
      "    POST HOC TESTING\n",
      "\n",
      "    JASP provides 4 Types\n",
      "\n",
      "     â€¢     Standard â€“ as above\n",
      "     â€¢     Games-Howell â€“ used when you are unsure about the equality of group variances.\n",
      "     â€¢     Dunnettâ€™s â€“ used to compare all the groups to one group, i.e. the control group\n",
      "     â€¢     Dunn â€“ a non-parametric post hoc test used for testing small sub-sets of pairs.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    JASP additionally provides 4 corrections for use with the independent group ANOVA tests:\n",
      "\n",
      "    â€¢     Bonferroni â€“ can be very conservative but gives guaranteed control over Type I errors at the\n",
      "          risk of reducing statistical power.\n",
      "    â€¢     Holm â€“ the Holm-Bonferroni test is a sequential Bonferroni method that is less conservative\n",
      "          than the original Bonferroni test.\n",
      "    â€¢     Tukey â€“ is one of the most commonly used tests and provides controlled Type I error for\n",
      "          groups with the same sample size and equal group variance.\n",
      "    â€¢     Scheffe â€“ controls for the overall confidence level when the group sample sizes are different.\n",
      "\n",
      "    113 | P a g e\n",
      "\n",
      "\n",
      "    EFFECT SIZE\n",
      "\n",
      "    JASP provides 3 alternative effect size calculations for use with the independent group ANOVA tests:\n",
      "\n",
      "       â€¢     Eta squared (Î·Â²)  -  accurate for the sample variance explained,        but overestimates the\n",
      "             population variance. This can make it difficult to compare the effect of a single variable in\n",
      "             different studies.\n",
      "       â€¢     Partial Eta squared (Î·â‚šÂ²)    â€“   this solves the problem relating to  population     variance\n",
      "             overestimation, allowing for comparison of the effect of the same variable in different studies.\n",
      "       â€¢     Omega squared (Ï‰Â²) â€“ Normally, statistical bias gets very small as sample size increases, but\n",
      "             for small samples (n<30), Ï‰Â² provides an unbiased effect size measure.\n",
      "\n",
      "     Test                      Measure              Trivial           Small     Medium        Large\n",
      "     ANOVA                     Eta                  <0.1              0.1       0.25          0.37\n",
      "                               Partial Eta          <0.01             0.01      0.06          0.14\n",
      "                               Omega squared        <0.01             0.01      0.06          0.14\n",
      "\n",
      "    RUNNING THE INDEPENDENT ANCOVA\n",
      "\n",
      "    Load ANCOVA hangover.csv. This dataset has been adapted from the one provided by Andy Field\n",
      "    (2017). The morning after a Fresherâ€™s ball, students were given either water, coffee or a Barocca to\n",
      "    drink.     Two hours later, they reported how well they felt (from 0 â€“ awful to 10 â€“very well). At the\n",
      "    same time, data were collected on how drunk they were the night before (0-10).\n",
      "\n",
      "    Initially, run an ANOVA with wellness as the dependent variable and the type of drink as the fixed\n",
      "    factor.\n",
      "\n",
      "     ANCOVA - wellness\n",
      "       Cases       Sum of Squares             df   Mean Square        F         p\n",
      "      drink              4.267                2      2.133      1.714          0.199\n",
      "      Residuals          33.600               27     1.244\n",
      "     Note. Type III Sum of Squares\n",
      "\n",
      "    As can be seen from the results, homogeneity of variance has not been violated, while the ANOVA\n",
      "    shows that there is no significant difference in the wellness scores between any of the morning drinks.\n",
      "    F(2,27)=1.714, p=.199. However, this may be related to how drunk the students were the night before!\n",
      "\n",
      "    Go to ANOVA > ANCOVA, put wellness as the dependent variable and the type of drink as the fixed\n",
      "    factor. Now add drunkenness to the Covariate(s) box. In the first instance, tick Descriptive statistics\n",
      "    and Ï‰Â² as the effect size;\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "    114 | P a g e\n",
      "\n",
      "\n",
      "    ANCOVA                      Ã—\n",
      "              Dependent Variable\n",
      "              wellness\n",
      "              Fixed Factors\n",
      "              drink\n",
      "\n",
      "    Covariates\n",
      "    drunkeness\n",
      "\n",
      "                                               WLS Weights\n",
      "\n",
      "    Display\n",
      "    ~Descriptive statistics\n",
      "      Estimates of effect size\n",
      "           wÂ²      partial Ï‰Â²2\n",
      "           n^Â²2    partial nÂ²2\n",
      "\n",
      "    In Assumption Checks, tick both options.\n",
      "\n",
      "                   Assumption Checks\n",
      "\n",
      "                   Homogeneity tests\n",
      "                   Q-Q plot of residuals\n",
      "\n",
      "    In Marginal Means, move drink to the right.\n",
      "\n",
      "    Additional Options\n",
      "    Marginal Means                             drink\n",
      "\n",
      "    From 1000 bootstraps\n",
      "    Compare marginal means to 0\n",
      "    Confidence interval adjustmentNone\n",
      "\n",
      "    This should result in 4 tables and one Q-Q plot.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    115 | P a g e\n",
      "\n",
      "                                                                      9        JASP\n",
      "\n",
      "    UNDERSTANDING THE OUTPUT\n",
      "\n",
      "     ANCOVA - wellness\n",
      "      Cases         Sum of Squares               df        Mean Square         F  p                     Ï‰Â²2\n",
      "      drink                    8.503                2                 4.252    7.470   0.003            0.173\n",
      "      drunkeness             18.801                 1         18.801           33.032  <.001            0.427\n",
      "      Residuals              14.799              26                   0.569\n",
      "     Note. Type II Sum of Squares\n",
      "\n",
      "                    Test for Equality of Variances (Levene's)\n",
      "                           F              df1            df2          p\n",
      "                      3.580                 2              27     0.042\n",
      "\n",
      "    The covariate (drunkenness) significantly predicts wellness (p<.001). The effects of the type of drink\n",
      "    on wellness, when adjusted for the effects of drunkenness, are now significant (p=.003).\n",
      "\n",
      "                               3âˆ’\n",
      "                      20       2\n",
      "                              1                               n\n",
      "\n",
      "                              0\n",
      "\n",
      "                             -1\n",
      "\n",
      "                             -2           O\n",
      "\n",
      "                             -3\n",
      "                                   -3     -2     -1      0     1  2            3\n",
      "                                          Theoretical Quantiles\n",
      "\n",
      "    Leveneâ€™s test is significant, unlike in ANOVA, where          no homogeneity of variance corrections (i.e.\n",
      "    Welch) are provided. For ANCOVA, this can be ignored. The Q-Q plot appears to be normal.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Descriptives - wellness\n",
      "      drink         N              Mean              SD           SE            Coefficient of variation\n",
      "     Barocca             10        6.000             1.414        0.447           0.236\n",
      "      Coffee             10        6.000             0.667        0.211           0.111\n",
      "     Water               10        5.200             1.135        0.359           0.218\n",
      "\n",
      "    116 | P a g e\n",
      "\n",
      "                                                                   9         JASP\n",
      "\n",
      "    The descriptive statistics show the unadjusted means for wellness in the three drink groups.\n",
      "\n",
      "    Marginal Means - drink\n",
      "                                     95% Cl for Mean Difference\n",
      "     drink      Marginal Mean        Lower              Upper      SE\n",
      "     Barocca                6.571              6.040     7.103     0.258\n",
      "     Coffee                 5.273              4.718     5.828     0.270\n",
      "     Water                  5.356              4.862     5.849     0.240\n",
      "\n",
      "    The marginal means are now the wellness means, having been adjusted for the effects of the covariate\n",
      "    (drunkenness).\n",
      "\n",
      "    TESTING FURTHER ASSUMPTIONS\n",
      "\n",
      "    As previously mentioned, the assumption of homogeneity of regression is important in ANCOVA. This\n",
      "    can be tested by looking at the interaction between the type of drink and the drunkenness scores. Go\n",
      "    to Model, drink, and drunkenness will have been automatically added as individual Model terms. Now\n",
      "    highlight both drink and drunkenness and add them both to Model terms.\n",
      "\n",
      "     Components                                                   Model Terms\n",
      "              drink                  $$\\frac2 }$                      drink\n",
      "              drunkeness                                              drunkeness\n",
      "                                                                      drink * drunkeness\n",
      "\n",
      "    ANCOVA - welIness\n",
      "              Cases        Sum of Squares  df   Mean Square  F     p                  $w^}$\n",
      "     drink                       2.290     2    1.145    1.876  0.175                 0.047\n",
      "     drunkeness                  4.865     1    4.865    7.971     0.009              0.189\n",
      "     drink * drunkeness          0.150     2    0.075    0.123     0.885              0.000\n",
      "     Residual                    14.649    24   0.610\n",
      "    Note. Type III Sum of Squares\n",
      "    The ANOVA table now has an extra row showing the interaction between the type of drink and\n",
      "    drunkenness. This is not significant (p=.885), i.e. the relationships between drunkenness and wellness\n",
      "    are the same in each drink group. If this is significant, there will be concerns over the validity of the\n",
      "    main ANCOVA analysis.\n",
      "\n",
      "    Having checked this, go back and remove the interaction term from the Model terms.\n",
      "\n",
      "\n",
      "    If the ANCOVA reports no significant difference, you can go no further in the analysis.\n",
      "\n",
      "    117 | P a g e\n",
      "\n",
      "                                            9  JASP\n",
      "\n",
      "    POST HOC TESTING\n",
      "\n",
      "    If the ANCOVA is significant, post hoc testing can now be carried out. In Post Hoc Tests, add Drink to\n",
      "    the analysis box on the right, tick Effect size, and, in this case, use Tukey for the post hoc correction.\n",
      "    Also, tick flag significant comparisons.\n",
      "\n",
      "    Post Hoc Tests\n",
      "\n",
      "                                            drink\n",
      "\n",
      "            Type                                                                 Correction\n",
      "                    Standard                                                     Tukey\n",
      "                     From       1000      bootstraps                             ScheffÃ©\n",
      "                     Effect size                                                 Bonferroni\n",
      "                     Conditional comparisons for interactions                    Holm\n",
      "                    Games-Howell                                                 SidÃ¡k\n",
      "                    Dunnett\n",
      "            Display\n",
      "                    Confidence intervals  95.0  %\n",
      "                    Flag significant comparisons\n",
      "\n",
      "    Standard (HSD)\n",
      "    Post Hoc Comparisons - drink\n",
      "                                      Mean Difference            SE       df     t             Cohen's d  Ptukey\n",
      "     Barocca        Coffee                      1.298            0.406     26         3.198    1.721      0.010**\n",
      "    Coffee          Water                       1.215            0.345     26         3.523    1.611      0.004**\n",
      "                    Water                       -0.083           0.371     26    -0.224        -0.110     0.973\n",
      "   **p < .01\n",
      "    Note. P-value adjusted for comparing a family of 3 estimates.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Post hoc testing shows that there is no significant difference between coffee and water on wellness.\n",
      "    However, wellness scores were significantly higher after drinking a Barocca.\n",
      "\n",
      "    This can be seen from the Descriptive plots.\n",
      "\n",
      "    118 | P a g e\n",
      "\n",
      "\n",
      "    Descriptives Plots\n",
      "    Factors           Horizontal Axis\n",
      "                      drunkeness\n",
      "                      Separate Lines\n",
      "                      drink\n",
      "                      Separate Plots\n",
      "\n",
      "    Display\n",
      "    Display error bars\n",
      "           Confidence intervals 95  %\n",
      "           Standard error\n",
      "\n",
      "                drink\n",
      "    8  â€¢                      Barocca\n",
      "\n",
      "       0   o    â€¢             Coffee\n",
      "    20  O  O    O  â€¢    o     Water\n",
      "\n",
      "    3                  â–¡\n",
      "\n",
      "         1  2 3 4  5 6 7\n",
      "          drunkeness\n",
      "\n",
      "    REPORTING THE RESULTS\n",
      "\n",
      "    The covariate, drunkenness, was significantly related to the morning after wellness, F(1,26) = 33.03,\n",
      "    p<.001, Ï‰Â² = 0.427. There was also a significant effect of the drink on wellness after controlling for\n",
      "    drunkenness, F(2, 26) = 7.47, p=.003, Ï‰Â² = 0.173.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Post hoc testing using Tukeyâ€™s correction revealed that drinking a Barocca resulted in significantly\n",
      "    greater wellness compared to water (p=.004)      and compared to coffee (p=.01. There were no\n",
      "    significant differences in wellness between water and coffee (p=.973).\n",
      "\n",
      "    119 | P a g e\n",
      "\n",
      "\n",
      "    TWO-WAY INDEPENDENT ANOVA\n",
      "    One-way ANOVA tests situations when only one independent variable is manipulated, and two-way\n",
      "    ANOVA is used when more than 1 independent variable has been manipulated. In this case,\n",
      "    independent variables are known as factors.\n",
      "\n",
      "     FACTOR 1        FACTOR 2\n",
      "     CONDITION 1             Group 1           Dependent variable\n",
      "                             Group 2           Dependent variable\n",
      "     CONDITION 2             Group 1           Dependent variable\n",
      "                             Group 2           Dependent variable\n",
      "     CONDITION 3             Group 1           Dependent variable\n",
      "                             Group 2           Dependent variable\n",
      "\n",
      "    The factors are split into levels; therefore, in this case, Factor 1 has 3 levels and Factor 2 has 2 levels.\n",
      "\n",
      "    A â€œmain effectâ€ is the effect of one of the independent variables on the dependent variable, ignoring\n",
      "    the effects of any other independent variables. There are 2 main effects tested, both of which are\n",
      "    â€œbetween-subjectsâ€: in this case, comparing differences between factor 1 (i.e. condition) and\n",
      "    differences between factor 2 (i.e. groups). Interaction is where one factor influences the other factor.\n",
      "\n",
      "    The two-way independent ANOVA is another omnibus test that is used to test 2 null hypotheses:\n",
      "\n",
      "      1.  There is no significant between-subject effect, i.e. no significant difference between the\n",
      "          means of the groups in either of the factors.\n",
      "      2.   There is no significant interaction effect, i.e. no significant group differences across\n",
      "          conditions.\n",
      "\n",
      "    ASSUMPTIONS\n",
      "\n",
      "    Like all other parametric tests, mixed factor ANOVA makes a series of assumptions that should either\n",
      "    be addressed in the research design or can the tested for.\n",
      "\n",
      "     â€¢     The independent variables (factors) should have at least two categorical independent groups\n",
      "           (levels).\n",
      "     â€¢     The dependent variable should be continuous and approximately normally distributed for all\n",
      "           combinations of factors.\n",
      "     â€¢     There should be homogeneity of variance for each of the combinations of factors.\n",
      "     â€¢     There should be no significant outliers.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    RUNNING TWO-WAY INDEPENDENT ANOVA\n",
      "\n",
      "    Open 2-way independent ANOVA.csv in JASP. This comprises 3 columns of data, Factor 1 â€“ gender\n",
      "    with 2 levels (male and female), Factor 2 - supplement with 3 levels (control, carbohydrate CHO and\n",
      "    protein) and the dependent variable (explosive jump power. In Descriptive statistics, check the data\n",
      "    for significant outliers. Go to ANOVA >ANOVA, add Jump power to the Dependent variable, Gender\n",
      "    and Supplement to the Fixed factors.\n",
      "\n",
      "    120 | P a g e\n",
      "\n",
      "\n",
      "    ANOVA                                                         R     x\n",
      "\n",
      "                                 Dependent Variable\n",
      "                                                              Jump power\n",
      "                                 Fixed Factors\n",
      "                                                                  Gender\n",
      "                                                              Supplement\n",
      "\n",
      "    Display\n",
      "    Descriptive statistics\n",
      "     Estimates of effect size\n",
      "           $w{     partial Ï‰Â²\n",
      "           n^Â²2   partial Î·Â²2\n",
      "           Confidence intervals  95.0  %\n",
      "\n",
      "    Tick Descriptive statistics and Estimates of effect size (Ï‰Â²).\n",
      "\n",
      "    In Descriptive plots, add the supplement to the horizontal axis and Gender to separate lines. In\n",
      "    Additional Options,\n",
      "\n",
      "    Descriptives Plots\n",
      "    Factors           Horizontal Axis\n",
      "                                        Supplement\n",
      "                                        Separate Lines\n",
      "                                        Gender\n",
      "                                        Separate Plots\n",
      "\n",
      "    Display\n",
      "    Display error bars\n",
      "               Confidence interval 95  %\n",
      "               Standard error\n",
      "\n",
      "    121 | P a g e\n",
      "\n",
      "\n",
      "    UNDERSTANDING THE OUTPUT\n",
      "\n",
      "    The output should comprise 2 tables and one plot.\n",
      "\n",
      "    ANOVA - Jump power\n",
      "     Cases                    Sum of Squares   df              Mean Square        F         p         Ï‰Â²\n",
      "     Gender                      119108.037           1.000    119108,037         9.589     0.003     0.058\n",
      "     Supplement                  896116.137           2.000    448058.068         36.071    <.001     0.477\n",
      "     Gender * Supplement         275806.438           2.000    137903.219         11.102    <.001     0.138\n",
      "     Residual                    521712.054          42.000    12421.716\n",
      "    Note. Type III Sum of Squares\n",
      "\n",
      "    The ANOVA table shows that there are significant main effects for both Gender and Supplement\n",
      "    (p=0.003 and p<.001, respectively) with medium and large effect sizes, respectively. This suggests that\n",
      "    there is a significant difference in jump power between genders, irrespective of Supplement, and\n",
      "    significant differences between supplements, irrespective of Gender.\n",
      "\n",
      "    There is also a significant interaction between Gender and Supplement (p<.001), which also has a\n",
      "    medium to large effect size (0.138). This suggests that the differences in jump power between genders\n",
      "    are affected somehow by the type of supplement used.\n",
      "\n",
      "    The Descriptive statistics and plot suggest that the main differences are between genders when using\n",
      "    a protein supplement.\n",
      "\n",
      "    Descriptives - Jump power\n",
      "     Gender        Supplement    N             Mean            SD             SE        Coefficient of variation\n",
      "     Female        CHO             7           789.286         102.283        38.660            0.130\n",
      "                   Control         8           877.500         134.563        47.575            0.153\n",
      "     Male          Protein         9           986.667              91.924    30.641            0.093\n",
      "                   CHO             8           901.875         117.502        41.543            0.130\n",
      "                   Control         8           788.125              64.417    22.775            0.082\n",
      "                   Protein         8           1263.125        140.863        49.803            0.112\n",
      "\n",
      "    1400\n",
      "\n",
      "    â€¢\n",
      "\n",
      "    600\n",
      "       Control  CHO  Protein\n",
      "\n",
      "    122 | P a g e\n",
      "\n",
      "                       9                                                   JASP\n",
      "\n",
      "    TESTING ASSUMPTIONS\n",
      "\n",
      "    In Assumption Checks, tick Homogeneity tests and Q-Q plot of residuals.\n",
      "\n",
      "     Assumption Checks\n",
      "\n",
      "     Test for Equality of Variances (Levene's)\n",
      "                       F  df1  df2            p\n",
      "                       1.100  5.000  42.000   0.375\n",
      "\n",
      "    Leveneâ€™s test shows no significant difference in variance within the dependent variable groups; thus,\n",
      "    homogeneity of variance has not been violated.\n",
      "\n",
      "    Q-Q Plot\n",
      "    20 3\n",
      "       2\n",
      "\n",
      "       1\n",
      "       0\n",
      "      -1\n",
      "      -3    C\n",
      "            -3 -2 -1 0 1 2 3\n",
      "               Theoretical Quantiles\n",
      "\n",
      "    The Q-Q plot shows that the data appear to be normally distributed and linear. We can now accept\n",
      "    the ANOVA result since none of these assumptions has been violated.\n",
      "\n",
      "However, if the ANOVA reports no significant difference, you can go no further with the\n",
      "                                       analysis.\n",
      "\n",
      "\n",
      "    SIMPLE MAIN EFFECTS\n",
      "\n",
      "    Go to the analysis options and Simple Main Effects. Here, add Gender to the Simple effect\n",
      "    factor and Supplement to the Moderator Factor 1. Simple main effects are effectively limited\n",
      "    to pairwise comparisons.\n",
      "\n",
      "    123 | P a g e\n",
      "\n",
      "\n",
      "    Simple Main Effects\n",
      "\n",
      "    Factors            Simple Effect Factor\n",
      "                       Gender\n",
      "                       Moderator Factor 1\n",
      "                       Supplement\n",
      "                       Moderator Factor 2\n",
      "\n",
      "    Simple Main Effects - Gender\n",
      "     Level of Supplement  Sum of Squares     df  Mean Square    F          p\n",
      "     Control                    31951.563    1     31951.563     2.572     0.116\n",
      "     CHO                        47325.030    1    47325.030      3.810     0.058\n",
      "     Protein                    323700.184   1    323700.184    26.059     <.001\n",
      "\n",
      "    This table shows that there are no gender differences in jump power between the control and\n",
      "    CHO groups (p=.116 and p=0.058, respectively). However, there is a significant difference\n",
      "    (p<.001) in jump power between genders in the protein supplement group.\n",
      "\n",
      "                          1400\n",
      "\n",
      "    600-\n",
      "        Control  CHO  Protein\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "    CONTRAST TESTING\n",
      "    There are two ways of testing for a difference between (combinations of) cells: post hoc tests\n",
      "    and contrast analysis. JASP has a range of different contrast tests available, including custom\n",
      "    contrasts. For example, we can contrast the three different supplements. Open up the\n",
      "    Contrasts menu, and next to Supplement, click on the drop-down menu and select custom.\n",
      "    This will add another series of options to this window.\n",
      "\n",
      "    124 | P a g e\n",
      "\n",
      "\n",
      "    Contrasts\n",
      "    Factors\n",
      "    Gender         none\n",
      "    Supplement     custom\n",
      "\n",
      "    Custom contrast for Supplement\n",
      "  Add Contrast                    CHO Control  Protein\n",
      "\n",
      "Delete Contrast  Contrast 1 0         0        0\n",
      "\n",
      "     Reset\n",
      "\n",
      "    In this window, contrasts can be added; in this case, three contrasts can be defined:\n",
      "\n",
      "    Custom for Supplement\n",
      "    Add Contrast               Delete Contrast                Reset\n",
      "\n",
      "    Supplement                 Contrast 1         Contrast 2  Contrast 3\n",
      "   1 Control             0                 -1    1\n",
      "   2 CHO                 1                 1     0\n",
      "   3 Protein             -1                0                  -1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Contrast 1 = CHO vs Protein\n",
      "    Contrast 2 = CHO vs Control\n",
      "    Contrast 3 = Control vs Protein\n",
      "\n",
      "    125 | P a g e\n",
      "\n",
      "\n",
      "    This will result in the following tables:\n",
      "\n",
      "    Custom Contrast - Supplement\n",
      "    Comparison  Estimate        SE        df     t         p\n",
      "\n",
      "   1              -273.899      47.755     44    -5.736    <.001\n",
      "   2                13.085      48.403     44     0.270    0.788\n",
      "   3              -286.984      46.908     44    -6.118    <.001\n",
      "\n",
      "    Custom Contrast Coefficients - Supplement\n",
      "     Supplement  Comparison 1  Comparison 2  Comparison 3\n",
      "     Control         0                       -1                   1\n",
      "     CHO         1                           1                    0\n",
      "     Protein        -1                       0                   -1\n",
      "\n",
      "    Comparing this table to the post hoc analysis below, the estimates of the differences in\n",
      "    marginal means are the same, as well as their standard errors and t-statistics. However, both\n",
      "    the p-values and confidence intervals vary: the corrected p-values are typically higher, and\n",
      "    the confidence intervals are wider, for the post hoc analysis.\n",
      "\n",
      "    POST HOC TESTING\n",
      "\n",
      "    If the ANOVA is significant, post hoc testing can now be carried out. In Post Hoc Tests, add Supplement\n",
      "    and the Gender*Supplement to the analysis box on the right, tick Effect size, and, in this case, use\n",
      "    Tukey for the post hoc correction. Also, for ease of viewing, tick Flag significant comparisons.\n",
      "\n",
      "    Post hoc testing is not done for Gender since there are only 2 levels.\n",
      "\n",
      "    Standard\n",
      "    Post Hoc Comparisons - Supplement\n",
      "                             Mean Difference           SE       t             Ptukey\n",
      "     CHO     Control                 12.77             40.10          0.32    0.95\n",
      "              Protein        -279.32                   39.56         -7.06    <.001***\n",
      "     Control  Protein        -292.08                   38.85         -7.52    <.001***\n",
      "    ***p<.001\n",
      "     Note. P-value adjusted for comparing a family of 3\n",
      "     Note. Results are averaged over the levels of: Gender\n",
      "\n",
      "    Post hoc testing shows no significant difference between the control and CHO, supplement group,\n",
      "    irrespective of Gender, but significant differences between Control and Protein (p<.001) and between\n",
      "    CHO and Protein (p<.001).\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "    126 | P a g e\n",
      "\n",
      "\n",
      "    The post hoc comparisons for the interactions decompose the results further:\n",
      "\n",
      "    Post Hoc Comparisons - Gender * Supplement\n",
      "                                             Mean Difference  SE  t                  Ptukey\n",
      "      Female, CHO         Male, CHO             -112.59    57.68           -1.95      0.39\n",
      "                          Female, Control        -88.21    57.68           -1.53       0.65\n",
      "                          Male, Control            1.16    57.68            0.02       1.00\n",
      "                          Female, Protein       -197.38    56.17           -3.51      0.01*\n",
      "                          Male, Protein         -473.84    57.68           -8.21     <.001***\n",
      "      Male, CHO           Female, Control         24.38    55.73            0.44       1.00\n",
      "                          Male, Control          113.75    55.73            2.04       0.34\n",
      "                          Female, Protein        -84.79    54.16           -1.57      0.62\n",
      "                          Male, Protein         -361.25    55.73           -6.48     <.001***\n",
      "      Female, Control     Male, Control           89.37    55.73            1.60       0.60\n",
      "                          Female, Protein       -109.17    54.16           -2.02       0.35\n",
      "                          Male, Protein         -385.63    55.73           -6.92     <.001***\n",
      "      Male, Control       Female, Protein       -198.54    54.16           -3.67    8.41e-3**\n",
      "                          Male, Protein         -475.00    55.73           -8.52     <.001***\n",
      "      Female, Protein     Male, Protein         -276.46    54.16           -5.10     <.001***\n",
      "     *p < .05, ** p < .01, *** p < .001\n",
      "     Note. P-value adjusted for comparing a family of 6\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "    REPORTING THE RESULTS\n",
      "\n",
      "    A two-way ANOVA was used to examine the effect of gender and supplement type on explosive jump\n",
      "    power. There were significant main effects for both gender (F (1, 42) = 9.59, p=.003, Ï‰Â² = 0.058) and\n",
      "    Supplement (F (2, 42) = 36.1, p<.001, Ï‰Â² = 0.477). There was a statistically significant interaction\n",
      "    between the effects of gender and supplement on explosive jump power (F (2, 42) = 11.1, p<.001, Ï‰Â²\n",
      "    = 0.138).\n",
      "\n",
      "    Tukeyâ€™s post hoc correction showed that explosive leg power was significantly higher in the protein\n",
      "    group compared to the control or CHO groups (t=--7.52, p<.001 and t=--7.06, p<.001 respectively).\n",
      "\n",
      "    Simple main effects showed that jump power was significantly higher in males on a protein\n",
      "    supplement (M = 1263, SD = 140) compared to females (M = 987, SD = 92, F (1) =26.06, p<.001).\n",
      "\n",
      "    127 | P a g e\n",
      "\n",
      "\n",
      "    TWO-WAY REPEATED MEASURES ANOVA\n",
      "    Two-way repeated Measures ANOVA means that there are two factors in the experiment, for example,\n",
      "    different treatments and different conditions. \"Repeated measures\" means that the same subject\n",
      "    received more than one treatment and/or more than one condition.\n",
      "\n",
      "     Independent                             Independent variable (Factor 1) = time\n",
      "     variable (Factor 2)     Participant     Time 1        Time 2                  Time 3\n",
      "     Condition 1             1               Dependent     Dependent               Dependent\n",
      "                                             variable      variable                variable\n",
      "                             2               Dependent     Dependent               Dependent\n",
      "                                             variable      variable                variable\n",
      "                             3               Dependent     Dependent               Dependent\n",
      "                                             variable      variable                variable\n",
      "     Condition 2             1               Dependent     Dependent               Dependent\n",
      "                                             variable      variable                variable\n",
      "                             2               Dependent     Dependent               Dependent\n",
      "                                             variable      variable                variable\n",
      "                             3               Dependent     Dependent               Dependent\n",
      "                                             variable      variable                variable\n",
      "\n",
      "    The factors are split into levels; therefore, in this case, Factor 1 has 3 repeated levels and Factor 2 has\n",
      "    2 repeated levels.\n",
      "\n",
      "    A â€œmain effectâ€ is the effect of one of the independent variables on the dependent variable, ignoring\n",
      "    the effects of any other independent variables. There are 2 main effects tested, both of which are\n",
      "    â€œbetween-subjectsâ€: in this case, comparing differences between factor 1 (i.e. condition) and\n",
      "    differences between factor 2 (i.e. groups). Interaction is where one factor influences the other factor.\n",
      "\n",
      "    The two-way repeated ANOVA is another omnibus test that is used to test the following main effect\n",
      "    null hypotheses:\n",
      "\n",
      "    H01: The dependent variable scores are the same for each level in factor 1 (ignoring factor 2).\n",
      "\n",
      "    H02: The dependent variable scores are the same for each level in factor 2 (ignoring factor 1).\n",
      "\n",
      "    The null hypothesis for the interaction between the two factors is:\n",
      "\n",
      "    H03: The two factors are independent, or that an interaction effect is not present.\n",
      "\n",
      "    ASSUMPTIONS\n",
      "\n",
      "    Like all other parametric tests, two-way repeated ANOVA makes a series of assumptions that should\n",
      "    either be addressed in the research design or can the tested for.\n",
      "\n",
      "    â€¢     The independent variables (factors) should have at least two categorical related groups\n",
      "          (levels).\n",
      "\n",
      "    128 | P a g e\n",
      "\n",
      "                                                       9  JASP\n",
      "\n",
      "     â€¢         The dependent variable should be continuous and approximately normally distributed for all\n",
      "               combinations of factors.\n",
      "     â€¢         Sphericity, i.e. the variances of the differences between all combinations of related groups\n",
      "               must be equal.\n",
      "     â€¢         There should be no significant outliers.\n",
      "\n",
      "    RUNNING TWO-WAY REPEATED MEASURES ANOVA\n",
      "\n",
      "    Open 2-way repeated ANOVA.csv in JASP. This comprises 4 columns of data (â€œsit and reachâ€ flexibility\n",
      "    scores for two factors, Factor 1 with 2 levels (stretch and no stretch) and Factor 2 with 2 levels (warm-\n",
      "    up and no warm-up). In Descriptive statistics, check the data for significant outliers. Go to ANOVA >\n",
      "    Repeated Measures ANOVA. Firstly, each Factor and its levels should be defined. For RM Factor 1 â€“\n",
      "    define this as Stretching and its levels as stretch and no stretch. Then define RM Factor 2 as Warm-up\n",
      "    and its levels as warm-up and no warm-up. Then add the appropriate column of data to the assigned\n",
      "    repeated measures cells.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "     Descriptives Plots\n",
      "\n",
      "    Factors                                               Horizontal Axis\n",
      "                                                          Stretching\n",
      "                                                          Separate Lines\n",
      "                                                          Warm up\n",
      "                                                       Separate Plots\n",
      "\n",
      "    Display\n",
      "    Error bars\n",
      "           Confidence interval  95.0  %\n",
      "\n",
      "    Also, tick Descriptive statistics and estimates of effect size - Ï‰Â².\n",
      "\n",
      "    Display\n",
      "    âœ“ Descriptive statistics\n",
      "     Estimates of effect size\n",
      "           ) wÂ²2   partial Ï‰2\n",
      "           nÂ²     partial nÂ²2\n",
      "           general Î·Â²\n",
      "    Vovk-Sellke maximum p-ratio\n",
      "\n",
      "    129 | P a g e\n",
      "\n",
      "                                                          9         JASP\n",
      "\n",
      "    In Descriptive plots, add the Stretching factor to the horizontal axis and the Warm-up factor\n",
      "    to separate lines. Tick the display error bars option.\n",
      "\n",
      "    Descriptives Plots\n",
      "\n",
      "    Factors                                               Horizontal Axis\n",
      "                                                          Stretching\n",
      "                                                          Separate Lines\n",
      "                                                          Warm up\n",
      "                                                          Separate Plots\n",
      "\n",
      "    Label y-axis\n",
      "\n",
      "    Display\n",
      "    âœ“ Display error bars       Average across unused RM factors\n",
      "           Confidence interval 95  %\n",
      "           Standard error\n",
      "\n",
      "    UNDERSTANDING THE OUTPUT\n",
      "\n",
      "    The output should comprise 3 tables and one plot. The Between-Subjects Effects table can be ignored\n",
      "    in this analysis.\n",
      "\n",
      "     Within Subjects Effects\n",
      "                            Sum of Squares  df    Mean Square  F         p         wÂ²\n",
      "      Stretch                     246.43    1     246.432     123.40     <.001     0.647\n",
      "      Residual             21.97            11        1.997\n",
      "      Warm up              85.71            1        85.707    68.69     <.001     0.404\n",
      "      Residual             13.72            11        1.248\n",
      "      Stretch * Warm up    34.99            1        34.987    29.64     <.001     0.215\n",
      "      Residual             12.98            11        1.180\n",
      "     Note. Type III Sum of Squares\n",
      "\n",
      "    The ANOVA within-subjects effects table shows that there are significant main effects for both stretch\n",
      "    (p<.001) and warm-up (p<.001) on sit and reach distance. Both are associated with large effect sizes.\n",
      "    There is also a significant interaction between stretch and warm-up (p<.001), which suggests that the\n",
      "    effects of performing a stretch on sit and reach distance are different depending on whether a warm-\n",
      "    up had been performed. These findings can be seen in both the descriptive data and the plot.\n",
      "\n",
      "    130 | P a g e\n",
      "\n",
      "                                                   9                  JASP\n",
      "\n",
      "    Descriptives\n",
      "    Stretching     Warm up       N      Mean       SD        SE       Coefficient of variation\n",
      "    Stretch        Warm up       12     15.029     1.551     0.448     0.103\n",
      "                   No warm up    12     10.649     2.121     0.612     0.199\n",
      "    No stretch     Warm up       12      8.790     1.892     0.546     0.215\n",
      "                   No warm up    12      7.825     1.750     0.505     0.224\n",
      "\n",
      "    16    Warm up\n",
      "          O Warm up\n",
      "          No warm up\n",
      "\n",
      "    6\n",
      "                       Stretch  No stretch\n",
      "                       Stretching         l\n",
      "\n",
      "    TESTING ASSUMPTIONS\n",
      "    In this case, there are no assumption checks. Sphericity can only be tested when there are at\n",
      "    least three levels, and homogeneity requires at least two unrelated data sets. If a factor has\n",
      "    more than 2 levels, Mauchlyâ€™s test of Sphericity should also be run, and the appropriate\n",
      "    corrected F value used if necessary (See Repeated Measures ANOVA for details).\n",
      "\n",
      "\n",
      "\n",
      "However, if the ANOVA reports no significant difference, you can go no further with the\n",
      "                                       analysis.\n",
      "\n",
      "    131 | P a g e\n",
      "                       9  JASP\n",
      "\n",
      "    SIMPLE MAIN EFFECTS\n",
      "\n",
      "    Now go to the analysis options and Simple Main Effects. Here, add Warm up to the Simple effect factor\n",
      "    and Stretch to the Moderator Factor 1. Simple main effects are effectively pairwise comparisons.\n",
      "\n",
      "    Simple Main Effects\n",
      "\n",
      "    Factors            Simple Effect Factor\n",
      "                       Warm up\n",
      "                       Moderator Factor 1\n",
      "                       Stretching\n",
      "                       Moderator Factor 2\n",
      "\n",
      "    Pool error terms\n",
      "\n",
      "    Simple Main Effects - Warm up\n",
      "     Level of Stretch  Sum of Squares  df       Mean Square  F  p\n",
      "     Stretch           115.106             1    115.106      112.673  <.001\n",
      "     No stretch                  5.587     1      5.587      3.973    0.072\n",
      "    Note. Type III Sum of Squares\n",
      "\n",
      "    This table shows that when moderating for warm-up there is a significant difference (p<.001) in sit\n",
      "    and reach performance when a stretch was also carried out but not without a stretch (p=.072).\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "    16\n",
      "\n",
      "    6\n",
      "     Stretch  No stretch\n",
      "              Stretch\n",
      "\n",
      "    132 | P a g e\n",
      "                                                            9  JASP\n",
      "\n",
      "    We can now moderate for stretch by changing the Simple Main Effects to use Stretch as the simple\n",
      "    effect factor and warm-up as the moderator factor. We can also replot the descriptives with a warm-\n",
      "    up on the horizontal axis and stretch as separate lines.\n",
      "\n",
      "     Simple Main Effects - Stretch\n",
      "      Level of Warm up  Sum of Squares    df                Mean Square  F         p\n",
      "      Warm up                    233.56    1                233.56    234.18       < .001\n",
      "      No warm up                  47.86    1                   47.86   21.95       <.001\n",
      "     Note. Type III Sum of Squares\n",
      "\n",
      "    In this case, when controlling for Stretch, there were significant differences between both warm-up\n",
      "    and no warm-up.\n",
      "\n",
      "                    16            A                                      Stretching\n",
      "\n",
      "                                                                         O Stretch\n",
      "                                                                         No stretch\n",
      "\n",
      "    T\n",
      "\n",
      "    6\n",
      "     Warm up  No warm up\n",
      "     Warm up\n",
      "    Both simple main effects can be visualised in their descriptive plots.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    The data can be further visualised using Raincloud plots.\n",
      "\n",
      "    Raincloud Plots\n",
      "\n",
      "    Factors                                                  Horizontal Axis\n",
      "                                                             Stretching\n",
      "                                                             Separate Plots\n",
      "                                                             Warm up\n",
      "\n",
      "    133 | P a g e\n",
      "\n",
      "\n",
      "    Dependent: Warm up: Warm up\n",
      "    20\n",
      "    âˆ’\n",
      "\n",
      "    15-\n",
      "\n",
      "    10\n",
      "\n",
      "    5 -\n",
      "\n",
      "    0 -\n",
      "        Stretch    No stretch\n",
      "                   Stretching\n",
      "\n",
      "    Dependent: Warm up: No warm up\n",
      "    20\n",
      "\n",
      "    15\n",
      "\n",
      "    10 -\n",
      "\n",
      "    5\n",
      "\n",
      "    0\n",
      "    Stretch         No stretch\n",
      "                    Stretching\n",
      "\n",
      "    POST HOC TESTING\n",
      "\n",
      "    If the ANOVA is significant, post hoc testing can now be carried out. In Post Hoc Tests, add stretch,\n",
      "    warm-up and the Stretching*warm-up interaction to the analysis box on the right, tick Effect size, and,\n",
      "    in this case, use Holm for the post hoc correction. Tick Flag significant comparisons.\n",
      "\n",
      "    134 | P a g e\n",
      "\n",
      "\n",
      "    Post Hoc Tests\n",
      "\n",
      "                  Stretching\n",
      "                  Warm up\n",
      "                  Stretching * Warm up\n",
      "\n",
      "              Effect size                               Pool error term for follow-up tests\n",
      "              Conditional comparisons for interactions\n",
      "\n",
      "     Correction\n",
      "               Holm\n",
      "               Bonferroni\n",
      "               Tukey\n",
      "               ScheffÃ©\n",
      "     Display\n",
      "               Confidence intervals  95.0  %\n",
      "               Flag significant comparisons\n",
      "               Letter-based grouping table Î±-level: 0.05\n",
      "\n",
      "    Post hoc testing for the main effects confirms that there are significant differences in sit and reach\n",
      "    distance when comparing the two levels of each factor. This is further decomposed in the Post hoc\n",
      "    comparisons for the interaction.\n",
      "\n",
      "    Post Hoc Comparisons - Stretching\n",
      "                                     Mean Difference    SE  t                              Cohen's d  Pholm\n",
      "     Stretch     No stretch                4.532        0.408  11.109                      2.463      <.001***\n",
      "     *** p < .001\n",
      "     Note. Computation of Cohen's d based on pooled error.\n",
      "     Note. Results are averaged over the levels of: Warm up\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Post Hoc Comparisons - Warm up\n",
      "                Mean Difference                          SE  t  Cohen's d  Pholm\n",
      "    Warm up     No warm up        2.672                  0.322  8.288  1.452  <.001***\n",
      "    *** p < .001\n",
      "    Note. Computation of Cohen's d based on pooled error.\n",
      "    Note. Results are averaged over the levels of: Stretching\n",
      "\n",
      "    135 | P a g e\n",
      "\n",
      "\n",
      "    Post Hoc Comparisons - Stretching * Warm up\n",
      "                                                       Mean Difference     SE       t           Pholm\n",
      "     Stretch, Warm.up        No.Stretch, Warm.up        6.239              0.515    12.125    < .001***\n",
      "                             Stretch, No.warm.up        4.380              0.450     9.737     <.001***\n",
      "                             No.Stretch, No.warm.up     7.204              0.520    13.854     <.001***\n",
      "     No.Stretch, Warm.up     Stretch, No.warm.up       -1.859              0.520    -3.575     0.004**\n",
      "                             No.Stretch, No.warm.up     0.965              0.450     2.145    0.043*\n",
      "     Stretch, No.warm.up     No.Stretch, No.warm.up     2.824             0.515      5.488     <.001***\n",
      "    * p < .05, ** p < .01, *** p < .001\n",
      "    Note. P-value adjusted for comparing a family of 6\n",
      "\n",
      "    REPORTING THE RESULTS\n",
      "\n",
      "    A two-way ANOVA was used to examine the effect of stretch and warm-up type on sit and teach\n",
      "    performance. There were significant main effects for stretch (F (1, 11) = 123.4, p<.001, Ï‰Â² = 0.647) and\n",
      "    warm-up (F (1, 11) = 68.69, p<.001, Ï‰Â² = 0.404). There was a statistically significant interaction\n",
      "    between the effects of stretch and warm-up on sit and reach performance (F (1, 11) = 29.64, p<.001,\n",
      "    Ï‰Â² = 0.215).\n",
      "\n",
      "    Simple main effects showed that sit and reach performance was significantly higher when both a\n",
      "    stretch and warm-up had been done (F (1) =234, p<.001).\n",
      "\n",
      "    136 | P a g e\n",
      "\n",
      "                                                      9                     JASP\n",
      "\n",
      "    MIXED FACTOR ANOVA\n",
      "    Mixed factor ANOVA (another two-way ANOVA) is a combination of both independent and\n",
      "    repeated measures ANOVA involving more than 1 independent variable (known as factors).\n",
      "\n",
      "     Independent variable     Independent variable (Factor 1) = time or condition\n",
      "     (Factor 2)               Time/condition 1        Time/condition 2       Time/condition 3\n",
      "     Group 1                  Dependent variable      Dependent variable     Dependent variable\n",
      "     Group 2                  Dependent variable      Dependent variable     Dependent variable\n",
      "\n",
      "    The factors are split into levels; therefore, in this case, Factor 1 has 3 levels and Factor 2 has\n",
      "    2 levels. This results in 6 possible combinations.\n",
      "    A â€œmain effectâ€ is the effect of one of the independent variables on the dependent variable,\n",
      "    ignoring the effects of any other independent variables. There are 2 main effects tested: in\n",
      "    this case, comparing data across factor 1 (i.e. time) is known as the â€œwithin-subjectsâ€ factor,\n",
      "    while comparing differences between factor 2 (i.e. groups) is known as the â€œbetween-\n",
      "    subjectsâ€ factor. Interaction is where one factor influences the other factor.\n",
      "    The main effect of time or condition tests the following, i.e. irrespective of which group is in\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "     Independent variable     Independent variable (Factor 1) = time or condition\n",
      "     (Factor 2)               Time/condition 1     Time/condition 2     Time/condition 3\n",
      "     Group 1                  All data             All data             All data\n",
      "     Group 2\n",
      "                                           *                   *\n",
      "                                                    *\n",
      "    The main effect of group tests is the following, i.e. irrespective of which condition the data is\n",
      "    in:\n",
      "      Independent variable     Independent variable (Factor 1) = time or condition\n",
      "      (Factor 2)               Time/condition 1     Time/condition 2     Time/condition 3\n",
      "      Group 1                  All data                                  *\n",
      "      Group 2                  All data\n",
      "\n",
      "    Simple main effects are effectively pairwise comparisons:\n",
      "      Independent variable     Independent variable (Factor 1) = time or condition\n",
      "      (Factor 2)               Time/condition 1     Time/condition 2     Time/condition 3\n",
      "      Group 1                  Data        *        Data       *         Data     *\n",
      "      Group 2                  Data                 Data                 Data\n",
      "\n",
      "    137 | P a g e\n",
      "\n",
      "\n",
      "    A mixed factor ANOVA is another omnibus test that is used to test 3 null hypotheses:\n",
      "    3.  There is no significant within-subject effect, i.e. no significant difference between\n",
      "        the means of the differences between all the conditions/times.\n",
      "    4.  There is no significant between-subject effect, i.e. no significant difference between\n",
      "        the means of the groups.\n",
      "    5.  There is no significant interaction effect, i.e. no significant group differences across\n",
      "        conditions/time.\n",
      "\n",
      "    ASSUMPTIONS\n",
      "    Like all other parametric tests, mixed factor ANOVA makes a series of assumptions that should\n",
      "    either be addressed in the research design or can the tested for.\n",
      "\n",
      "     â€¢  The â€œwithin-subjectsâ€ factor should contain at least two related (repeated measures)\n",
      "        categorical groups (levels)\n",
      "     â€¢  The â€œbetween-subjectsâ€ factor should have at least two categorical independent\n",
      "        groups (levels).\n",
      "     â€¢  The dependent variable should be continuous and approximately normally distributed\n",
      "        for all combinations of factors.\n",
      "     â€¢  There should be homogeneity of variance for each of the groups, and, if more than 2\n",
      "        levels) sphericity between the related groups.\n",
      "     â€¢  There should be no significant outliers.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    RUNNING THE MIXED FACTOR ANOVA\n",
      "    Open 2-way Mixed ANOVA.csv in JASP. This contains 4 columns of data relating to the type\n",
      "    of weightlifting grip and speed of the lift at 3 different loads (%1RM). Column 1 contains the\n",
      "    grip type, and columns 2-4 contain the 3 repeated measures (30, 50 and 70%). Check for\n",
      "    significant outliers using boxplots, then go to ANOVA > Repeated measures ANOVA.\n",
      "    Define the Repeated Measures Factor, %1RM, and add 3 levels (30, 50 and 70%). Add the\n",
      "    appropriate variable to the Repeated measures Cells and add Grip to the Between-Subjects\n",
      "    Factors:\n",
      "\n",
      "    138 | P a g e\n",
      "\n",
      "\n",
      "    Repeated Measures ANOVA\n",
      "                           Repeated Measures Factors\n",
      "                                   %1RM\n",
      "                        30%\n",
      "                        50%\n",
      "                        70%                         Ã—\n",
      "                           Level 4\n",
      "                                   RM Factor 2\n",
      "\n",
      "                           Repeated Measures Cells\n",
      "                           RM30    30%\n",
      "                           RM50    50%\n",
      "                           RM70    70%\n",
      "\n",
      "    Between Subject Factors\n",
      "    Grip\n",
      "\n",
      "    Additionally, tick Descriptive statistics and Estimates of effect size (Ï‰2).\n",
      "\n",
      "    Display\n",
      "    ~Descriptive statistics\n",
      "    Estimates of effect size\n",
      "               wÂ² partial Ï‰Â²\n",
      "           n^Â²2  partial Î·Â²2\n",
      "           general Î·Â²2\n",
      "    Vovk-Sellke maximum p-ratio\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    In Descriptive plots, move %1RM to the horizontal axis and Grip to separate lines. It is now\n",
      "    possible to add a title for the vertical axis.\n",
      "\n",
      "    Descriptives Plots\n",
      "    Factors                              Horizontal Axis\n",
      "                                         %1RMax\n",
      "                                         Separate Lines\n",
      "                                         Grip\n",
      "                                         Separate Plots\n",
      "\n",
      "    Label y-axisVelocity\n",
      "    Display\n",
      "    Display error bars    Average across unused RM factors\n",
      "               Confidence interval  95  %\n",
      "               Standard error\n",
      "\n",
      "    139 | P a g e\n",
      "\n",
      "\n",
      "    UNDERSTANDING THE OUTPUT\n",
      "    The output should initially comprise 3 tables and 1 graph.\n",
      "\n",
      "    Within Subjects Effects\n",
      "                   Sum of Squares    df     Mean Square       F            p                        $w{}\n",
      "    %1RM                   5.605â€¢     2:     2.803:           115.450:     <.001:                   0.744\n",
      "    %1RM * Grip            0.583â€¢     2:     0.291â€¢           12.003:      <.001:                   0.218\n",
      "    Residual               0.874     36      0.024\n",
      "    Note. Type II Sum of Squares\n",
      "    â€¢ Mauchly's test of sphericity indicates that the assumption of sphericity is violated (p < .05)\n",
      "\n",
      "    For the main effect for %1RM, the within-subjects effects table reports a large F-statistic,\n",
      "    which is highly significant (p<.001) and has a large effect size (0.744). Therefore, irrespective\n",
      "    of grip type, there is a significant difference between the three %1RM loads.\n",
      "    However, JASP has reported under the table that the assumption of sphericity has been\n",
      "    violated. This will be addressed in the next section.\n",
      "    Finally, there is a significant interaction between %1RM and grip (p<.001), which also has a\n",
      "    large effect size (0.499). This suggests that the differences between the %1RM loads are\n",
      "    affected somehow by the type of grip used.\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "    Between Subjects Effects\n",
      "     Cases        Sum of Squares    df    Mean Square        F  p                Ï‰Â²\n",
      "     Grip                  1.095    1               1.095    20.925  <.001       0.344\n",
      "     Residuals             0.942    18              0.052\n",
      "    Note. Type II Sum of Squares\n",
      "\n",
      "    For the main effect of grip, the between-subjects table shows a significant difference between\n",
      "    grips (p< .001), irrespective of %1RM.\n",
      "    From the descriptive data and the plot, it appears that there is a larger difference between\n",
      "    the two grips at the high 70% RM load.\n",
      "\n",
      "    140 | P a g e\n",
      "\n",
      "\n",
      "    Descriptives\n",
      "    %1RM        Grip           N      Mean       SD        SE       Coefficient of variation\n",
      "    30%         Reverse         10     1.279     0.178     0.056    0.139\n",
      "                Traditional     10     1.482     0.217     0.069    0.146\n",
      "    50%         Reverse         10     1.114     0.198     0.063    0.178\n",
      "    70%         Traditional     10     1.183     0.256     0.081    0.216\n",
      "                Reverse         10     0.379     0.105     0.033    0.278\n",
      "                Traditional     10     0.917     0.086     0.027    0.093\n",
      "\n",
      "    1.6    Grip\n",
      "           Reverse\n",
      "\n",
      "    0      Traditional\n",
      "\n",
      "    0.2\n",
      "                       30%  50%  70%\n",
      "                           %1RMax\n",
      "    TESTING ASSUMPTIONS\n",
      "    In Assumptions Checks, tick Sphericity tests, Sphericity corrections and Homogeneity tests.\n",
      "\n",
      "    Assumption Checks\n",
      "\n",
      "    Sphericity tests\n",
      "    Sphericity corrections\n",
      "    None            Greenhouse-Geisser  Huynh-Feldt\n",
      "    ) Homogeneity tests\n",
      "    Test of Sphericity\n",
      "    Mauchly's W        Approx, XÂ²  df  p-value    Greenhouse-Geisser E  Huynh-Feldt Îµ  Lower Bound Îµ\n",
      "    %1RM              0.649  7.360  2    0.025              0.740       0.791          0.500\n",
      "\n",
      "    Mauchlyâ€™s test of sphericity is significant, so that assumption has been violated; therefore,\n",
      "    the Greenhouse-Geisser correction should be used since epsilon is <0.75. Go back to\n",
      "    Assumption Checks and in Sphericity corrections, leave Greenhouse-Geisser only ticked. This\n",
      "    will result in an updated Within-Subjects Effects table:\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "    141 | P a g e\n",
      "\n",
      "                                                                       9                             JASP\n",
      "\n",
      "     Within Subjects Effects\n",
      "      Cases       Sphericity Correction    Sum of Squares     df       Mean Square                   F           p         $w{}\n",
      "      %1RM           Greenhouse-Geisser         5.605         1.480    3.787                         115.450     <.001     0.744\n",
      "      %1RM * Grip    Greenhouse-Geisser         0.583         1.480    0.394                          12.003     <.001     0.218\n",
      "      Residuals      Greenhouse-Geisser         0.874        26.639    0.033\n",
      "     Note. Type III Sum of Squares\n",
      "     â€¢ Mauchly's test of sphericity indicates that the assumption of sphericity is violated (p < .05)\n",
      "\n",
      "    Leveneâ€™s test shows that there is no difference in variance in the dependent variable between\n",
      "    the two grip types.\n",
      "\n",
      "                            Test for Equality of Variances (Levene's)\n",
      "                                           F                 df1       df2                           p\n",
      "                            RM3D           0.523             1.000     18.000                        0.479\n",
      "                            RM50           0.346             1.000     18.000                        0.564\n",
      "                            RM70           0.183             1.000     18.000                        0.674\n",
      "\n",
      "                                                             However, if the ANOVA reports no significant difference, you can go no\n",
      "                                                                                    further in the analysis.\n",
      "\n",
      "\n",
      "    POST HOC TESTING\n",
      "    If the ANOVA is significant, post hoc testing can now be carried out. In Post Hoc Tests, add\n",
      "    %1RM to the analysis box on the right, tick Effect size, and, in this case, use Holm for the post\n",
      "    hoc correction. Only Bonferroni or Holmâ€™s corrections are available for repeated measures.\n",
      "\n",
      "    Post Hoc Tests\n",
      "\n",
      "     Grip           I2}$    %1RM\n",
      "     Grip * %1RM\n",
      "\n",
      "    Confidence intervals  95.0  %\n",
      "    Effect size  Pool error term for RM factors\n",
      "\n",
      "    Correction\n",
      "    Holm\n",
      "    Bonferroni\n",
      "    Tukey\n",
      "    Scheffe\n",
      "    Display\n",
      "    Flag Significant Comparisons\n",
      "\n",
      "    142 | P a g e\n",
      "\n",
      "\n",
      "    Post Hoc Tests\n",
      "\n",
      "     Post Hoc Comparisons - %1RM\n",
      "                         Mean Difference                SE        df    t         Cohen's d  Pholm\n",
      "     30%       50%              0.232                   0.060     18     3.881     1.266     0.001\n",
      "               70%              0.733                   0.033     18    22.040     3.995     <.001\n",
      "     50%       70%              0.500                   0.051     18    9.814      2.728     <.001\n",
      "     Note. P-value adjusted for comparing a family of 3 estimates.\n",
      "     Note. Results are averaged over the levels of: Grip\n",
      "\n",
      "    The post hoc tests show that, irrespective of grip type, each load is significantly different from each of\n",
      "    the other loads, and as seen from the plot, lift velocity significantly decreases as the load increases.\n",
      "\n",
      "                  1.6                                                             Grip\n",
      "                                                                                  Reverse\n",
      "\n",
      "            0                                                                     Traditional\n",
      "\n",
      "             0.2\n",
      "                       30%  50%  70%\n",
      "                            %1RMax\n",
      "\n",
      "    Finally, in Simple main effects, add Grip to the Simple effect factor and %1RM to the\n",
      "    Moderator factor 1.\n",
      "\n",
      "             Simple Main Effects\n",
      "\n",
      "    Factors                          Simple Effect Factor\n",
      "                                     Grip\n",
      "                                     Moderator Factor 1\n",
      "                                     %1RMax\n",
      "                                     Moderator Factor 2\n",
      "\n",
      "             Pool error terms\n",
      "\n",
      "    143 | P a g e\n",
      "\n",
      "\n",
      "    Simple Main Effects - Grip\n",
      "    Level of % 1RM  Sum of Squares    df    Mean Square     F         p\n",
      "    30%                       0.206    1     0.206          5.229     0.035\n",
      "    50%                       0.024    1     0.024          0.461     0.506\n",
      "    70%                       1.447    1     1.447         157.212   <.001\n",
      "\n",
      "    These results show that there is a significant difference in lift speed between the two grips at\n",
      "    30% 1RM and the higher 70% 1RM loads (p=0.035 and p<0.001, respectively).\n",
      "\n",
      "    REPORTING THE RESULTS\n",
      "    Using the Greenhouse-Geisser correction, there was a significant main effect of load: F(1.48,\n",
      "    26.64) = 115.45, p<.001. Bonferroni corrected post hoc testing showed that there was a\n",
      "    significant sequential decline in lift speed from 30-50% 1RM (p=.035) and 50-70% 1RM\n",
      "    (p<.001).\n",
      "    There was a significant main effect for grip type: F( 1, 18) = 20.925, p<.001, showing an overall\n",
      "    higher lift speed using the traditional rather than the reverse grip.\n",
      "    Using the Greenhouse-Geisser correction, there was a significant %1RM x Grip interaction: F\n",
      "    (1.48, 26.64) = 12.00, p<.001) showing that the type of grip affected lift velocity over the\n",
      "    %1RM loads.\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "    144 | P a g e\n",
      "\n",
      "\n",
      "    CHI-SQUARE TEST FOR ASSOCIATION\n",
      "    The chi-square (Ï‡Â²) test for independence (also known as Pearson's Ï‡2 test or the Ï‡2 test of association)\n",
      "    can be used to determine if a relationship exists between two or more categorical variables. The test\n",
      "    produces a contingency table, or cross-tabulation, which displays the cross-grouping of the categorical\n",
      "    variables.\n",
      "\n",
      "    The Ï‡2 test checks the null hypothesis that there is no association between two categorical variables.\n",
      "    It compares the observed frequencies of the data with frequencies that would be expected if there\n",
      "    were no association between the two variables.\n",
      "\n",
      "    The analysis requires two assumptions to be met:\n",
      "\n",
      "       1.     The two variables must be categorical data (nominal or ordinal)\n",
      "       2.     Each variable should comprise two or more independent categorical groups\n",
      "\n",
      "    Most statistical tests fit a model to the observed data with a null hypothesis that there is no difference\n",
      "    between the observed and modelled (expected) data. The error or deviation of the model is calculated\n",
      "    as:\n",
      "\n",
      "                                     Deviation = âˆ‘ (ð’ð’ƒð’”ð’†ð’“ð’—ð’†ð’… âˆ’ð’Žð’ð’…ð’†ð’) ðŸ\n",
      "\n",
      "    Most parametric models are based on population means and standard deviations. The Ï‡2 model,\n",
      "    however, is based on expected frequencies.\n",
      "\n",
      "    How are the expected frequencies calculated? For example, we categorised 100 people into male,\n",
      "    female, short and tall. If there was an equal distribution between the 4 categories expected frequency\n",
      "    = 100/4 or 25% but the actual observed data does not have an equal frequency distribution.\n",
      "\n",
      "     Equal            Male     Female     Row       Observed                        Male     Female     Row\n",
      "     Distribution                         Total     Distribution                                        Total\n",
      "\n",
      "     Tall             25       25         50        Tall                          57         24         81\n",
      "\n",
      "     Short            25       25         50        Short                         14         5          19\n",
      "\n",
      "     Column Total     50       50                   Column Total                  71         29\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    The model based on expected values can be calculated by:\n",
      "\n",
      "    Model (expected)         = (ð‘Ÿð‘œð‘¤ ð‘¡ð‘œð‘¡ð‘Žð‘™ ð‘¥ ð‘ð‘œð‘™ð‘¢ð‘šð‘› ð‘¡ð‘œð‘¡ð‘Žð‘™)/100\n",
      "\n",
      "    Model â€“ tall male        = (81 x 71) /100 = 57.5\n",
      "    Model â€“ tall female      = (81 x 29) /100 = 23.5\n",
      "    Model â€“ small male       = (19 x 71) /100 = 13.5\n",
      "    Model â€“ small female     = (19 x 29) /100 = 5.5\n",
      "\n",
      "    These values can then be added to the contingency table:\n",
      "\n",
      "    145 | P a g e\n",
      "\n",
      "\n",
      "                     Male (M)     Female (F)     Row Total\n",
      "\n",
      "    Tall (T)         57           24             81\n",
      "\n",
      "    Expected         57.5         23.5\n",
      "    Short (S)        14           5              19\n",
      "    Expected         13.5         5.5\n",
      "    Column Total     71           29\n",
      "\n",
      "            The Ï‡2 statistic is derived from âˆ‘ (ð¨ð›ð¬ðžð«ð¯ðžð âˆ’ðžð±ð©ðžðœð­ðžð)ðŸ\n",
      "                                                     ðžð±ð©ðžðœð­ðžð\n",
      "    Validity\n",
      "\n",
      "    Ï‡2 tests are only valid when you have a reasonable sample size, that is, less than 20% of cells have an\n",
      "    expected count of less than 5, and none have an expected count of less than 1.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    RUNNING THE ANALYSIS\n",
      "\n",
      "    The dataset Titanic survival is a classic dataset used for machine learning and contains data on 1309\n",
      "    passengers and crew who were on board the Titanic when it sank in 1912. We can use this to look at\n",
      "    associations between survival and other factors. The dependent variable is â€˜Survivalâ€™, and possible\n",
      "    independent variables are all the other values.\n",
      "\n",
      "    Class      survived                           name                   sex       age\n",
      "    2Third     2No         Abbing, Mr. Anthony                           male      42\n",
      "    Third      No          Abbott, Master. Eugene Joseph                 male      13\n",
      "    Third      No          Abbott, Mr. Rossmore Edward                   male      16\n",
      "    Third      Yes         Abbott, Mrs. Stanton (Rosa Hunt)              female    35\n",
      "    Third      Yes         Abelseth, Miss. Karen Marie                   female    16\n",
      "    Third     Yes          Abelseth, Mr. Olaus Jorgensen                 male      25\n",
      "    Second     No          Abelson, Mr. Samuel                           male      30\n",
      "    Second     Yes         Abelson, Mrs. Samuel (Hannah Wizosky)         female    28\n",
      "    Third      Yes         Abrahamsson, Mr. Abraham August Johannes      male      20\n",
      "    Third      Yes         Abrahim, Mrs. Joseph (Sophie Halaut Easu)     female    18\n",
      "    Third      No          Adahl, Mr. Mauritz Nils Martin                male      30\n",
      "    Third      No          Adams, Mr. John                               male      26\n",
      "\n",
      "    146 | P a g e\n",
      "\n",
      "\n",
      "    By convention, the independent variable is usually placed in the contingency table columns, and the\n",
      "    dependent variable is placed in the rows.\n",
      "\n",
      "    Open Titanic survival chi square.csv in JASP, in the spreadsheet tab and double click on Survived. This\n",
      "    will open up the Label editor, where you can add labels to the code. Survival has been coded as no =\n",
      "    0 and yes = 1.\n",
      "\n",
      "    Name:          survived                  Long name: survived\n",
      "     Column type:  Nominal                   Description:\n",
      "     Computed type: Not computed\n",
      "\n",
      "     Label editor  Missing values\n",
      "     M Filter Value Label\n",
      "     3     âœ“ 0             No\n",
      "                   1  Yes\n",
      "\n",
      "    Go to Frequencies > Contingency tables and add survived to rows as the dependent variable and sex\n",
      "    into columns as the independent variable.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "     Contingency Tables\n",
      "\n",
      "      Class                      $$ \\frac { 2 }$     Rows\n",
      "      name                                               survived\n",
      "      age\n",
      "      spouses on board\n",
      "      parents with children\n",
      "      embarked                                       Columns\n",
      "                                                         sex\n",
      "\n",
      "    147 | P a g e\n",
      "\n",
      "                                                9  JASP\n",
      "\n",
      "    To make the tables easier to read, in Preferences, I suggest that you reduce the number of\n",
      "    decimals to 1.\n",
      "\n",
      "                  Results Preferences\n",
      "\n",
      "                  Table options\n",
      "                  Display exact p-values\n",
      "                  Use exponent notation\n",
      "                  Fix the number of decimals    1  +\n",
      "\n",
      "    In statistics, tick all the following options:\n",
      "\n",
      "     Statistics\n",
      "    0 x                                           âœ“Odds ratio (2x2 only)\n",
      "    xÂ² continuity correction                      Log Odds Ratio\n",
      "     Likelihood ratio                             Confidence interval 95.0  %\n",
      "     Vovk-Sellke maximum p-ratio    Alt. Hypothesis (Fisher's exact test)\n",
      "                                            Group one â‰  Group two\n",
      "                                            Group one > Group two\n",
      "                                            Group one < Group two\n",
      "\n",
      "    Nominal                                       Ordinal\n",
      "     Contingency coefficient                      Gamma\n",
      "     Phi and Cramer's V                           Kendall's tau-b\n",
      "     Lambda\n",
      "\n",
      "    In Cells, tick the following:\n",
      "     Cells\n",
      "    Counts                          Residuals\n",
      "      Expected                      Unstandardized\n",
      "                                    Pearson\n",
      "                                    Standardized (adjusted Pearson)\n",
      "    Percentages\n",
      "      Row\n",
      "      Column\n",
      "      Total\n",
      "\n",
      "    148 | P a g e\n",
      "\n",
      "\n",
      "    UNDERSTANDING THE OUTPUT\n",
      "\n",
      "    First, look at the Contingency table output.\n",
      "\n",
      "             Contingency Tables\n",
      "                                                sex\n",
      "             survived                           female      male           Total\n",
      "             No          Count                     127.0     682.0         809.0\n",
      "                         Expected count         288.0        521.0           809.0\n",
      "                         % within row             15.7 %     84.3 %        100.0 %\n",
      "                         % within column          27.3 %     80.9 %         61.8 %\n",
      "                         Pearson residuals          -9.5        7.1\n",
      "             Yes         Count                     339.0     161.0           500.0\n",
      "                         Expected count            178.0      322.0          500.0\n",
      "                         % within row             67.8 %     32.2 %        100.0%\n",
      "                         % within column          72.7 %      19.1%         38.2 %\n",
      "                         Pearson residuals          12.1           -9.0\n",
      "             Total       Count                     466.0          843.0     1309.0\n",
      "                         Expected count            466.0    843.0           1309.0\n",
      "                         % within row             35.6 %     64.4 %        100.0 %\n",
      "                         % within column          100.0%    100.0 %        100.0 %\n",
      "\n",
      "    Remember that Ï‡Â²tests are only valid when you have a reasonable sample size, i.e. less than 20% of\n",
      "    cells have an expected count of less than 5, and none have an expected count of less than 1.\n",
      "\n",
      "    From this table, looking at % within rows, more males died on the Titanic compared to females, and\n",
      "    more females survived compared to males. But is there a significant association between gender and\n",
      "    survival?\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "    The statistical results are shown below:\n",
      "\n",
      "    Chi-Squared Tests\n",
      "                                            Value    df    p\n",
      "    XÂ²                                      365.9     1    <.001\n",
      "    XÂ² continuity correction                363.6     1    <.001\n",
      "    Likelihood ratio                        372.9     1    <.001\n",
      "    N                                       1309\n",
      "\n",
      "    The Ï‡Â² statistic (Ï‡Â² (1) = 365.9, p<.001) suggests that there is a significant association between gender\n",
      "    and survival.\n",
      "\n",
      "    Ï‡Â² continuity correction can be used to prevent the overestimation of statistical significance for small\n",
      "    datasets. This is mainly used when at least one cell of the table has an expected count smaller than 5.\n",
      "\n",
      "    149 | P a g e\n",
      "\n",
      "\n",
      "    As a note of caution, this correction may overcorrect and result in an overly conservative result that\n",
      "    fails to reject the null hypothesis when it should (a type II error).\n",
      "\n",
      "    The likelihood ratio is an alternative to the Pearson chi-square. It is based on the maximum-likelihood\n",
      "    theory. For large samples, it is identical to Pearson Ï‡2. It is recommended for small sample sizes, i.e.\n",
      "    <30.\n",
      "\n",
      "    Nominal measures, Phi (2 x 2 contingency tables only) and Cramer's V (most popular) are both tests\n",
      "    of the strength of association (i.e. effect sizes). Both values are in the range of 0 (no association) to 1\n",
      "    (complete association). The strength of association between the variables has a large effect size.\n",
      "\n",
      "    Nominal\n",
      "                                   Value\n",
      "     Contingency coefficient       0.47\n",
      "     Phi-coefficient               0.53\n",
      "     Cramer's V                    0.53\n",
      "\n",
      "    The Contingency coefficient is an adjusted Phi value and is only suggested for large contingency tables,\n",
      "    such as 5 x 5 tables or larger.\n",
      "\n",
      "             Effect size 4              df        Small    Moderate    Large\n",
      "     Phi and Cramerâ€™s V (2x2 only)      1          0.1           0.3    0.5\n",
      "               Cramerâ€™s V               2          0.07      0.21       0.35\n",
      "               Cramerâ€™s V               3          0.06      0.17       0.29\n",
      "               Cramerâ€™s V               4          0.05      0.15       0.25\n",
      "               Cramerâ€™s V               5          0.04      0.13       0.22\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    JASP also provides the Odds ratio (OR), which is used to compare the relative odds of the occurrence\n",
      "    of the outcome of interest (survival), given exposure to the variable of interest (in this case, gender).\n",
      "\n",
      "    In Preferences, I suggest that you return the number of decimals to 3.\n",
      "\n",
      "    Odds Ratio\n",
      "                                        95% Confidence Intervals\n",
      "                            Odds Ratio  Lower    Upper           p\n",
      "     Odds ratio              0.088      0.068     0.115         <.001\n",
      "     Fisher's exact test     0.089      0.067     0.116\n",
      "\n",
      "    For ease of understanding, take the reciprocal of the OR (1/0.088), i.e. 11.36. This suggests that male\n",
      "    passengers had 11.36 times more chance of dying than females.\n",
      "\n",
      "    4 Kim HY. Statistical notes for clinical researchers: Chi-squared test and Fisher's exact test. Restor. Dent.\n",
      "    Endod. 2017; 42(2):152-155.\n",
      "\n",
      "                                             150 | P a g e\n",
      "\n",
      "\n",
      "    How is this calculated? Use the counts from the contingency table in the following:\n",
      "\n",
      "    Odds[males]       = Died/Survived       = 682/162     = 4.209\n",
      "    Odds[females]     = Died/Survived       = 127/339     = 0.374\n",
      "\n",
      "    OR = Odds[males] / Odds [females] = 11.3\n",
      "\n",
      "    GOING ONE STEP FURTHER.\n",
      "\n",
      "    We can also further decompose the contingency table as a form of post hoc testing by converting the\n",
      "    counts and expected counts in each cell to a standardised residual. This can tell us if the observed\n",
      "    counts and expected counts are significantly different in each cell.\n",
      "\n",
      "    The Pearson's residual for a cell in a table is a version of the standard z-score, calculated as\n",
      "\n",
      "    z =              observed â€” expected\n",
      "                     âˆšexpected\n",
      "\n",
      "    The resulting value of z is then given a positive sign if observed>expected and a negative sign if\n",
      "    observed<expected. Z-score significances are shown below.\n",
      "\n",
      "          z-score                                     P-value\n",
      "          <-1.96 or > 1.96                            <0.05\n",
      "          <-2.58 or > 2.58                            <0.01\n",
      "          <-3.29 or > 3.29                            <0.001\n",
      "\n",
      "    Contingency Tables\n",
      "                                             sex\n",
      "    survived                              female      male           Total\n",
      "    No               Count                   127.0     682.0         809.0\n",
      "                     Expected count          288.0     521.0           809.0\n",
      "                     % within row           15.7 %     84.3 %        100.0 %\n",
      "                     % within column        27.3 %     80.9 %         61.8 %\n",
      "                     Pearson residuals        -9.5        7.1\n",
      "    Yes              Count                   339.0     161.0           500.0\n",
      "                     Expected count          178.0      322.0          500.0\n",
      "                     % within row           67.8 %     32.2 %        100.0%\n",
      "                     % within column        72.7 %      19.1%         38.2 %\n",
      "                     Pearson residuals        12.1           -9.0\n",
      "    Total            Count                   466.0          843.0     1309.0\n",
      "                     Expected count          466.0    843.0           1309.0\n",
      "                     % within row           35.6 %     64.4 %        100.0 %\n",
      "                     % within column        100.0%    100.0 %        100.0 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                            151 | P a g e\n",
      "\n",
      "\n",
      "    When Pearsonâ€™s residual z-scores are calculated for each cell in the contingency table, we can see\n",
      "    that the z-scores are significant in all cells.\n",
      "\n",
      "    UNDERSTANDING THE OUTPUT\n",
      "\n",
      "    There is a significant association between gender and survival (Ï‡Â² (1) = 365.9, p<.001). The odds ratio\n",
      "    suggests that male passengers had 11.36 times more chance of dying than females.\n",
      "    Pearson's residuals suggest that significantly fewer women died than expected and significantly\n",
      "    more males died than expected.\n",
      "\n",
      "    152 | P a g e\n",
      "\n",
      "                                                            9  JASP\n",
      "\n",
      "    META-ANALYSIS IN JASP\n",
      "    Background\n",
      "\n",
      "    A meta-analysis is a statistical analysis that integrates results from multiple studies, providing a single\n",
      "    numerical value of the overall treatment effect for that group of studies. The difference between\n",
      "    statistical data analysis and meta-analysis is shown below. Effectively, each study becomes a\n",
      "    â€œparticipantâ€ in the meta-analysis.\n",
      "\n",
      "Statistical analysis\n",
      "Participant 1           Individual data\n",
      "Participant 2           Individual data\n",
      "Participant 3           Individual data\n",
      "Participant 4           Individual data\n",
      "Participant 5           Individual data\n",
      "Overall group data & statistics\n",
      "Meta-analysis\n",
      "Study 1                     Study data\n",
      "Study 2                     Study data\n",
      "Study 3                     Study data\n",
      "Study 4                     Study data\n",
      "Study 5                     Study data\n",
      "Overall study group data & statistics\n",
      "\n",
      "    In JASP, click on the blue cross in the top right corner, and then tick the Meta-Analysis module. This\n",
      "    will add meta-analysis to the main ribbon.\n",
      "\n",
      "    Effect size and calculations\n",
      "\n",
      "    To perform a Meta-analysis in JASP, the overall effect size (ES) and standard error (SE) of the study\n",
      "    need to be provided. An ES is a dimensionless estimate (no units) that indicates both the direction\n",
      "    and magnitude of the effect/outcome. The standard error measures the dispersion of different sample\n",
      "    means taken from the same population and can be estimated from a single sample standard deviation.\n",
      "    Some studies will provide this information, although many do not. However, they will provide results\n",
      "    such as:\n",
      "\n",
      "      â€¢     Central tendencies and dispersion\n",
      "      â€¢     T or F statistics\n",
      "      â€¢     P-values\n",
      "      â€¢     Correlation coefficients\n",
      "      â€¢     Chi-square\n",
      "\n",
      "    All of these can be converted to an ES and the SE determined using JASP's Effect size computation,\n",
      "    which is described later.\n",
      "\n",
      "    For example, a study comparing a treatment to a control group may provide the variable mean, SD\n",
      "    and n of each group. From this, the ES, a standardised mean difference (d), and estimated standard\n",
      "    error can be calculated.\n",
      "\n",
      "    To interpret the meta-analysis output, one needs to        understand the following concepts:\n",
      "    heterogeneity, the model, effect size, and the forest plot.\n",
      "\n",
      "    Heterogeneity:\n",
      "\n",
      "    Heterogeneity describes any variability that may exist between the different studies. It is the opposite\n",
      "    of homogeneity, which means that the population/data/results are the same. There are 3 types:\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    153 | P a g e\n",
      "\n",
      "                                                                  9              JASP\n",
      "\n",
      "      â€¢     Clinical:                   Differences in participants, interventions, or outcomes\n",
      "      â€¢     Methodological:             Differences in study design, risk of bias\n",
      "      â€¢     Statistical:                Variation in intervention effects or results\n",
      "\n",
      "    If there is no variability, then the data can be described as homogeneous. Meta-analysis is concerned\n",
      "    with   statistical   heterogeneity. Statistical heterogeneity is used to     describe variability among\n",
      "    data/studies and occurs when the treatment effect estimates of a set of data/studies vary among one\n",
      "    another. Studies with methodological flaws and small studies may overestimate treatment effects\n",
      "    and can contribute to statistical heterogeneity.\n",
      "\n",
      "     Low                                            High\n",
      "     heterogeneity                                  heterogeneity\n",
      "\n",
      "    The diagram aboveâµ shows examples of forest plots exhibiting low and high heterogeneity. In the low\n",
      "    condition, all the studies are generally lined up to the right of the vertical axis and all confidence\n",
      "    intervals are overlapping. In the high condition, the studies are spread over either side of the vertical\n",
      "    favours treatment  favours control    favours treatment  favours control\n",
      "    decision line and there is little overlap of the confidence intervals. Apart from visual observation of\n",
      "\n",
      "    Meta-analysis provides quantitative statistical methods to measure heterogeneity.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Tests for heterogeneity\n",
      "\n",
      "    Q      Cochran Q test - values are given for 2 tests outlined below, (these tests have low statistical\n",
      "           power when only a few studies are included in the meta-analysis):\n",
      "\n",
      "           â€˜Test for residual heterogeneityâ€™ tests the null hypothesis that all the effect sizes in the studies\n",
      "           are equal (homogeneity of effect sizes).\n",
      "\n",
      "    Ï„Â²     Tau square is an estimate of the total amount of heterogeneity. This is interpreted as\n",
      "           systematic, unexplained differences between the observed effects of the separate studies. It\n",
      "           is not affected by the number of studies, but it is often hard to interpret how relevant the\n",
      "           value is from a practical standpoint.\n",
      "\n",
      "    IÂ²     This measures the extent of heterogeneity not caused by sampling error. If there is high\n",
      "           heterogeneity, a possible subgroup analysis could be done. If the value is very low, there is no\n",
      "           point in doing further subgroup analyses. IÂ²  is not sensitive to changes in the number of\n",
      "           studies and is therefore used extensively in medical and psychological research, especially\n",
      "           since there is a â€œrule of thumbâ€ to interpret it. A rough guide for interpretations has been\n",
      "           suggested as followsâ¶:\n",
      "\n",
      "           â€¢     0% to 40%: might not be important.\n",
      "           â€¢     30% to 60%: may represent moderate heterogeneity.\n",
      "           â€¢     50% to 90%: may represent substantial heterogeneity.\n",
      "           â€¢     75% to 100%: considerable heterogeneity.\n",
      "\n",
      "    5 https://s4be.cochrane.org/blog/2018/11/29/what-is-heterogeneity/\n",
      "    6 Cochrane Handbook for Systematic Reviews of Interventions\n",
      "\n",
      "                                                                      154 | P a g e\n",
      "\n",
      "\n",
      "    HÂ²     The between-study variance is determined by equating the Q statistic to its expected value.\n",
      "           HÂ² has a value of 1 in the case of homogeneity, and heterogeneity is assumed to be present\n",
      "           when HÂ²>1.\n",
      "\n",
      "    Meta-analysis models\n",
      "\n",
      "    There are two models commonly used in meta-analysis, and each makes different assumptions\n",
      "    relating to the observed differences among the studies.\n",
      "\n",
      "    Fixed effects model: this assumes that all studies share a common true ES, i.e. the data is\n",
      "    homogeneous.  All factors that could influence the ES are the same in all the study samples, and\n",
      "    therefore very little heterogeneity. Between-study differences are assumed to be due to chance and\n",
      "    thus not incorporated into the model. Therefore, each study included in the meta-analysis estimates\n",
      "    the same population treatment effect, which, in theory, represents the true population treatment\n",
      "    effect. Each study is weighted where more weight is given to studies with large sample sizes, i.e. more\n",
      "    information.\n",
      "\n",
      "    This model answers the following question: â€œWhat is the best estimate of the population effect size?â€\n",
      "\n",
      "    Random effects model: This assumes a distribution of the treatment effect for some populations. i.e.\n",
      "    the different studies are estimating different, yet    related, intervention effects. Therefore,\n",
      "    heterogeneity cannot be explained because it is due to chance. This model assigns a more balanced\n",
      "    weighting between studies.\n",
      "\n",
      "    This model answers the question â€œWhat is the average treatment effect?â€.\n",
      "\n",
      "        It is therefore important to check for significant heterogeneity to\n",
      "        select the correct model for the meta-analysis.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Random effects model selection.\n",
      "\n",
      "    JASP provides 8 random effects estimators to estimate the 4 indices of heterogeneity (see tests for\n",
      "    heterogeneity above). All use a slightly different approach, resulting in different pooled ES\n",
      "    estimates and CIs. To date, the most often used estimator in medical research is the\n",
      "    DerSimonian-Laird estimator;   however, recent studies have shown better estimates of\n",
      "    between-study variance    using Maximum-Likelihood,    Restricted ML         (Default in JASP),\n",
      "    Empirical Bayes and Sidak-Jonkman methods.\n",
      "\n",
      "    The Forest Plot.\n",
      "\n",
      "    This plot provides a visual summary of the meta-analysis findings. Graphically, it represents the ES and\n",
      "    95% CI for each study and an estimate of the overall ES and 95% CI for all the studies that were\n",
      "    included. As previously mentioned, it can be used to visually assess the level of heterogeneity.\n",
      "\n",
      "    155 | P a g e\n",
      "\n",
      "\n",
      "                                   Graphical ES and 95% Cl\n",
      "\n",
      "    Study label             Size of the squares is proportional  Numerical ES\n",
      "                                   to the study weighting        and 95% CI\n",
      "\n",
      "    Aronson                                                      -0.94 [-2.11, 0.23]\n",
      "    Ferguson & Simes                                             -1.67 [-2.56, -0.77]\n",
      "    Rosenthal et al. 1                                           -1.39 [-2.68, -0.10]\n",
      "    Hart & Sutherland              Hâ€¢                            -1.46 [-1.74, -1.18]\n",
      "    Frimodt-Moller et al                                         -0.22 [-0.67, 0.23]\n",
      "    Stein & Aronson                HH                            -0.96 [-1.15, -0.76]\n",
      "    Vandiviere et al                                             -1.63 [-2.57, -0.70]\n",
      "    TPT Madras                                                   0.01 [-0.11, 0.14]\n",
      "    Coetzee & Berjak                                             -0.47 [-0.94, -0.00]\n",
      "    Rosenthal et al.2                                            -1.40 [-1.94, -0.86]\n",
      "    Comstock et al.1                                             -0.34 [-0.56, -0.12]\n",
      "    Comstock & Webster                                           0.45 [-0.99, 1.88]\n",
      "    Comstock et al.2                                             -0.02 [-0.54, 0.51]\n",
      "\n",
      "    FE Model                                                     -0.44 [-0.52, -0.35]\n",
      "\n",
      "     Overall ES - width of the  -3 -2 -1  0 1          2           Overall ES and\n",
      "    diamond indicates the 95% Cl   Observed Outcome                    95% CI\n",
      "\n",
      "                   Vertical axis centred on the zero-effect size hypothesis\n",
      "\n",
      "    As a rule of thumb, if all the individual study CIs cover the final combined ES and its 95% CI (diamond),\n",
      "    then there is low heterogeneity (or high homogeneity). In this case, 6 studies do not intersect with the\n",
      "    diamond.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Funnel plot\n",
      "\n",
      "    Looking like an inverted funnel, this is a scatter plot of the intervention effect estimates from individual\n",
      "    studies against each studyâ€™s size or precision. The intervention effect should increase as the size of the\n",
      "    study increases. Studies with low power will cluster at the bottom, while higher power studies will be\n",
      "    near the top. Ideally, the data points should have a symmetrical distribution. Funnel plot asymmetry\n",
      "    indicates that the meta-analysis results may be biased. Potential reasons for bias include:\n",
      "\n",
      "     â€¢     Publication bias (the tendency of authors/publishers to only publish studies with significant\n",
      "           results)\n",
      "     â€¢     True heterogeneity\n",
      "     â€¢     Artefact (wrong choice of effect measure)\n",
      "     â€¢     Data irregularities (methodological design, data analysis, etc.)\n",
      "\n",
      "    Funnel plot asymmetry can be analysed statistically using either meta-regression, weighted regression\n",
      "    or rank correlation.\n",
      "\n",
      "    156 | P a g e\n",
      "\n",
      "\n",
      "    Funnel Plot\n",
      "    0\n",
      "\n",
      "    0.1\n",
      "\n",
      "  2 0.2\n",
      "    0.3\n",
      "\n",
      "    0.4\n",
      "\n",
      "    0.5\n",
      "\n",
      "    -2  -1  0  1    2\n",
      "\n",
      "    157 | P a g e\n",
      "\n",
      "\n",
      "    EFFECT SIZE COMPUTATION IN JASP\n",
      "\n",
      "    Before running a meta-analysis, you will have to calculate the effect sizes and standard errors based\n",
      "    on the data extracted from the studies.\n",
      "\n",
      "    Open the Meta-Analysis fatigue.csv dataset. This is from papers comparing the effects of a new\n",
      "    treatment on the force recovery from eccentric exercise. The data comprises of the means, SD and\n",
      "    N for control and treatment groups as well as the authors and publication date.\n",
      "\n",
      "            M                          M            M\n",
      "                                                    Control mean M      M          M\n",
      "         Author               date     Control N              Control SD        Treatment N  Treatment mean M\n",
      "                                                                                                            Treatment SD\n",
      "    1    Bae                  2013     88           3.1       10.42       193                8.1            10.42\n",
      "    2    Choy                 2012     102          3.74      17.833      119                14.72          19.165\n",
      "    3    Emery                2008     263          16.7      21.9        265                21.4           22.9\n",
      "    4    Horslev-Petersen     2014     91           23.3      31.3        89                 33.1           32.9\n",
      "    5    Keystone             2004     96           7.87      21.3        206                15.1           21.94\n",
      "\n",
      "    Click on the Meta-Analysis icon (this module may need to be added by clicking the blue plus sign).\n",
      "    Then click on Effect size computation.\n",
      "\n",
      "    This allows you to calculate effect sizes and standard errors from a variety of research designs and\n",
      "    measurements. In this case, we can use the default settings. Next, populate the appropriate cells:\n",
      "\n",
      "    Step 1: SMD (Independent groups/Quantitative)     Mean Group 1\n",
      "    Author                       $\\frac{{ 2 }$        Control mean\n",
      "    date                                              Mean Group 2\n",
      "    Control N                                         Treatment mean\n",
      "    Control mean\n",
      "    Control SD                                       SD Group 1\n",
      "    Treatment N                                       Control SD\n",
      "    Treatment mean                                    SD Group 2\n",
      "    Treatment SD\n",
      "    computed effect size                              Treatment SD\n",
      "    computed standard error                           Sample Size Group 1\n",
      "    computed effect size type                         Control N\n",
      "\n",
      "                                                      Sample Size Group 2\n",
      "                                                      Treatment N\n",
      "\n",
      "    You will see in the results that JASP has computed 21 effect sizes.\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "    158 | P a g e\n",
      "\n",
      "\n",
      "    If you return to the spreadsheet viewer, you will see that 3 extra columns have been added:\n",
      "\n",
      "     â€¢     Computed effect size\n",
      "     â€¢     Computed standard error\n",
      "     â€¢     Computed effect size type â€“ in this case, the standardised mean difference (SMD)\n",
      "\n",
      "    These are used to run the meta-analysis.\n",
      "\n",
      "    RUNNING THE META-ANALYSIS IN JASP\n",
      "\n",
      "    Go to Meta-Analysis and click on Classical Meta-Analysis. Add the computed effect size, computed\n",
      "    standard error and finally the Author to the Study Labels. Keep the method as Restricted ML.\n",
      "\n",
      "    Classical Meta-Analysis\n",
      "\n",
      "date                         $\\frac{ 2 }$\n",
      "Control N\n",
      "Control mean\n",
      "Control SD\n",
      "Treatment N\n",
      "Treatment mean\n",
      "Treatment SD\n",
      "computed effect size type\n",
      "\n",
      "\n",
      "Effect Size\n",
      " computed effect size\n",
      " Effect Size Standard Error\n",
      " computed standard error\n",
      "Method\n",
      "\n",
      " Restricted ML\n",
      " Fixed effect test\n",
      " knha\n",
      "Predictors\n",
      "\n",
      "                                 Clustering\n",
      "\n",
      "                                 Study Labels\n",
      "                                 Author\n",
      "\n",
      "    In the Statistics tab, tick all 4 Heterogeneity measures, Ï„, Ï„Â², IÂ², HÂ².\n",
      "\n",
      "    This will result in 3 tables.\n",
      "\n",
      "    159 | P a g e\n",
      "\n",
      "\n",
      "    Model Summary\n",
      "    Residual Heterogeneity Test\n",
      "    Qe  df                     p\n",
      "    49.439  20                 <.001\n",
      "\n",
      "    Pooled Effect Size Test\n",
      "    Estimate  Standard Error  t  df  p\n",
      "    -0.352    0.045           -7.900  20.000  <.001\n",
      "\n",
      "    Meta-Analytic Estimates\n",
      "                               95% CI                        95% PI\n",
      "                     Estimate             Lower     Upper    Lower  Upper\n",
      "      Effect Size    -0.352              -0.445    -0.259    -0.668  -0.036\n",
      "      Ï„              0.145     0.081                0.279\n",
      "      Ï„Â²             0.021                0.007     0.078\n",
      "     F               59.313              31.196    84.394\n",
      "     $H^Â²}$          2.458                1.453     6.408\n",
      "\n",
      "    The Residual Heterogeneity test confirms significant heterogeneity in the data and that the\n",
      "    random-effects model (Restricted ML) is appropriate in this case. If this were not significant,\n",
      "    the method should be changed to fixed effects.\n",
      "    The Pooled Effect Size tests the Hâ‚€ that all the estimates are zero, i.e. the interventions have\n",
      "    no significant effect. As can be seen, this is significant and Hâ‚€ can be rejected, thus the\n",
      "    intervention has a significant effect with an effect size difference of -0.352.\n",
      "    Looking at the Meta-Analytic Estimates, both HÂ² and IÂ² show excess variance (heterogeneity)\n",
      "    between the studies, thus supporting the use of a random-effects model.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Forest Plots\n",
      "    Return to the Statistics options and Forest Plot, tick Study information, and add both Author\n",
      "    and Date to the selected variables. Scroll down and tick Model information.\n",
      "\n",
      "    Forest Plot\n",
      "\n",
      "    Study information\n",
      "\n",
      "    Control N                  $\\frac{{2 }$                  Selected Variables\n",
      "    Control mean                                                     Author\n",
      "    Control SD                                                       date\n",
      "\n",
      "    160 | P a g e\n",
      "\n",
      "\n",
      "    The Forest plot shows the weighted effect sizes (the size of the squares reflects the weight of\n",
      "    each study) and CIs used to determine the overall pooled ES (diamond).\n",
      "\n",
      "    Forest Plot\n",
      "\n",
      "                    Strand              2012\n",
      "                    Schiff              2008\n",
      "                    Rigby               2011\n",
      "                    Kremer              2006\n",
      "                    Genovese            2005\n",
      "                    Cohen               2006\n",
      "                    Alten               2011\n",
      "                    Weinblatt           2003\n",
      "                    Strand              2012\n",
      "                    Strand              2009                                  âˆ’\n",
      "                    Soubrier            2009\n",
      "                    Smolen              2009\n",
      "                    Pope                2012\n",
      "                    Moreland            1999\n",
      "                    Mittlendorf         2007\n",
      "                    Li                  2013\n",
      "                    Keystone            2004\n",
      "                    Horslev-Petersen    2014\n",
      "                    Emery               2008\n",
      "                    Choy                2012\n",
      "                    Bae                 2013\n",
      "                                        Model Information\n",
      "                  Heterogeneity: Q(20) = 49.44, p < 0.001\n",
      "                                  tau = 0.14 [0.08, 0.28]\n",
      "                                          Pooled Estimate\n",
      "                              t(20.00) = -7.90, p < 0.001\n",
      "                                                         -1.5    -1.0         -0.5 Effect Size 0.0    0.5    1.0\n",
      "    \n",
      "\n",
      "    The model information is just a summary of the first 3 tables above.\n",
      "\n",
      "    Funnel Plot\n",
      "\n",
      "    From the Meta-Analysis icon,        click on Funnel Plot.             Add the computed effect size and\n",
      "    computed standard error to their relevant boxes. Also, click on Funnel under H1 and click\n",
      "    Funnel plot asymmetry tests.\n",
      "\n",
      "    Funnel Plot\n",
      "\n",
      "     Author                             $\\frac{{ 2 }$                     Effect Size\n",
      "     date                                                                     computed effect size\n",
      "     Control N                                                            Effect Size Standard Error\n",
      "     Control mean                                                             computed standard error\n",
      "     Control SD\n",
      "     Treatment N                                                         Study Label\n",
      "     Treatment mean\n",
      "     Treatment SD                                                        Split\n",
      "     computed effect size type\n",
      "\n",
      "    Funnel under Ho                          Funnel under H1\n",
      "    Parameters                               Parameters     Estimated  Fixed\n",
      "    L                                        Method Restricted ML\n",
      "\n",
      "                                                                            161 | P a g e\n",
      "\n",
      "\n",
      "    Funnel Plot\n",
      "\n",
      "    0.00\n",
      "\n",
      "    0.05\n",
      "\n",
      "    20 0.10 -\n",
      "     0.15                                            0\n",
      "\n",
      "     0.20                                            o\n",
      "\n",
      "     0.25\n",
      "\n",
      "     0.30 -\n",
      "               -1.5                     -1           -0.5          0  0.5\n",
      "                                                     Effect Size\n",
      "\n",
      "    Funnel Plot Asymmetry Tests\n",
      "    Meta-Regression Test for Funnel Plot Asymmetry\n",
      "                      Asymmetry Test                 Limit Estimate\n",
      "    Estimates         Z         p       Estimate     Lower 95% CI  Upper 95% CI\n",
      "     21               -0.865  0.387     -0.245       -0.499        0.009\n",
      "\n",
      "    The funnel plot shows that the observed effect sizes appear to be symmetrically distributed\n",
      "    around the vertical axis (based on the pooled effect size estimate, in this case, -0.352) and lie\n",
      "    within the 95% confidence triangle.   Asymmetry is often reported as being indicative of\n",
      "    publication bias. This plot is accompanied by the â€˜Meta-Regression Testâ€™ for funnel plot\n",
      "    asymmetry, which in this case is non-significant (p=.387).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Reporting the results.\n",
      "    A random-effects model (Restricted ML) was used in the analysis. The Residual Heterogeneity\n",
      "    test confirms significant heterogeneity in the data Q(20) = 49.4, p<.001. This was supported\n",
      "    with an IÂ² of 59.3%. The Pooled Effect Size test showed a significant difference of -0.352\n",
      "    between the control and treatment studies, t(20) = -7.9, p<.001. Meta-regression showed no\n",
      "    Funnel plot asymmetry, Z=-0.865, p=0.387.\n",
      "    Also, show the Forest plot.\n",
      "\n",
      "    162 | P a g e\n",
      "\n",
      "\n",
      "    163 | P a g e\n",
      "\n",
      "                             9  JASP\n",
      "\n",
      "    EXPERIMENTAL DESIGN AND DATA LAYOUT IN EXCEL FOR JASP IMPORT.\n",
      "    Independent t-test\n",
      "    Design example:\n",
      "\n",
      "     Independent variable    Group 1    Group 2\n",
      "     Dependent variable        Data       Data\n",
      "\n",
      "     Independent variable    Dependent variable\n",
      "     Categorical             Continuous\n",
      "\n",
      "           A     B\n",
      "    1    Group   Data\n",
      "    2      1      0\n",
      "    3      1      0\n",
      "    4      1     3.8\n",
      "    5      1      6\n",
      "    6      1     0.7\n",
      "    7      1     2.9\n",
      "    8      1     2.8\n",
      "    9      1      2\n",
      "    10     1      2\n",
      "    11     1     8.5\n",
      "    12     1     1.9\n",
      "    13     1     3.1\n",
      "    14     1     1.5\n",
      "    15     1      3\n",
      "    16     1     3.6\n",
      "    17     1     0.9\n",
      "    18     1     -2.1\n",
      "    19     2      2\n",
      "    20     2     1.7\n",
      "    21     2     4.3\n",
      "    22     2      7\n",
      "    23     2     0.6\n",
      "    24     2     2.7\n",
      "    25     2     3.6\n",
      "\n",
      "\n",
      "    More dependent variables can be added if required\n",
      "\n",
      "    164 | P a g e\n",
      "\n",
      "                                     9  JASP\n",
      "\n",
      "    Paired samples t-test\n",
      "    Design example:\n",
      "\n",
      "     Independent variable    Pre-test    Post-test\n",
      "     Participant                     Dependent variable\n",
      "     1                         Data         Data\n",
      "     2                         Data         Data\n",
      "     3                         Data         Data\n",
      "     ..n                       Data         Data\n",
      "\n",
      "                         Pre-test       Post-test\n",
      "\n",
      "    A             B\n",
      "   1  Pre-test    Post-test\n",
      "   2     60       60\n",
      "   3    103       103\n",
      "   4     58       54\n",
      "   5     60       54\n",
      "   6     64       63\n",
      "   7     64       61\n",
      "   8     65       62\n",
      "   9     66       64\n",
      "   10    67       65\n",
      "   11    69       61\n",
      "   12    70       68\n",
      "   13    70       67\n",
      "   14    72       71\n",
      "   15   72       69\n",
      "   16    72       68\n",
      "   17    82       81\n",
      "   18    58       60\n",
      "   19    58       56\n",
      "   20    59       57\n",
      "   21    61       57\n",
      "   22    62       55\n",
      "   23    63       62\n",
      "   24    63       60\n",
      "   25    63       59\n",
      "\n",
      "    165 | P a g e\n",
      "\n",
      "                   9  JASP\n",
      "\n",
      "    Correlation\n",
      "    Design example:\n",
      "                   Simple correlation\n",
      "\n",
      "    Participant    Variable 1    Variable 2  Variable 3  Variable 4  Variable ..n\n",
      "    1                 Data          Data     Data        Data            Data\n",
      "    2                 Data          Data     Data        Data            Data\n",
      "    3                 Data          Data     Data        Data            Data\n",
      "    â€¦n                Data          Data     Data        Data            Data\n",
      "\n",
      "    Multiple correlations\n",
      "\n",
      "               A             B      C          D          E              F\n",
      "    1     Participant    Variable 1 Variable 2 Variable 3 Variable 4 Variable 5\n",
      "    2     1                 533     77         77            106  106\n",
      "    3          2            472     63         59             92         93\n",
      "    4          3            484     82         77             93         78\n",
      "    5          4            536     72         72            103         93\n",
      "    6     5                 630     77         68            104         93\n",
      "    7          6            563     68         68            101         87\n",
      "    8          7            531     77         82            108        106\n",
      "    9          8            344     50         50             86         92\n",
      "    10         9  346               54         50             90         86\n",
      "    11         10           386     59         54             85         80\n",
      "    12         11           460     54         63             89         83\n",
      "    13         12           492     63         59             92         94\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "    166 | P a g e\n",
      "\n",
      "\n",
      "    Regression\n",
      "    Design example:\n",
      "                   Simple Regression\n",
      "\n",
      "    Participant    Outcome    Predictor 1  Predictor 2  Predictor 3  Predictor ..n\n",
      "    1                Data         Data     Data         Data         Data\n",
      "    2                Data         Data     Data         Data         Data\n",
      "    3                Data         Data     Data         Data         Data\n",
      "    â€¦n               Data         Data     Data         Data         Data\n",
      "\n",
      "\n",
      "    Multiple regression\n",
      "\n",
      "       A               B         C           D    E                  F\n",
      "   1 Participant    Outcome Predictor 1 Predictor 2 Predictor 3 Predictor 4\n",
      "   2      1     533              77     77       106            106\n",
      "   3     2           472        63     59        92            93\n",
      "   4      3           484        82     77     93               78\n",
      "   5      4           536        72     72       103            93\n",
      "   6      5           630        77     68       104            93\n",
      "   7      6           563        68     68       101            87\n",
      "   8      7           531        77     82       108            106\n",
      "   9      8           344        50     50        86            92\n",
      "   10     9           346        54     50        90            86\n",
      "   11     10          386  59           54     85               80\n",
      "   12     11          460        54     63        89            83\n",
      "   13     12          492        63     59        92            94\n",
      "\n",
      "    167 | P a g e\n",
      "\n",
      "\n",
      "    Logistic Regression\n",
      "    Design example:\n",
      "\n",
      "              Dependent Variable    Factor         Covariate\n",
      "                (categorical)    (categorical)    (continuous)\n",
      "    Participant    Outcome        Predictor 1     Predictor 2\n",
      "    1                Data             Data            Data\n",
      "    2                Data             Data            Data\n",
      "    3                Data             Data            Data\n",
      "    â€¦n               Data             Data            Data\n",
      "\n",
      "           A      B      C  D\n",
      "    1     ID   Outcome  Factor  Covariate\n",
      "    2      1     Yes    Yes     70\n",
      "    3      2     Yes     No    80\n",
      "    4      3     Yes    Yes    50\n",
      "    5      4     Yes     No    60\n",
      "    6      5     Yes     No    40\n",
      "    7      6     Yes     No    65\n",
      "    8      7     Yes     No    75\n",
      "    9      8     Yes     No    80\n",
      "    10     9     Yes     No    70\n",
      "    11     10    Yes     No    60\n",
      "    12     11     No    Yes    65\n",
      "    13     12     No    Yes    50\n",
      "    14     13     No    Yes    45\n",
      "    15     14     No    Yes    35\n",
      "    16     15     No    Yes    40\n",
      "    17     16     No    Yes    50\n",
      "    18     17     No     No    55\n",
      "    19     17    Yes     No    65\n",
      "    20     18   No      Yes    45\n",
      "\n",
      "    More factors and covariates can be added if required\n",
      "\n",
      "\n",
      "    168 | P a g e\n",
      "\n",
      "                             9  JASP\n",
      "\n",
      "    One-way Independent ANOVA\n",
      "    Design example:\n",
      "\n",
      "     Independent variable    Group 1    Group 2    Group 3    Groupâ€¦n\n",
      "\n",
      "     Dependent variable        Data       Data       Data       Data\n",
      "\n",
      "    Independent variable     Dependent variable\n",
      "    (Categorical)            (Continuous)\n",
      "\n",
      "         A                     B\n",
      "    1  Group           Dependent variable\n",
      "    2     Group 1     3.8\n",
      "    3     Group 1              6\n",
      "    4     Group 1     0.7\n",
      "    5     Group 1     2.9\n",
      "    6     Group 1     2.8\n",
      "    7     Group 1              2\n",
      "    8     Group 1              2\n",
      "    9     Group 1     3.5\n",
      "    10    Group 2     1.9\n",
      "    11    Group 2     3.1\n",
      "    12    Group 2     1.5\n",
      "    13    Group 2      3\n",
      "    14    Group 2     3.6\n",
      "    15    Group 2     0.9\n",
      "    16    Group 2     -0.6\n",
      "    17    Group 3     1.1\n",
      "    18    Group 3     4.5\n",
      "    19    Group 3     6.1\n",
      "    20    Group 3      5\n",
      "    21    Group 3     2.4\n",
      "    22    Group 3     3.9\n",
      "    23    Group 3     3.5\n",
      "    24    Group 3     5.1\n",
      "    25    Group 3     3.5\n",
      "    More dependent variables can be added if required\n",
      "\n",
      "\n",
      "    169 | P a g e\n",
      "\n",
      "\n",
      "    One-way repeated measures ANOVA\n",
      "    Design example:\n",
      "\n",
      "                                   Independent variable (Factor)\n",
      "     Participant    Level 1    Level 2    Level 3               Level..n\n",
      "     1                Data       Data       Data                Data\n",
      "     2                Data       Data       Data                Data\n",
      "     3                Data       Data       Data                Data\n",
      "     4                Data       Data       Data                Data\n",
      "     ..n              Data       Data       Data                Data\n",
      "\n",
      "                    Factor (time)\n",
      "\n",
      "    âœ“     A            B      C              D     Levels\n",
      "    1 Participant    Week 0  Week 3         Week 6\n",
      "    2     1          6.42           5.83     5.75  (Related groups)\n",
      "    3     2          6.76    6.2             6.13\n",
      "    4     3          6.56           5.83     5.71\n",
      "    5     4           4.8           4.27     4.15\n",
      "    6     5          8.43           7.71     7.67\n",
      "    7     6          7.49           7.12     7.05\n",
      "    8     7          8.05           7.25     7.1\n",
      "    9     8          5.05           4.63     4.67\n",
      "    10    9          5.77           5.31     5.33\n",
      "    11    10         3.91    3.7             3.66\n",
      "    12    11         6.77           6.15     5.96\n",
      "    13    12         6.44           5.59     5.64\n",
      "    14    13         6.17           5.56     5.51\n",
      "    15    14         7.67           7.11     6.96\n",
      "    16    15         7.34           6.84     6.82\n",
      "    17    16         6.85    6.4             6.29\n",
      "    18    17         5.13    4.52            4.45\n",
      "    19    18         5.73           5.13     5.17\n",
      "\n",
      "    More levels can be added if required\n",
      "\n",
      "\n",
      "    170 | P a g e\n",
      "\n",
      "\n",
      "    Two-way Independent ANOVA\n",
      "    Design example:\n",
      "\n",
      "     Factor 1           Supplement 1              Supplement 2\n",
      "     Factor 2      Dose 1  Dose 2    Dose 3  Dose 1  Dose 2      Dose 3\n",
      "     Dependent     Data     Data     Data    Data     Data       Data\n",
      "     variable\n",
      "\n",
      "                           Factor 1  Factor 2  Dependent variable\n",
      "\n",
      "           A       B       C\n",
      "    1     supp    dose    len\n",
      "    2      OJ     1000    19.7\n",
      "    3      OJ     1000    23.3\n",
      "    4      OJ     1000    23.6\n",
      "    5      OJ     1000    26.4\n",
      "    6      OJ     1000     20\n",
      "    7      OJ     1000    25.2\n",
      "    8      OJ     1000    25.8\n",
      "    9      OJ     1000    21.2\n",
      "    10     OJ     1000    14.5\n",
      "    11     OJ     1000    27.3\n",
      "    12     OJ     2000    25.5\n",
      "    13     OJ     2000    26.4\n",
      "    14     OJ     2000    22.4\n",
      "    15     OJ     2000    24.5\n",
      "    16     OJ     2000    24.8\n",
      "    17     OJ     2000    30.9\n",
      "    18     OJ     2000    26.4\n",
      "    19     OJ     2000    27.3\n",
      "    20     OJ     2000    29.4\n",
      "    21     OJ     2000     23\n",
      "    22     vc     1000    16.5\n",
      "    23     vc     1000    16.5\n",
      "    24     vc     1000    15.2\n",
      "    25     vc     1000    17.3\n",
      "\n",
      "    More factors and dependent variables can be added if required\n",
      "\n",
      "\n",
      "    171 | P a g e\n",
      "\n",
      "                                             9        JASP\n",
      "\n",
      "    Two-way Repeated measures ANOVA\n",
      "    Design example:\n",
      "\n",
      "Factor 1                  Level 1\n",
      "Interventions       i.e. intervention 1\n",
      "Factor 2    Level 1       Level 2       Level 3\n",
      "Time       i.e time 1    i.e time 2    i.e time 3\n",
      "1             Data          Data          Data\n",
      "2             Data          Data          Data\n",
      "3             Data          Data          Data\n",
      "..n           Data          Data          Data\n",
      "               Level 2\n",
      "         i.e. intervention 2\n",
      " Level 1  Level 2  Level 3\n",
      "i.e time 1    i.e time 2    i.e time 3\n",
      "   Data          Data          Data\n",
      "   Data          Data          Data\n",
      "   Data          Data          Data\n",
      "   Data          Data          Data\n",
      "\n",
      "                      Factor 1 levels 1-n                          Factor 2 levels 1-n\n",
      "\n",
      "        A              B                   C                   D                   E\n",
      "   1 Subject    Factor 1 level 1    Factor 1 level 2    Factor 2 level 1    Factor 2 level 2\n",
      "   2     A            7.38    6.52                            9.27               14.32\n",
      "   3     B            7.71               10.83               11.48               16.38\n",
      "   4     C            6.19               10.42                9.77               15.45\n",
      "   5     D            9.27               11.78               15.45               16.96\n",
      "   6     E    11.41                       9.52               11.65               15.64\n",
      "   7     F            5.29                5.82    9.22    13.01\n",
      "    8    G            8.54                9.43               10.92               17.35\n",
      "   9    H             7.89                8.43                8.26               12.57\n",
      "   10    I            5.49                6.64               11.39               14.02\n",
      "   11    J       9.26                     9.36               13.03               16.24\n",
      "   12    K    6.9                         7.09                9.02                14.7\n",
      "   13    L       8.57                     9.64                8.33               13.71\n",
      "\n",
      "    172 | P a g e\n",
      "\n",
      "                                              9       JASP\n",
      "\n",
      "    Two-way Mixed Factor ANOVA\n",
      "    Design example:\n",
      "\n",
      "     Factor 1                      Group 1                      Group 2\n",
      "     (Between subjects)\n",
      "     Factor 2 levels    Trial 1    Trial 2  Trial 3  Trial 1    Trial 2    Trial 3\n",
      "     (Repeated measures)\n",
      "     1                    Data       Data     Data     Data       Data       Data\n",
      "     2                    Data       Data     Data     Data       Data       Data\n",
      "     3                    Data       Data     Data     Data       Data       Data\n",
      "     ..n                  Data       Data     Data     Data       Data       Data\n",
      "\n",
      "                 Factor 1         Factor 2 levels\n",
      "                 (Categorical)    (Continuous)\n",
      "\n",
      "    '        A         B          C          D\n",
      "   1       Group    Level 1    Level 2    Level 3\n",
      "   2      Group 1     1.31       0.9     0.9\n",
      "   3      Group 1     1.29       0.89       0.72\n",
      "    4     Group 1     1.8    0.9            0.96\n",
      "   5      Group 1    1.4         1.26       0.97\n",
      "   6      Group 1     1.49       1.18       0.88\n",
      "   7      Group 1     1.35       1.15       0.92\n",
      "   8      Group 1     1.45       1.19        1\n",
      "   9      Group 1     1.21       1.2        0.85\n",
      "   10     Group 1     1.79       1.48       0.99\n",
      "   11     Group 1    1.73        1.68       0.98\n",
      "   12     Group 2     1.55       0.9        0.55\n",
      "   13     Group 2     1.27       0.95       0.41\n",
      "   14     Group 2     1.53       0.87       0.42\n",
      "   15     Group 2     1.26       1.15       0.44\n",
      "   16     Group 2     1.14       1.12       0.38\n",
      "   17     Group 2     1.11       1.08       0.34\n",
      "   18     Group 2     1.1       1.0758      0.18\n",
      "   19     Group 2     1.08       1.18       0.24\n",
      "   20     Group 2     1.3        1.26       0.39\n",
      "   21     Group 2     1.45       1.55       0.44\n",
      "\n",
      "    173 | P a g e\n",
      "\n",
      "                                                9  JASP\n",
      "\n",
      "    Chi-squared - Contingency tables\n",
      "    Design example:\n",
      "     Participant    Response 1      Response 2  Response 3    Responseâ€¦n\n",
      "     1                 Data         Data           Data          Data\n",
      "     2                 Data         Data           Data          Data\n",
      "     3                 Data         Data           Data          Data\n",
      "     ..n               Data         Data           Data          Data\n",
      "\n",
      "    All data should be categorical\n",
      "\n",
      "          A      B                C        D                      E\n",
      "    1 Respondant Response 1       Response 2    Response 3    Response 4\n",
      "    2     1            Female     clay           Morning      yes\n",
      "    3     2          Male         astro          Morning      No\n",
      "    4     3            Female     grass          Evening      No\n",
      "    5     4          Male            clay       Afternoon     No\n",
      "    6     5          Male         clay     Morning            No\n",
      "    7     6          Male         grass          Evening      No\n",
      "    8     7            Female     grass          Evening      yes\n",
      "    9     8          Male            clay        Morning      yes\n",
      "    10    9            Female     grass          Morning      No\n",
      "    11    10     Male             clay          Afternoon     No\n",
      "    12    11           Female     clay          Afternoon     No\n",
      "    13    12         Male         astro         Afternoon     No\n",
      "    14    13         Male         astro         Afternoon     No\n",
      "    15    14         Male         astro         Afternoon     yes\n",
      "    16    15           Female     clay           Morning      No\n",
      "    17    16         Male         astro         Afternoon  yes\n",
      "    18    17           Female     astro         Afternoon     yes\n",
      "    19    18         Male         grass    Morning            No\n",
      "    20    19         Male         clay          Afternoon     No\n",
      "\n",
      "    174 | P a g e\n",
      "\n",
      "                                                        9             JASP\n",
      "\n",
      "    SOME CONCEPTS IN FREQUENTIST STATISTICS\n",
      "    The frequentist approach is the most commonly taught and used statistical methodology. It\n",
      "    describes sample data based on the frequency or proportion of the data from repeated\n",
      "    studies through which the probability of events is defined.\n",
      "    Frequentist statistics uses rigid frameworks including hypothesis testing, p values confidence\n",
      "    intervals etc.\n",
      "    Hypothesis testing\n",
      "\n",
      "    A hypothesis can be defined as â€œa supposition or proposed explanation made based on\n",
      "    limited evidence as a starting point for further investigationâ€.\n",
      "    There are two simple types of hypotheses, a null hypothesis (Hâ‚€) and an alternative or\n",
      "    experimental hypothesis (Hâ‚). The null hypothesis is the default position for most statistical\n",
      "    analyses in which it is stated that there is no relationship or difference between groups. The\n",
      "    alternative hypothesis states that there is a relationship or difference between groups in a\n",
      "    direction of difference/relationship. For example, if a study was carried out to look at the\n",
      "    effects of a supplement on sprint time in one group of participants compared to the placebo\n",
      "    group:\n",
      "    Hâ‚€ = there is no difference in sprint times between the two groups\n",
      "    Hâ‚ = there is a difference in sprint times between the two groups\n",
      "    Hâ‚‚ = Group 1 is greater than Group 2\n",
      "    Hâ‚ƒ = Group 1 is less than Group 2\n",
      "    Hypothesis testing refers to the strictly predefined procedures used to accept or reject the\n",
      "    hypotheses and the probability that this could be purely by chance. The confidence at which\n",
      "    a null hypothesis is accepted or rejected is called the level   of significance. The level of\n",
      "    significance is denoted by Î±, usually 0.05 (5%). This is the level of probability of accepting an\n",
      "    effect as true (95%) and that there is only 5% of the result is purely by chance.\n",
      "    Different types of hypotheses can easily be selected in JASP, however, the null hypothesis is\n",
      "    always the default.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                       Hypothesis\n",
      "                                     Group 1 â‰  Group 2\n",
      "                       Â© Group 1 > Group 2\n",
      "                       Â©Group 1 < Group 2\n",
      "\n",
      "    175 | P a g e\n",
      "\n",
      "\n",
      "    Type I and II errors\n",
      "    The probability of rejecting the null hypothesis, when it is, in fact, true, is called Type I error\n",
      "    whereas the probability of accepting the null hypothesis when it is not true is called Type II\n",
      "    error.\n",
      "\n",
      "                                             The truth\n",
      "                                             Not guilty (Hâ‚€)            Guilty (Hâ‚)\n",
      "                                             Type I error\n",
      "                        Guilty (Hâ‚)          An    innocent     person  Correct decision\n",
      "    The verdict                              goes to prison\n",
      "                        Not guilty (Hâ‚€)                                 Type II error\n",
      "                                             Correct decision           A guilty person goes free\n",
      "\n",
      "    Type I error is deemed the worst error to make in statistical analyses.\n",
      "    Statistical power is defined as the probability that the test will reject the null hypothesis when\n",
      "    the alternative hypothesis is true. For a set level of significance, if the sample size increases,\n",
      "    the probability of Type II error decreases, which therefore increases the statistical power.\n",
      "    Testing the hypothesis\n",
      "\n",
      "    The essence of hypothesis testing is to first define the null (or alternative) hypothesis, set\n",
      "    the criterion level Î±, usually 0.05 (5%), collect and analyse sample data. Use a test statistic to\n",
      "    determine how far (or the number of standard deviations) the sample mean is from the\n",
      "    population mean stated in the null hypothesis. The test statistic is then compared to a critical\n",
      "    value. This is a cut-off value defining the boundary where less than 5% of the sample means\n",
      "    can be obtained if the null hypothesis is true.\n",
      "    If the probability of obtaining a difference between the means by chance is less than 5% when\n",
      "    the null hypothesis has been proposed, the null hypothesis is rejected and the alternative\n",
      "    hypothesis can be accepted.\n",
      "    The p-value is the probability of obtaining a sample outcome, given that the value stated in\n",
      "    the null hypothesis is true. If    the p-value is less than 5% (p < .05) the null hypothesis is\n",
      "    rejected. When the p-value is greater than 5% (p > .05), we accept the null hypothesis.\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    Effect size\n",
      "\n",
      "    An effect size is a standard measure that can be calculated from any number of statistical\n",
      "    analyses. If the null hypothesis is rejected the result is significant. This significance only\n",
      "    evaluates the probability of obtaining the sample outcome by chance but does not indicate\n",
      "    how big a difference (practical significance) is, nor can it be used to compare across different\n",
      "    studies.\n",
      "    The effect size indicates the magnitude of the difference between the groups. So for example,\n",
      "    if there was a significant decrease in 100m sprint times in a supplement compared to a\n",
      "\n",
      "                                                                                     176 | P a g e\n",
      "\n",
      "\n",
      "    placebo group, the effect size would indicate how much more effective the intervention was.\n",
      "    Some common effect sizes are shown below.\n",
      "\n",
      "     Test                    Measure                                Trivial     Small     Medium   Large\n",
      "     Between means           Cohenâ€™s d                              <0.2        0.2       0.5      0.8\n",
      "     Correlation             Correlation coefficient (r)            <0.1        0.1       0.3      0.5\n",
      "                             Rank -biserial (rB)                    <0.1        0.1       0.3      0.5\n",
      "                             Spearmanâ€™s rho                         <0.1        0.1       0.3      0.5\n",
      "     Multiple Regression     Multiple               correlation     <0.10       0.1       0.3      0.5\n",
      "                             coefficient (R)\n",
      "     ANOVA                   Eta                                    <0.1        0.1       0.25     0.37\n",
      "                             Partial Eta                            <0.01       0.01      0.06     0.14\n",
      "                             Omega squared                          <0.01       0.01      0.06     0.14\n",
      "     Chi-squared             Phi (2x2 tables only)                  <0.1        0.1       0.3      0.5\n",
      "                             Cramerâ€™s V                             <0.1        0.1       0.3      0.5\n",
      "                             Odds ratio (2x2 tables only)           <1.5        1.5       3.5      9.0\n",
      "\n",
      "    In small datasets, there may be a moderate to large effect size but no significant differences.\n",
      "    This could suggest that the analysis lacked statistical power and that increasing the number\n",
      "    of data points may show a significant outcome. Conversely, when using large                   datasets,\n",
      "    significant testing can be misleading since small or trivial effects may produce statistically\n",
      "    significant results.\n",
      "    \n",
      "    \n",
      "\n",
      "    \n",
      "    PARAMETRIC vs NON-PARAMETRIC TESTING\n",
      "    Most research collects information from a sample of the population of interest, it is normally\n",
      "    impossible to collect data from the whole population. We do, however, want to see how well\n",
      "    the collected data reflects the population in terms of          the        population mean, standard\n",
      "    deviations, proportions etc. based on parametric distribution functions. These measures are\n",
      "    the population parameters. Parameter estimates of these in the sample population are\n",
      "    statistics. Parametric statistics require assumptions to be made of the data including             the\n",
      "    normality of distribution and homogeneity of variance.\n",
      "    In some cases, these assumptions may be violated in that the data may be noticeably skewed:\n",
      "\n",
      "    177 | P a g e\n",
      "\n",
      "\n",
      "    0    0\n",
      "\n",
      "                0  1  2  3  4               0  1  2  3\n",
      "                      Normal                   Skewed\n",
      "    Sometimes transforming the data can rectify this but not always. It is also common to collect\n",
      "    ordinal data (i.e. Likert scale ratings) for which terms such as mean and standard deviation\n",
      "    are meaningless. As such there are no parameters associated with ordinal (non-parametric)\n",
      "    data. The non-parametric counterparts include median values and quartiles.\n",
      "    In both of the cases described non-parametric statistical tests are available. There are\n",
      "    equivalents to the most common classical parametric tests. These tests    donâ€™t assume\n",
      "    normally distributed data or population parameters and are based on sorting the data into\n",
      "    ranks from lowest to highest values. All subsequent calculations are done with these ranks\n",
      "    rather than with the actual data values.\n",
      "\n",
      "    178 | P a g e\n",
      "\n",
      "\n",
      "                    WHICH TEST SHOULD I USE?\n",
      "Comparing one sample to a known or hypothesized population mean.\n",
      "\n",
      "    Data type\n",
      "\n",
      "    Continuous    Ordinal    Nominal\n",
      "\n",
      "    2 categories    >2 categories\n",
      "\n",
      "One-sample    One-sample  Binomial test    Multinomial test\n",
      "  t-test    median test                     or Chi-square\n",
      "                                          â€˜goodness of fitâ€™\n",
      "    Currently not available in\n",
      "    JASP\n",
      "\n",
      "    Testing relationships between two or more variables\n",
      "\n",
      "    Data type\n",
      "\n",
      "    Continuous    Ordinal    Nominal\n",
      "\n",
      "    Are parametric\n",
      "    assumptions met?\n",
      "\n",
      "    Yes    No\n",
      "\n",
      "             Chi-square\n",
      " Pearsonâ€™s    Spearmanâ€™s or    contingency\n",
      "correlation    Kendallâ€™s tau    tables\n",
      "\n",
      "    179 | P a g e\n",
      "\n",
      "\n",
      "    Predicting outcomes\n",
      "\n",
      "    Data type\n",
      "\n",
      "    Continuous    Ordinal    Nominal\n",
      "\n",
      "   More than one\n",
      "predictor variable?\n",
      "\n",
      "    No    Yes\n",
      "\n",
      "  Simple       Multiple    Ordinal    Logistic\n",
      "regression    regression    regression    regression\n",
      "                                          tables\n",
      "Currently not available in\n",
      "           JASP\n",
      "\n",
      "\n",
      "    Testing for differences between two independent groups\n",
      "\n",
      "    Data type\n",
      "\n",
      "    Continuous    Ordinal    Nominal\n",
      "\n",
      " Are parametric\n",
      "assumptions met?\n",
      "\n",
      "    Yes    No\n",
      "\n",
      "Independent    Mann-Whitney U    Chi-square or\n",
      "   t-test    test                Fischerâ€™s Exact\n",
      "                                 test\n",
      "\n",
      "                                 180 | P a g e\n",
      "\n",
      "\n",
      "    Testing for differences between two related groups\n",
      "\n",
      "    Data type\n",
      "\n",
      "    Continuous    Ordinal    Nominal\n",
      "\n",
      " Are parametric\n",
      "assumptions met?\n",
      "\n",
      "    Yes    No\n",
      "\n",
      "    Paired samples t-test    Wilcoxonâ€™s test    McNemarâ€™s test\n",
      "\n",
      "                                          Currently not available in\n",
      "                                                     JASP\n",
      "\n",
      "\n",
      "    Testing for differences between three or more independent groups\n",
      "\n",
      "    Data type\n",
      "\n",
      "    Continuous    Ordinal    Nominal\n",
      "\n",
      "    Are parametric\n",
      "    assumptions met?\n",
      "\n",
      "    Yes    No\n",
      "\n",
      "    ANOVA    Kruskall-Wallis    Chi-square\n",
      "                                Contingency tables\n",
      "\n",
      "    181 | P a g e\n",
      "\n",
      "\n",
      "    Testing for differences between three or more related groups\n",
      "\n",
      "    Data type\n",
      "\n",
      "    Continuous    Ordinal    Nominal\n",
      "\n",
      " Are parametric\n",
      "assumptions met?\n",
      "\n",
      "    Yes    No\n",
      "\n",
      "    RMANOVA    Friedman test    Repeated measures\n",
      "                                logistic regression\n",
      "\n",
      "    Test for interactions between 2 or more independent variables\n",
      "\n",
      "    Data type\n",
      "\n",
      "    Continuous    Ordinal    Nominal\n",
      "\n",
      "    Are parametric\n",
      "    assumptions met?\n",
      "\n",
      "    Yes    No\n",
      "\n",
      "Two-way    Ordered logistic    Factorial logistic\n",
      " ANOVA    regression           regression\n",
      "\n",
      "    182 | P a g e\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(documents_new[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "744608f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse_document_with_llm\n"
     ]
    }
   ],
   "source": [
    "print(parser.parse_mode)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jasp-multimodal-rag-F1fOabRm-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
