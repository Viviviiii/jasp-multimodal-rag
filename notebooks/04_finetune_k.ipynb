{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "871d3651",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-19 01:23:03.785\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mâœ… Loaded FlagEmbeddingReranker from llama_index.postprocessor.flag_embedding_reranker\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#setup\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import random\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "# add /Users/ywxiu/jasp-multimodal-rag/src to sys.path\n",
    "project_root = Path.cwd().parent  # goes from notebooks â†’ jasp-multimodal-rag\n",
    "src_path = project_root / \"src\"\n",
    "sys.path.append(str(src_path))\n",
    "\n",
    "import retrieval.retrieval as retr  # adjust if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a456856b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'query', 'answerable', 'ground_truth_answer', 'relevant_chunk_ids']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 1 â€“ Load test_set\n",
    "TEST_JSON = Path(\"/Users/ywxiu/jasp-multimodal-rag/data/test_QA/QA_filled_1.json\")\n",
    "\n",
    "with open(TEST_JSON, \"r\") as f:\n",
    "    test_set = json.load(f)\n",
    "\n",
    "\n",
    "print(list(test_set[0]))\n",
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "781e6177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2 â€“ Parameter space for tuning\n",
    "param_space = {\n",
    "    \"K_BM25\":          [5, 10, 20],\n",
    "    \"boost_weight\":    [0.0, 1.0, 3.0, 5.0],\n",
    "    \"K_SEMANTIC\":      [5, 10, 20],\n",
    "    \"RRF_K\":           [10, 60, 120],\n",
    "    \"TOP_AFTER_RRF\":   [10, 20, 40],\n",
    "    \"score_threshold\": [-3, -1, 0, 1.5, 2.0, 2.5, 3.0],\n",
    "    \"TOP_FINAL\":       [1, 3, 5],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b2a3005",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3 â€“ Helper to apply a config to the retrieval module\n",
    "def apply_config(cfg: dict):\n",
    "    retr.K_BM25        = cfg[\"K_BM25\"]\n",
    "    retr.BOOST_WEIGHT  = cfg[\"boost_weight\"]\n",
    "    retr.K_SEMANTIC    = cfg[\"K_SEMANTIC\"]\n",
    "    retr.RRF_K         = cfg[\"RRF_K\"]\n",
    "    retr.TOP_AFTER_RRF = cfg[\"TOP_AFTER_RRF\"]\n",
    "    retr.SCORE_THRESHOLD = cfg[\"score_threshold\"]\n",
    "    retr.TOP_FINAL     = cfg[\"TOP_FINAL\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b72af56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4 â€“ Evaluation function (compute H1a, H1b, H2)\n",
    "\n",
    "def evaluate_config(cfg: dict, test_set: list):\n",
    "    \"\"\"Run retrieval for a given config and compute H1a, H1b, H2.\"\"\"\n",
    "    apply_config(cfg)\n",
    "\n",
    "    retrieval_results = []\n",
    "\n",
    "    for item in test_set:\n",
    "        q = item[\"query\"]\n",
    "        qid = item[\"id\"]\n",
    "        relevant_ids = set(item[\"relevant_chunk_ids\"])\n",
    "\n",
    "        # Run your pipeline\n",
    "        results = retr.retrieve_top_k(q, top_k=cfg[\"TOP_FINAL\"])\n",
    "\n",
    "        retrieved_ids = [\n",
    "            # try doc_id, fall back to section_id\n",
    "            (getattr(r, \"metadata\", {}) or {}).get(\"doc_id\")\n",
    "            or (getattr(r, \"metadata\", {}) or {}).get(\"section_id\")\n",
    "            for r in results\n",
    "        ]\n",
    "\n",
    "        success_at_k = any(rid in relevant_ids for rid in retrieved_ids[:cfg[\"TOP_FINAL\"]])\n",
    "        top1_relevant = retrieved_ids[0] in relevant_ids if retrieved_ids else False\n",
    "\n",
    "        retrieval_results.append({\n",
    "            \"id\": qid,\n",
    "            \"query\": q,\n",
    "            \"answerable\": item[\"answerable\"],\n",
    "            \"retrieved_ids\": retrieved_ids,\n",
    "            \"success_at_k\": success_at_k,\n",
    "            \"top1_relevant\": top1_relevant,\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(retrieval_results)\n",
    "    df_answerable   = df[df[\"answerable\"] == True]\n",
    "    df_unanswerable = df[df[\"answerable\"] == False]\n",
    "\n",
    "    H1a = df_answerable[\"success_at_k\"].mean() if not df_answerable.empty else float(\"nan\")\n",
    "    H1b = df_answerable[\"top1_relevant\"].mean() if not df_answerable.empty else float(\"nan\")\n",
    "\n",
    "    if not df_unanswerable.empty:\n",
    "        is_empty = (df_unanswerable[\"retrieved_ids\"].str.len() == 0)\n",
    "        H2 = is_empty.mean()\n",
    "    else:\n",
    "        H2 = float(\"nan\")\n",
    "\n",
    "    return H1a, H1b, H2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cd3699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-19 01:24:44.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mretrieve_top_k\u001b[0m:\u001b[36m370\u001b[0m - \u001b[1mðŸ” Starting retrieval pipeline for query: 'How to import data from Excel or CSV into JASP?'\u001b[0m\n",
      "\u001b[32m2025-11-19 01:24:44.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mload_docs_for_bm25\u001b[0m:\u001b[36m199\u001b[0m - \u001b[1mðŸ“„ Loaded 16 chunks from /Users/ywxiu/jasp-multimodal-rag/data/processed/chunks/github_RegressionLinearBayesian.json\u001b[0m\n",
      "\u001b[32m2025-11-19 01:24:44.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mload_docs_for_bm25\u001b[0m:\u001b[36m199\u001b[0m - \u001b[1mðŸ“„ Loaded 33 chunks from /Users/ywxiu/jasp-multimodal-rag/data/processed/chunks/github_RegressionLogistic.json\u001b[0m\n",
      "\u001b[32m2025-11-19 01:24:44.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mload_docs_for_bm25\u001b[0m:\u001b[36m199\u001b[0m - \u001b[1mðŸ“„ Loaded 43 chunks from /Users/ywxiu/jasp-multimodal-rag/data/processed/chunks/video_Introduction_to_JASP_APRaBFC2lEQ_chunks.json\u001b[0m\n",
      "\u001b[32m2025-11-19 01:24:44.264\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mload_docs_for_bm25\u001b[0m:\u001b[36m199\u001b[0m - \u001b[1mðŸ“„ Loaded 58 chunks from /Users/ywxiu/jasp-multimodal-rag/data/processed/chunks/github_MixedModelsLMM.json\u001b[0m\n",
      "\u001b[32m2025-11-19 01:24:44.265\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mload_docs_for_bm25\u001b[0m:\u001b[36m199\u001b[0m - \u001b[1mðŸ“„ Loaded 76 chunks from /Users/ywxiu/jasp-multimodal-rag/data/processed/chunks/github_MixedModelsGLMM.json\u001b[0m\n",
      "\u001b[32m2025-11-19 01:24:44.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mload_docs_for_bm25\u001b[0m:\u001b[36m199\u001b[0m - \u001b[1mðŸ“„ Loaded 94 chunks from /Users/ywxiu/jasp-multimodal-rag/data/processed/chunks/github_Correlation.json\u001b[0m\n",
      "\u001b[32m2025-11-19 01:24:44.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mload_docs_for_bm25\u001b[0m:\u001b[36m199\u001b[0m - \u001b[1mðŸ“„ Loaded 406 chunks from /Users/ywxiu/jasp-multimodal-rag/data/processed/chunks/manual_Statistical-Analysis-in-JASP-A-guide-for-students-2025.json\u001b[0m\n",
      "\u001b[32m2025-11-19 01:24:44.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mload_docs_for_bm25\u001b[0m:\u001b[36m199\u001b[0m - \u001b[1mðŸ“„ Loaded 422 chunks from /Users/ywxiu/jasp-multimodal-rag/data/processed/chunks/github_MixedModelsBGLMM.json\u001b[0m\n",
      "\u001b[32m2025-11-19 01:24:44.283\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mload_docs_for_bm25\u001b[0m:\u001b[36m199\u001b[0m - \u001b[1mðŸ“„ Loaded 425 chunks from /Users/ywxiu/jasp-multimodal-rag/data/processed/chunks/video_JASP_repeated_measures_ANOVA_and_post_hoc_tests_CWRmc2t1Vlo_chunks.json\u001b[0m\n",
      "\u001b[32m2025-11-19 01:24:44.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mload_docs_for_bm25\u001b[0m:\u001b[36m199\u001b[0m - \u001b[1mðŸ“„ Loaded 438 chunks from /Users/ywxiu/jasp-multimodal-rag/data/processed/chunks/github_GeneralizedLinearModel.json\u001b[0m\n",
      "\u001b[32m2025-11-19 01:24:44.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mload_docs_for_bm25\u001b[0m:\u001b[36m199\u001b[0m - \u001b[1mðŸ“„ Loaded 452 chunks from /Users/ywxiu/jasp-multimodal-rag/data/processed/chunks/github_MixedModelsBLMM.json\u001b[0m\n",
      "\u001b[32m2025-11-19 01:24:44.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mload_docs_for_bm25\u001b[0m:\u001b[36m199\u001b[0m - \u001b[1mðŸ“„ Loaded 467 chunks from /Users/ywxiu/jasp-multimodal-rag/data/processed/chunks/github_RegressionLinear.json\u001b[0m\n",
      "\u001b[32m2025-11-19 01:24:44.287\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mload_docs_for_bm25\u001b[0m:\u001b[36m199\u001b[0m - \u001b[1mðŸ“„ Loaded 485 chunks from /Users/ywxiu/jasp-multimodal-rag/data/processed/chunks/github_CorrelationBayesian.json\u001b[0m\n",
      "\u001b[32m2025-11-19 01:24:44.287\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mload_docs_for_bm25\u001b[0m:\u001b[36m201\u001b[0m - \u001b[32m\u001b[1mâœ… Total BM25 corpus size: 485 chunks from 13 files.\u001b[0m\n",
      "\u001b[32m2025-11-19 01:24:52.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mbuild_bm25_retriever\u001b[0m:\u001b[36m244\u001b[0m - \u001b[1mInitializing BM25 retriever with 485 documents...\u001b[0m\n",
      "\u001b[32m2025-11-19 01:24:52.826\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mretrieve_top_k\u001b[0m:\u001b[36m381\u001b[0m - \u001b[1mâš™ï¸ Retrieving from BM25 and semantic retrievers...\u001b[0m\n",
      "\u001b[32m2025-11-19 01:24:52.845\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mretrieve\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mâš¡ Boosted score by 3.0 for match in 'data handling in jasp'\u001b[0m\n",
      "\u001b[32m2025-11-19 01:24:52.845\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mretrieve\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mâš¡ Boosted score by 3.0 for match in 'experimental design and data layout in excel for jasp import.'\u001b[0m\n",
      "\u001b[32m2025-11-19 01:24:52.845\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mretrieve\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mâš¡ Boosted score by 3.0 for match in 'experimental design and data layout in excel for jasp import.'\u001b[0m\n",
      "\u001b[32m2025-11-19 01:24:52.846\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mretrieve\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mâš¡ Boosted score by 3.0 for match in 'experimental design and data layout in excel for jasp import.'\u001b[0m\n",
      "\u001b[32m2025-11-19 01:24:52.846\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mretrieve\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mâš¡ Boosted score by 3.0 for match in 'is your data correct?'\u001b[0m\n",
      "\u001b[32m2025-11-19 01:24:52.846\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mretrieve\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mâš¡ Boosted score by 3.0 for match in 'running the mixed factor anova'\u001b[0m\n",
      "\u001b[32m2025-11-19 01:24:52.846\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mretrieve\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mâš¡ Boosted score by 3.0 for match in 'data handling in jasp'\u001b[0m\n",
      "\u001b[32m2025-11-19 01:24:52.847\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mretrieve\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mâš¡ Boosted score by 3.0 for match in 'reporting the results'\u001b[0m\n",
      "\u001b[32m2025-11-19 01:24:52.847\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mretrieve\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mâš¡ Boosted score by 3.0 for match in 'reporting the results'\u001b[0m\n",
      "\u001b[32m2025-11-19 01:24:52.848\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mretrieve\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mâš¡ Boosted score by 3.0 for match in 'mixed factor anova'\u001b[0m\n",
      "\u001b[32m2025-11-19 01:24:52.848\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mretrieve\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mâš¡ Boosted score by 3.0 for match in 'comparing more than two related groups'\u001b[0m\n",
      "\u001b[32m2025-11-19 01:24:54.050\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mretrieve_top_k\u001b[0m:\u001b[36m384\u001b[0m - \u001b[32m\u001b[1mBM25: 20 | Semantic: 5\u001b[0m\n",
      "\u001b[32m2025-11-19 01:24:54.052\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mretrieve_top_k\u001b[0m:\u001b[36m388\u001b[0m - \u001b[32m\u001b[1mðŸ”— Fused results (RRF): 10\u001b[0m\n",
      "\u001b[32m2025-11-19 01:24:54.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mretrieval.retrieval\u001b[0m:\u001b[36mrerank_cross_encoder\u001b[0m:\u001b[36m325\u001b[0m - \u001b[1mâš™ï¸ Cross-encoder rerank with BGE model: BAAI/bge-reranker-large\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Step 5 â€“ Randomly sample configurations and evaluate\n",
    "def sample_random_config(space: dict) -> dict:\n",
    "    return {k: random.choice(v) for k, v in space.items()}\n",
    "\n",
    "N_EXPERIMENTS = 30  # you can make this 30, 50, 100...\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(N_EXPERIMENTS):\n",
    "    cfg = sample_random_config(param_space)\n",
    "    H1a, H1b, H2 = evaluate_config(cfg, test_set)\n",
    "\n",
    "    row = {**cfg, \"H1a\": H1a, \"H1b\": H1b, \"H2\": H2}\n",
    "    results.append(row)\n",
    "\n",
    "    print(f\"{i+1}/{N_EXPERIMENTS} | {cfg} | H1a={H1a:.3f}, H1b={H1b:.3f}, H2={H2:.3f}\")\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9bc67a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d075064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6 â€“ Plot 3 figures: H1a, H1b, H2 vs each parameter\n",
    "param_names = [\n",
    "    \"K_BM25\",\n",
    "    \"boost_weight\",\n",
    "    \"K_SEMANTIC\",\n",
    "    \"RRF_K\",\n",
    "    \"TOP_AFTER_RRF\",\n",
    "    \"score_threshold\",\n",
    "    \"TOP_FINAL\",\n",
    "]\n",
    "\n",
    "def plot_metric_vs_params(df, metric: str):\n",
    "    n_params = len(param_names)\n",
    "    fig, axes = plt.subplots(1, n_params, figsize=(4*n_params, 4), sharey=True)\n",
    "\n",
    "    if n_params == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, param in zip(axes, param_names):\n",
    "        grouped = df.groupby(param)[metric].mean().sort_index()\n",
    "        ax.plot(grouped.index, grouped.values, marker=\"o\")\n",
    "        ax.set_title(param)\n",
    "        ax.set_xlabel(param)\n",
    "        ax.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "    axes[0].set_ylabel(metric)\n",
    "    fig.suptitle(f\"{metric} vs retrieval parameters\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_metric_vs_params(df_results, \"H1a\")\n",
    "plot_metric_vs_params(df_results, \"H1b\")\n",
    "plot_metric_vs_params(df_results, \"H2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00d3745",
   "metadata": {},
   "outputs": [],
   "source": [
    "good = df_results[\n",
    "   # (df_results[\"H1a\"] >= 0.60) &\n",
    "   # (df_results[\"H1b\"] >= 0.60) &\n",
    "    (df_results[\"H2\"] >= 0.80)\n",
    "].sort_values(\"H1a\", ascending=False)\n",
    "\n",
    "good.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jasp-multimodal-rag-F1fOabRm-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
