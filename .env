GITHUB_PERSONAL_ACCESS_TOKEN= ***
PYTHONPATH=src 
# ---------------------------- 
# pdf ingestion 
# ---------------------------- 
LLAMA_CLOUD_API_KEY =***
OLLAMA_URL=http://localhost:11434/api/generate 
OLLAMA_MODEL=llava-phi3:latest 
# ---------------------------- 
# data splitting: Model & Storage Configuration 
# ---------------------------- 
EMBEDDING_MODEL=BAAI/bge-large-en-v1.5 
CHROMA_PERSIST_DIR=./data/vector_store
